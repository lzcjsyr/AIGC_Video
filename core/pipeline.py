"""
Minimal pipeline runner to simplify main.py.
Implements an auto end-to-end flow using existing core modules.

è°ƒç”¨å…³ç³»:
- cli/__main__.py: é€šè¿‡VideoPipelineç±»æ‰§è¡Œå®Œæ•´çš„è§†é¢‘åˆ¶ä½œæµç¨‹
- web/backend/app.py: åœ¨åå°ä»»åŠ¡ä¸­ä½¿ç”¨VideoPipelineæ‰§è¡Œè§†é¢‘åˆ¶ä½œ
- ä½œä¸ºç³»ç»Ÿçš„æ ¸å¿ƒç¼–æ’æ¨¡å—ï¼Œåè°ƒæ‰€æœ‰å…¶ä»–æ ¸å¿ƒæ¨¡å—å®Œæˆ5æ­¥å¤„ç†æµç¨‹
- è°ƒç”¨core/routers.pyçš„æ–‡æ¡£è¯»å–ã€æ™ºèƒ½æ€»ç»“ã€è¦ç‚¹æå–åŠŸèƒ½
- è°ƒç”¨core/media.pyçš„å›¾åƒç”Ÿæˆã€è¯­éŸ³åˆæˆã€è§†é¢‘åˆæˆåŠŸèƒ½
- è°ƒç”¨core/document_processor.pyå¯¼å‡ºDOCXæ–‡æ¡£
"""

import os
import json
import datetime
from typing import Dict, Any, List, Optional

from config import config
from core.utils import load_json_file
from core.document_processor import export_raw_to_docx
from core.routers import (
    read_document,
    intelligent_summarize,
    extract_keywords,
)
from core.media import (
    generate_opening_image,
    generate_images_for_segments,
    synthesize_voice_for_segments,
)
from core.video_composer import VideoComposer
from core.services import text_to_audio_bytedance


def run_auto(
    input_file: str,
    output_dir: str,
    target_length: int,
    num_segments: int,
    image_size: str,
    llm_server: str,
    llm_model: str,
    image_server: str,
    image_model: str,
    tts_server: str,
    voice: str,
    image_style_preset: str,
    opening_image_style: str,
    enable_subtitles: bool,
    bgm_filename: Optional[str] = None,
    opening_quote: bool = True,
) -> Dict[str, Any]:
    start_time = datetime.datetime.now()

    project_root = os.path.dirname(os.path.dirname(__file__))

    # 1) è¯»å–æ–‡æ¡£
    document_content, original_length = read_document(input_file)

    # 2) æ™ºèƒ½ç¼©å†™ï¼ˆåŸå§‹æ•°æ®ï¼‰
    raw_data = intelligent_summarize(
        llm_server, llm_model, document_content, target_length, num_segments
    )

    # 3) åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„
    current_time = datetime.datetime.now()
    time_suffix = current_time.strftime("%m%d_%H%M")
    title = raw_data.get('title', 'untitled').replace(' ', '_').replace('/', '_').replace('\\', '_')
    project_folder = f"{title}_{time_suffix}"
    project_output_dir = os.path.join(output_dir, project_folder)
    os.makedirs(project_output_dir, exist_ok=True)
    os.makedirs(f"{project_output_dir}/images", exist_ok=True)
    os.makedirs(f"{project_output_dir}/voice", exist_ok=True)
    os.makedirs(f"{project_output_dir}/text", exist_ok=True)

    # 4) ä¿å­˜åŸå§‹JSON + å¯¼å‡ºå¯ç¼–è¾‘DOCX
    raw_json_path = f"{project_output_dir}/text/raw.json"
    with open(raw_json_path, 'w', encoding='utf-8') as f:
        json.dump(raw_data, f, ensure_ascii=False, indent=2)
    try:
        raw_docx_path = f"{project_output_dir}/text/raw.docx"
        export_raw_to_docx(raw_data, raw_docx_path)
    except Exception:
        raw_docx_path = None

    # 5) æ­¥éª¤1.5ï¼šæ®µè½åˆ‡åˆ†
    step15 = run_step_1_5(project_output_dir, num_segments, is_new_project=True, raw_data=raw_data, auto_mode=True)
    if not step15.get("success"):
        return {"success": False, "message": step15.get("message", "æ­¥éª¤1.5å¤„ç†å¤±è´¥")}
    script_data = step15.get("script_data")
    script_path = step15.get("script_path")

    # 6) è¦ç‚¹æå–
    keywords_data = extract_keywords(llm_server, llm_model, script_data)
    keywords_path = f"{project_output_dir}/text/keywords.json"
    with open(keywords_path, 'w', encoding='utf-8') as f:
        json.dump(keywords_data, f, ensure_ascii=False, indent=2)

    # 7) ç”Ÿæˆå¼€åœºå›¾åƒï¼ˆå¯é€‰ï¼‰& æ®µè½å›¾åƒ
    opening_image_path = generate_opening_image(
        image_model, opening_image_style, image_size, f"{project_output_dir}/images", opening_quote
    )
    image_result = generate_images_for_segments(
        image_model, keywords_data, image_style_preset, image_size, f"{project_output_dir}/images"
    )
    image_paths: List[str] = image_result["image_paths"]
    failed_image_segments: List[int] = image_result["failed_segments"]

    # 8) è¯­éŸ³åˆæˆï¼ˆå«SRTå¯¼å‡ºï¼‰
    audio_paths = synthesize_voice_for_segments(tts_server, voice, script_data, f"{project_output_dir}/voice")

    # 9) BGMè·¯å¾„è§£æ
    bgm_audio_path = None
    if bgm_filename:
        candidate = os.path.join(project_root, "music", bgm_filename)
        if os.path.exists(candidate):
            bgm_audio_path = candidate

    # 10) å¼€åœºé‡‘å¥å£æ’­ï¼ˆå¯é€‰ï¼‰
    opening_golden_quote = (script_data or {}).get("golden_quote", "")
    opening_narration_audio_path = None
    try:
        if opening_quote and isinstance(opening_golden_quote, str) and opening_golden_quote.strip():
            opening_voice_dir = os.path.join(project_output_dir, "voice")
            os.makedirs(opening_voice_dir, exist_ok=True)
            opening_narration_audio_path = os.path.join(opening_voice_dir, "opening.wav")
            if not os.path.exists(opening_narration_audio_path):
                ok = text_to_audio_bytedance(opening_golden_quote, opening_narration_audio_path, voice=voice, encoding="wav")
                if not ok:
                    opening_narration_audio_path = None
    except Exception:
        opening_narration_audio_path = None

    # 11) è§†é¢‘åˆæˆ
    composer = VideoComposer()
    final_video_path = composer.compose_video(
        image_paths, audio_paths, f"{project_output_dir}/final_video.mp4",
        script_data=script_data, enable_subtitles=enable_subtitles,
        bgm_audio_path=bgm_audio_path,
        opening_image_path=opening_image_path,
        opening_golden_quote=opening_golden_quote,
        opening_narration_audio_path=opening_narration_audio_path,
        bgm_volume=float(getattr(config, "BGM_DEFAULT_VOLUME", 0.2)),
        narration_volume=float(getattr(config, "NARRATION_DEFAULT_VOLUME", 1.0)),
        image_size=image_size,
        opening_quote=opening_quote,
    )

    # 12) æ±‡æ€»ç»“æœ
    end_time = datetime.datetime.now()
    execution_time = (end_time - start_time).total_seconds()
    compression_ratio = (1 - (script_data['total_length'] / original_length)) * 100 if original_length > 0 else 0.0

    return {
        "success": True,
        "message": "è§†é¢‘åˆ¶ä½œå®Œæˆ",
        "execution_time": execution_time,
        "script": {
            "file_path": script_path,
            "total_length": script_data['total_length'],
            "segments_count": script_data['actual_segments']
        },
        "keywords": {
            "file_path": keywords_path,
            "total_keywords": sum(len(seg.get('keywords', [])) + len(seg.get('atmosphere', [])) for seg in keywords_data['segments']),
            "avg_per_segment": sum(len(seg.get('keywords', [])) + len(seg.get('atmosphere', [])) for seg in keywords_data['segments']) / max(1, len(keywords_data['segments']))
        },
        "images": image_paths,
        "audio_files": audio_paths,
        "final_video": final_video_path,
        "statistics": {
            "original_length": original_length,
            "compression_ratio": f"{compression_ratio:.1f}%",
            "total_processing_time": execution_time,
        },
        "project_output_dir": project_output_dir,
        "failed_image_segments": failed_image_segments,
    }


__all__ = ["run_auto"]


def run_interactive_setup(project_root: str, output_dir: str):
    """Minimal interactive setup: choose input file and run mode.

    Returns: (input_file, run_mode)
    """
    try:
        from cli.ui_helpers import prompt_choice, interactive_file_selector
        # æ–‡ä»¶é€‰æ‹©
        while True:
            input_file = interactive_file_selector(input_dir=os.path.join(project_root, "input"))
            if input_file is None:
                print("\nğŸ‘‹ è¿”å›ä¸Šä¸€çº§")
                continue
            mode = prompt_choice("è¯·é€‰æ‹©å¤„ç†æ–¹å¼", ["å…¨è‡ªåŠ¨ï¼ˆä¸€æ¬¡æ€§å…¨éƒ¨ç”Ÿæˆï¼‰", "åˆ†æ­¥å¤„ç†ï¼ˆæ¯æ­¥ç¡®è®¤å¹¶å¯ä¿®æ”¹äº§ç‰©ï¼‰"], default_index=0)
            if mode is None:
                print("ğŸ‘‹ è¿”å›ä¸Šä¸€çº§")
                continue
            run_mode = "auto" if mode.startswith("å…¨è‡ªåŠ¨") else "step"
            return input_file, run_mode
    except Exception:
        # å‘ç”Ÿå¼‚å¸¸æ—¶è¿”å›Noneï¼Œä¸»æµç¨‹è‡ªè¡Œå¤„ç†
        return None, "auto"

__all__.append("run_interactive_setup")


# -------------------- Step-wise pipeline (for CLI step mode) --------------------

def run_step_1(
    input_file: str,
    output_dir: str,
    llm_server: str,
    llm_model: str,
    target_length: int,
    num_segments: int,
) -> Dict[str, Any]:
    document_content, _ = read_document(input_file)
    raw_data = intelligent_summarize(llm_server, llm_model, document_content, target_length, num_segments)

    current_time = datetime.datetime.now()
    time_suffix = current_time.strftime("%m%d_%H%M")
    title = raw_data.get('title', 'untitled').replace(' ', '_').replace('/', '_').replace('\\', '_')
    project_folder = f"{title}_{time_suffix}"
    project_output_dir = os.path.join(output_dir, project_folder)
    os.makedirs(project_output_dir, exist_ok=True)
    os.makedirs(f"{project_output_dir}/images", exist_ok=True)
    os.makedirs(f"{project_output_dir}/voice", exist_ok=True)
    os.makedirs(f"{project_output_dir}/text", exist_ok=True)

    raw_json_path = f"{project_output_dir}/text/raw.json"
    with open(raw_json_path, 'w', encoding='utf-8') as f:
        json.dump(raw_data, f, ensure_ascii=False, indent=2)

    try:
        raw_docx_path = f"{project_output_dir}/text/raw.docx"
        export_raw_to_docx(raw_data, raw_docx_path)
    except Exception:
        raw_docx_path = None

    return {
        "success": True,
        "project_output_dir": project_output_dir,
        "raw": {"raw_json_path": raw_json_path, "raw_docx_path": raw_docx_path, "total_length": raw_data.get('total_length', 0)},
    }


def run_step_1_5(project_output_dir: str, num_segments: int, is_new_project: bool = False, raw_data: Optional[Dict[str, Any]] = None, auto_mode: bool = False) -> Dict[str, Any]:
    """
    ç»Ÿä¸€å¤„ç†æ­¥éª¤1.5ï¼šæ®µè½åˆ‡åˆ†
    
    Args:
        project_output_dir: é¡¹ç›®è¾“å‡ºç›®å½•
        num_segments: ç›®æ ‡åˆ†æ®µæ•°
        is_new_project: æ˜¯å¦ä¸ºæ–°å»ºé¡¹ç›®
        raw_data: åŸå§‹æ•°æ®ï¼ˆæ–°å»ºé¡¹ç›®æ—¶æä¾›ï¼‰
        
    Returns:
        Dict[str, Any]: å¤„ç†ç»“æœï¼ŒåŒ…å«æˆåŠŸçŠ¶æ€å’Œç›¸å…³ä¿¡æ¯
    """
    from core.utils import load_json_file, logger
    from core.document_processor import parse_raw_from_docx, export_script_to_docx
    
    try:
        print("æ­£åœ¨å¤„ç†åŸå§‹å†…å®¹ä¸ºè„šæœ¬...")
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        raw_json_path = os.path.join(project_output_dir, 'text', 'raw.json')
        raw_docx_path = os.path.join(project_output_dir, 'text', 'raw.docx')
        script_path = os.path.join(project_output_dir, 'text', 'script.json')
        script_docx_path = os.path.join(project_output_dir, 'text', 'script.docx')
        
        # è·å–åŸå§‹æ•°æ®
        if is_new_project and raw_data is not None:
            # æ–°å»ºé¡¹ç›®ï¼šä½¿ç”¨æä¾›çš„raw_data
            logger.info(f"æ–°å»ºé¡¹ç›®ï¼šä½¿ç”¨æä¾›çš„rawæ•°æ®")
            current_raw_data = raw_data
        else:
            # ç°æœ‰é¡¹ç›®ï¼šä»æ–‡ä»¶åŠ è½½
            if not os.path.exists(raw_json_path):
                # æ²¡æœ‰raw.jsonä½†æœ‰raw.docxï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„raw.json
                current_raw_data = {"title": "æ‰‹åŠ¨åˆ›å»ºé¡¹ç›®", "golden_quote": "", "content": "", "target_segments": num_segments}
            else:
                print(f"åŠ è½½rawæ•°æ®: {raw_json_path}")
                current_raw_data = load_json_file(raw_json_path)
                if current_raw_data is None:
                    return {"success": False, "message": f"æ— æ³•åŠ è½½ raw.json æ–‡ä»¶: {raw_json_path}"}
                num_segments = current_raw_data.get("target_segments", num_segments)
                print(f"å½“å‰åˆ†æ®µæ•°: {num_segments}")
        
        # å°è¯•ä»ç¼–è¾‘åçš„DOCXæ–‡ä»¶è§£ææ•°æ®
        updated_raw_data = current_raw_data
        if os.path.exists(raw_docx_path):
            try:
                parsed_data = parse_raw_from_docx(raw_docx_path)
                if parsed_data is not None:
                    print("å·²ä»ç¼–è¾‘åçš„DOCXæ–‡ä»¶è§£æå†…å®¹")
                    updated_raw_data = parsed_data
                    
                    # æ›´æ–°å…ƒæ•°æ®ä½†ä¿ç•™åŸå§‹ä¿¡æ¯
                    updated_raw_data.update({
                        "target_segments": current_raw_data.get("target_segments", num_segments),
                        "created_time": current_raw_data.get("created_time"),
                        "model_info": current_raw_data.get("model_info", {}),
                        "total_length": len(updated_raw_data.get("content", ""))
                    })
                    
                    # æ›´æ–°raw.jsonæ–‡ä»¶
                    with open(raw_json_path, 'w', encoding='utf-8') as f:
                        json.dump(updated_raw_data, f, ensure_ascii=False, indent=2)
                    print(f"å·²æ›´æ–°åŸå§‹JSON: {raw_json_path}")
                else:
                    print("âš ï¸  DOCXè§£æè¿”å›Noneï¼Œä½¿ç”¨åŸå§‹æ•°æ®")
            except Exception as e:
                print(f"âš ï¸  è§£æDOCXå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ•°æ®: {e}")
        
        # æ£€æŸ¥æœ€ç»ˆæ•°æ®
        if updated_raw_data is None:
            return {"success": False, "message": "å¤„ç†rawæ•°æ®å¤±è´¥ï¼šæ•°æ®ä¸ºç©º"}
        
        # ç”¨æˆ·é€‰æ‹©åˆ‡åˆ†æ¨¡å¼ï¼ˆä»…åœ¨äº¤äº’æ¨¡å¼ä¸‹ï¼‰
        split_mode = "auto"  # é»˜è®¤è‡ªåŠ¨åˆ‡åˆ†
        if not auto_mode:  # åªæœ‰éå…¨è‡ªåŠ¨æ¨¡å¼æ‰æ˜¾ç¤ºé€‰æ‹©ç•Œé¢
            try:
                from cli.ui_helpers import prompt_choice
                choice = prompt_choice("è¯·é€‰æ‹©æ–‡æœ¬åˆ‡åˆ†æ–¹å¼", ["æ‰‹åŠ¨åˆ‡åˆ†(æ ¹æ®æ¢è¡Œç¬¦)", "è‡ªåŠ¨åˆ‡åˆ†(æ™ºèƒ½å‡åˆ†)"], default_index=1)
                if choice and choice.startswith("æ‰‹åŠ¨"):
                    split_mode = "manual"
            except:
                pass  # å¦‚æœæ— æ³•æ˜¾ç¤ºé€‰æ‹©ç•Œé¢ï¼Œä½¿ç”¨é»˜è®¤å€¼

        # å¤„ç†ä¸ºåˆ†æ®µè„šæœ¬æ•°æ®
        from core.routers import process_raw_to_script
        target_segments = updated_raw_data.get("target_segments", num_segments)
        script_data = process_raw_to_script(updated_raw_data, target_segments, split_mode)
        
        # ä¿å­˜script.json
        with open(script_path, 'w', encoding='utf-8') as f:
            json.dump(script_data, f, ensure_ascii=False, indent=2)
        print(f"åˆ†æ®µè„šæœ¬å·²ä¿å­˜åˆ°: {script_path}")
        
        # ç”Ÿæˆå¯é˜…è¯»çš„script.docx
        try:
            export_script_to_docx(script_data, script_docx_path)
            print(f"é˜…è¯»ç‰ˆDOCXå·²ä¿å­˜åˆ°: {script_docx_path}")
        except Exception as e:
            print(f"âš ï¸  ç”Ÿæˆscript.docxå¤±è´¥: {e}")
        
        logger.info(f"æ­¥éª¤1.5å¤„ç†å®Œæˆ: {script_path}")
        return {
            "success": True,
            "script_data": script_data,
            "script_path": script_path,
            "message": "æ­¥éª¤1.5å¤„ç†å®Œæˆ"
        }
        
    except Exception as e:
        logger.error(f"æ­¥éª¤1.5å¤„ç†å¤±è´¥: {str(e)}")
        return {"success": False, "message": f"æ­¥éª¤1.5å¤„ç†å¤±è´¥: {str(e)}"}


def run_step_2(llm_server: str, llm_model: str, project_output_dir: str, script_path: str = None) -> Dict[str, Any]:
    script_data = load_json_file(script_path) if script_path else load_json_file(os.path.join(project_output_dir, 'text', 'script.json'))
    keywords_data = extract_keywords(llm_server, llm_model, script_data)
    keywords_path = f"{project_output_dir}/text/keywords.json"
    with open(keywords_path, 'w', encoding='utf-8') as f:
        json.dump(keywords_data, f, ensure_ascii=False, indent=2)
    return {"success": True, "keywords_path": keywords_path}


def run_step_3(image_model: str, image_size: str, image_style_preset: str, project_output_dir: str, opening_image_style: str, opening_quote: bool = True) -> Dict[str, Any]:
    # ç¡®ä¿å¿…è¦çš„æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(f"{project_output_dir}/images", exist_ok=True)

    keywords_path = os.path.join(project_output_dir, 'text', 'keywords.json')
    keywords_data = load_json_file(keywords_path)
    opening_image_path = generate_opening_image(image_model, opening_image_style, image_size, f"{project_output_dir}/images", opening_quote)
    image_result = generate_images_for_segments(image_model, keywords_data, image_style_preset, image_size, f"{project_output_dir}/images")
    return {"success": True, "opening_image_path": opening_image_path, **image_result}


def run_step_4(tts_server: str, voice: str, project_output_dir: str, opening_quote: bool = True) -> Dict[str, Any]:
    # ç¡®ä¿å¿…è¦çš„æ–‡ä»¶å¤¹å­˜åœ¨
    os.makedirs(f"{project_output_dir}/voice", exist_ok=True)

    script_path = os.path.join(project_output_dir, 'text', 'script.json')
    script_data = load_json_file(script_path)
    audio_paths = synthesize_voice_for_segments(tts_server, voice, script_data, f"{project_output_dir}/voice")

    # ç”Ÿæˆå¼€åœºéŸ³é¢‘
    opening_golden_quote = (script_data or {}).get("golden_quote", "")
    if opening_quote and isinstance(opening_golden_quote, str) and opening_golden_quote.strip():
        opening_voice_dir = os.path.join(project_output_dir, "voice")
        os.makedirs(opening_voice_dir, exist_ok=True)
        opening_narration_audio_path = os.path.join(opening_voice_dir, "opening.wav")
        if not os.path.exists(opening_narration_audio_path):
            from core.media import text_to_audio_bytedance
            ok = text_to_audio_bytedance(opening_golden_quote, opening_narration_audio_path, voice=voice, encoding="wav")
            if ok:
                print(f"âœ… å¼€åœºéŸ³é¢‘å·²ç”Ÿæˆ: {opening_narration_audio_path}")
            else:
                print("âŒ å¼€åœºéŸ³é¢‘ç”Ÿæˆå¤±è´¥")
        else:
            print(f"âœ… å¼€åœºéŸ³é¢‘å·²å­˜åœ¨: {opening_narration_audio_path}")

    return {"success": True, "audio_paths": audio_paths}


def run_step_5(project_output_dir: str, image_size: str, enable_subtitles: bool, bgm_filename: str, voice: str, opening_quote: bool = True) -> Dict[str, Any]:
    project_root = os.path.dirname(os.path.dirname(__file__))
    images_dir = os.path.join(project_output_dir, 'images')
    voice_dir = os.path.join(project_output_dir, 'voice')
    script_path = os.path.join(project_output_dir, 'text', 'script.json')

    # å‰ç½®æ£€æŸ¥ï¼šç¡®ä¿å¿…è¦æ–‡ä»¶å­˜åœ¨
    if not os.path.exists(script_path):
        return {"success": False, "message": "è„šæœ¬æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤1.5"}

    script_data = load_json_file(script_path)
    if not script_data:
        return {"success": False, "message": "è„šæœ¬æ–‡ä»¶åŠ è½½å¤±è´¥"}

    # æ£€æŸ¥å›¾åƒæ–‡ä»¶
    expected_segments = script_data.get('actual_segments', 0)
    image_count = 0
    for i in range(1, expected_segments + 1):
        img_path = os.path.join(images_dir, f"segment_{i}.png")
        if os.path.exists(img_path):
            image_count += 1
        else:
            # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
            for ext in ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv', '.m4v']:
                vid_path = os.path.join(images_dir, f"segment_{i}{ext}")
                if os.path.exists(vid_path):
                    image_count += 1
                    break

    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
    audio_count = 0
    for i in range(1, expected_segments + 1):
        audio_path = os.path.join(voice_dir, f"voice_{i}.wav")
        if os.path.exists(audio_path):
            audio_count += 1

    if image_count == 0:
        return {"success": False, "message": "æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤3"}
    if audio_count == 0:
        return {"success": False, "message": "æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤4"}
    if image_count != expected_segments:
        return {"success": False, "message": f"å›¾åƒæ–‡ä»¶ä¸å®Œæ•´ï¼Œéœ€è¦{expected_segments}ä¸ªï¼Œæ‰¾åˆ°{image_count}ä¸ª"}
    if audio_count != expected_segments:
        return {"success": False, "message": f"éŸ³é¢‘æ–‡ä»¶ä¸å®Œæ•´ï¼Œéœ€è¦{expected_segments}ä¸ªï¼Œæ‰¾åˆ°{audio_count}ä¸ª"}

    # Resolve ordered assets (æ”¯æŒå›¾ç‰‡å’Œè§†é¢‘æ–‡ä»¶)
    image_paths = []
    for i in range(1, script_data.get('actual_segments', 0) + 1):
        # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶
        img_path = os.path.join(images_dir, f"segment_{i}.png")
        if os.path.exists(img_path):
            image_paths.append(img_path)
            continue
        # æ£€æŸ¥è§†é¢‘æ–‡ä»¶
        for ext in ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv', '.m4v']:
            vid_path = os.path.join(images_dir, f"segment_{i}{ext}")
            if os.path.exists(vid_path):
                image_paths.append(vid_path)
                break
    audio_paths = [os.path.join(voice_dir, f"voice_{i}.wav") for i in range(1, script_data.get('actual_segments', 0) + 1) if os.path.exists(os.path.join(voice_dir, f"voice_{i}.wav"))]

    # BGM
    bgm_audio_path = None
    if bgm_filename:
        candidate = os.path.join(project_root, "music", bgm_filename)
        if os.path.exists(candidate):
            bgm_audio_path = candidate

    # Opening assets
    opening_image_candidate = os.path.join(images_dir, "opening.png")
    opening_image_candidate = opening_image_candidate if os.path.exists(opening_image_candidate) else None
    opening_golden_quote = (script_data or {}).get("golden_quote", "")
    opening_narration_audio_path = None
    try:
        if opening_quote and isinstance(opening_golden_quote, str) and opening_golden_quote.strip():
            opening_narration_audio_path = os.path.join(voice_dir, "opening.wav")
            if not os.path.exists(opening_narration_audio_path):
                ok = text_to_audio_bytedance(opening_golden_quote, opening_narration_audio_path, voice=voice, encoding="wav")
                if not ok:
                    opening_narration_audio_path = None
    except Exception:
        opening_narration_audio_path = None

    composer = VideoComposer()
    final_video_path = composer.compose_video(
        image_paths, audio_paths, f"{project_output_dir}/final_video.mp4",
        script_data=script_data, enable_subtitles=enable_subtitles,
        bgm_audio_path=bgm_audio_path,
        opening_image_path=opening_image_candidate,
        opening_golden_quote=opening_golden_quote,
        opening_narration_audio_path=opening_narration_audio_path,
        bgm_volume=float(getattr(config, "BGM_DEFAULT_VOLUME", 0.2)),
        narration_volume=float(getattr(config, "NARRATION_DEFAULT_VOLUME", 1.0)),
        image_size=image_size,
        opening_quote=opening_quote,
    )

    return {"success": True, "final_video": final_video_path}


__all__ += [
    "run_step_1",
    "run_step_1_5",
    "run_step_2",
    "run_step_3",
    "run_step_4",
    "run_step_5",
]


