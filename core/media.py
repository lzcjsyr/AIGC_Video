"""
Media-related logic: opening image, images per segment, and TTS synthesis.
"""

from typing import Optional, Dict, Any, List
import os
import concurrent.futures
import threading

from config import config
from prompts import OPENING_IMAGE_STYLES
from utils import logger, ensure_directory_exists
from core.services import text_to_image_doubao, text_to_audio_bytedance
from prompts import IMAGE_STYLE_PRESETS

import requests


def _download_to_path(url: str, output_path: str, error_msg: str = "ä¸‹è½½å¤±è´¥") -> None:
    try:
        resp = requests.get(url, timeout=30)
        resp.raise_for_status()
        with open(output_path, 'wb') as f:
            f.write(resp.content)
    except Exception as e:
        raise ValueError(f"{error_msg}: {e}")


def generate_opening_image(model: str, opening_style: str,
                           image_size: str, output_dir: str, opening_quote: bool = True) -> Optional[str]:
    """
    ç”Ÿæˆå¼€åœºå›¾åƒï¼Œä½¿ç”¨é¢„è®¾é£æ ¼ã€‚
    """
    if not opening_quote:
        return None
    try:
        prompt = OPENING_IMAGE_STYLES.get(opening_style)
        if not prompt:
            default_style = next(iter(OPENING_IMAGE_STYLES))
            logger.warning(f"æœªæ‰¾åˆ°å¼€åœºå›¾åƒé£æ ¼: {opening_style}ï¼Œä½¿ç”¨é»˜è®¤é£æ ¼: {default_style}")
            prompt = OPENING_IMAGE_STYLES[default_style]
        prompt = str(prompt).strip()

        image_url = text_to_image_doubao(
            prompt=prompt,
            size=image_size,
            model=model
        )

        if not image_url:
            raise ValueError("å¼€åœºå›¾åƒç”Ÿæˆå¤±è´¥")

        ensure_directory_exists(output_dir)
        image_path = os.path.join(output_dir, "opening.png")
        _download_to_path(image_url, image_path, error_msg="å¼€åœºå›¾åƒä¸‹è½½å¤±è´¥")
        logger.info(f"å¼€åœºå›¾åƒå·²ä¿å­˜: {image_path} (é£æ ¼: {opening_style})")
        print(f"å¼€åœºå›¾åƒå·²ä¿å­˜: {image_path}")
        return image_path
    except Exception as e:
        logger.warning(f"å¼€åœºå›¾åƒç”Ÿæˆå¤±è´¥: {e}")
        return None


def _generate_single_image(args) -> Dict[str, Any]:
    """
    ç”Ÿæˆå•ä¸ªå›¾åƒçš„è¾…åŠ©å‡½æ•°ï¼ˆç”¨äºå¤šçº¿ç¨‹ï¼‰
    """
    segment_index, keywords, atmosphere, image_style, model, image_size, output_dir = args
    
    style_part = f"[é£æ ¼] {image_style}" if image_style else ""
    content_parts: List[str] = []
    content_parts.extend(keywords)
    content_parts.extend(atmosphere)
    content_part = f"[å†…å®¹] {' | '.join(content_parts)}" if content_parts else ""
    prompt_sections = [part for part in [style_part, content_part] if part]
    final_prompt = "\n".join(prompt_sections)

    print(f"æ­£åœ¨ç”Ÿæˆç¬¬{segment_index}æ®µå›¾åƒ...")
    logger.debug(f"ç¬¬{segment_index}æ®µå›¾åƒæç¤ºè¯: {final_prompt}")

    for attempt in range(3):
        try:
            image_url = text_to_image_doubao(
                prompt=final_prompt,
                size=image_size,
                model=model
            )
            if image_url:
                image_path = os.path.join(output_dir, f"segment_{segment_index}.png")
                _download_to_path(image_url, image_path, error_msg=f"ä¸‹è½½ç¬¬{segment_index}æ®µå›¾åƒå¤±è´¥")
                print(f"ç¬¬{segment_index}æ®µå›¾åƒå·²ä¿å­˜: {image_path}")
                logger.info(f"ç¬¬{segment_index}æ®µå›¾åƒç”ŸæˆæˆåŠŸ: {image_path}")
                return {"success": True, "segment_index": segment_index, "image_path": image_path}
            else:
                if attempt < 2:
                    logger.warning(f"ç¬¬{segment_index}æ®µå›¾åƒç”Ÿæˆå¤±è´¥ï¼Œå‡†å¤‡é‡è¯•ï¼ˆç¬¬{attempt + 2}/3æ¬¡ï¼‰")
                    continue
        except Exception as e:
            error_msg = str(e)
            is_sensitive_error = (
                "OutputImageSensitiveContentDetected" in error_msg or
                "sensitive" in error_msg.lower() or
                "content" in error_msg.lower()
            )
            if attempt < 2:
                if is_sensitive_error:
                    logger.warning(f"ç¬¬{segment_index}æ®µå›¾åƒæ¶‰åŠæ•æ„Ÿå†…å®¹ï¼Œå‡†å¤‡é‡è¯•ï¼ˆç¬¬{attempt + 2}/3æ¬¡ï¼‰")
                else:
                    logger.warning(f"ç¬¬{segment_index}æ®µå›¾åƒç”Ÿæˆå¤±è´¥ï¼š{error_msg}ï¼Œå‡†å¤‡é‡è¯•ï¼ˆç¬¬{attempt + 2}/3æ¬¡ï¼‰")
                continue
            else:
                if is_sensitive_error:
                    logger.warning(f"ç¬¬{segment_index}æ®µå›¾åƒç”Ÿæˆå¤±è´¥ï¼ˆæ•æ„Ÿå†…å®¹ï¼‰ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯ï¼š{error_msg}")
                else:
                    logger.warning(f"ç¬¬{segment_index}æ®µå›¾åƒç”Ÿæˆå¤±è´¥ï¼Œå·²è·³è¿‡ã€‚é”™è¯¯ï¼š{error_msg}")
                print(f"ç¬¬{segment_index}æ®µå›¾åƒç”Ÿæˆå¤±è´¥ï¼Œå·²è·³è¿‡")
    
    return {"success": False, "segment_index": segment_index, "image_path": ""}


def generate_images_for_segments(model: str, keywords_data: Dict[str, Any],
                                 image_style_preset: str, image_size: str, output_dir: str) -> Dict[str, Any]:
    """
    ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆå›¾åƒï¼ˆæ”¯æŒå¤šçº¿ç¨‹å¹¶å‘ï¼‰
    """
    try:
        try:
            image_style = IMAGE_STYLE_PRESETS.get(
                image_style_preset,
                next(iter(IMAGE_STYLE_PRESETS.values()))
            )
        except Exception:
            image_style = ""
        logger.info(f"ä½¿ç”¨å›¾åƒé£æ ¼: {image_style_preset} -> {image_style}")

        # å‡†å¤‡å¹¶å‘ä»»åŠ¡å‚æ•°
        task_args = []
        for i, segment_keywords in enumerate(keywords_data["segments"], 1):
            keywords = segment_keywords.get("keywords", [])
            atmosphere = segment_keywords.get("atmosphere", [])
            task_args.append((i, keywords, atmosphere, image_style, model, image_size, output_dir))

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘ç”Ÿæˆå›¾åƒ
        max_workers = getattr(config, "MAX_CONCURRENT_IMAGE_GENERATION", 3)
        print(f"ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹ç”Ÿæˆå›¾åƒ...")
        
        image_paths: List[str] = [""] * len(task_args)  # é¢„åˆ†é…ä½ç½®
        failed_segments: List[int] = []
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {executor.submit(_generate_single_image, args): args[0] for args in task_args}
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            for future in concurrent.futures.as_completed(future_to_index):
                result = future.result()
                segment_index = result["segment_index"]
                if result["success"]:
                    image_paths[segment_index - 1] = result["image_path"]
                else:
                    failed_segments.append(segment_index)
                    image_paths[segment_index - 1] = ""

        return {
            "image_paths": image_paths,
            "failed_segments": failed_segments
        }

    except Exception as e:
        raise ValueError(f"å›¾åƒç”Ÿæˆé”™è¯¯: {e}")


def _synthesize_single_voice(args) -> Dict[str, Any]:
    """
    åˆæˆå•ä¸ªè¯­éŸ³çš„è¾…åŠ©å‡½æ•°ï¼ˆç”¨äºå¤šçº¿ç¨‹ï¼‰
    """
    segment_index, content, server, voice, output_dir = args
    
    print(f"æ­£åœ¨ç”Ÿæˆç¬¬{segment_index}æ®µè¯­éŸ³...")
    
    audio_filename = f"voice_{segment_index}.wav"
    audio_path = os.path.join(output_dir, audio_filename)
    
    try:
        if server == "bytedance":
            success = text_to_audio_bytedance(
                text=content,
                output_filename=audio_path,
                voice=voice
            )
        else:
            return {"success": False, "segment_index": segment_index, "error": f"ä¸æ”¯æŒçš„TTSæœåŠ¡å•†: {server}"}
        
        if success:
            print(f"ç¬¬{segment_index}æ®µè¯­éŸ³å·²ä¿å­˜: {audio_path}")
            return {"success": True, "segment_index": segment_index, "audio_path": audio_path}
        else:
            return {"success": False, "segment_index": segment_index, "error": f"ç”Ÿæˆç¬¬{segment_index}æ®µè¯­éŸ³å¤±è´¥"}
    
    except Exception as e:
        return {"success": False, "segment_index": segment_index, "error": str(e)}


def synthesize_voice_for_segments(server: str, voice: str, script_data: Dict[str, Any], output_dir: str) -> List[str]:
    """
    ä¸ºæ¯ä¸ªæ®µè½åˆæˆè¯­éŸ³ï¼ˆæ”¯æŒå¤šçº¿ç¨‹å¹¶å‘ï¼‰
    """
    try:
        # å‡†å¤‡å¹¶å‘ä»»åŠ¡å‚æ•°
        task_args = []
        for segment in script_data["segments"]:
            segment_index = segment["index"]
            content = segment["content"]
            task_args.append((segment_index, content, server, voice, output_dir))

        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘åˆæˆè¯­éŸ³
        max_workers = getattr(config, "MAX_CONCURRENT_VOICE_SYNTHESIS", 2)
        print(f"ä½¿ç”¨ {max_workers} ä¸ªå¹¶å‘çº¿ç¨‹åˆæˆè¯­éŸ³...")
        
        audio_paths: List[str] = [""] * len(task_args)  # é¢„åˆ†é…ä½ç½®
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_index = {executor.submit(_synthesize_single_voice, args): args[0] for args in task_args}
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            for future in concurrent.futures.as_completed(future_to_index):
                result = future.result()
                segment_index = result["segment_index"]
                if result["success"]:
                    audio_paths[segment_index - 1] = result["audio_path"]
                else:
                    error_msg = result.get("error", f"ç”Ÿæˆç¬¬{segment_index}æ®µè¯­éŸ³å¤±è´¥")
                    raise ValueError(error_msg)

        # è¯­éŸ³åˆæˆå®Œæˆåï¼Œç«‹å³å¯¼å‡ºSRTå­—å¹•æ–‡ä»¶
        print("ğŸ¬ å¼€å§‹å¯¼å‡ºSRTå­—å¹•æ–‡ä»¶...")
        try:
            srt_path = export_srt_subtitles(script_data, audio_paths, output_dir)
            print(f"âœ… SRTå­—å¹•å·²ä¿å­˜: {srt_path}")
        except Exception as e:
            print(f"âš ï¸ SRTå­—å¹•å¯¼å‡ºå¤±è´¥: {e}")  # éå…³é”®åŠŸèƒ½ï¼Œå¤±è´¥ä¸ä¸­æ–­æµç¨‹

        return audio_paths

    except Exception as e:
        raise ValueError(f"è¯­éŸ³åˆæˆé”™è¯¯: {e}")


def export_srt_subtitles(script_data: Dict[str, Any], audio_paths: List[str], voice_dir: str) -> str:
    """
    å¯¼å‡ºSRTå­—å¹•æ–‡ä»¶åˆ°voiceæ–‡ä»¶å¤¹
    
    Args:
        script_data: è„šæœ¬æ•°æ®
        audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        voice_dir: voiceæ–‡ä»¶å¤¹è·¯å¾„
    
    Returns:
        str: SRTæ–‡ä»¶è·¯å¾„
    """
    from moviepy import AudioFileClip
    from core.video_composer import VideoComposer
    
    try:
        # è·å–å®é™…éŸ³é¢‘æ—¶é•¿
        segment_durations = []
        for audio_path in audio_paths:
            if os.path.exists(audio_path):
                clip = AudioFileClip(audio_path)
                segment_durations.append(float(clip.duration))
                clip.close()
            else:
                segment_durations.append(0.0)
        
        # å¤ç”¨VideoComposerçš„å­—å¹•åˆ†å‰²é€»è¾‘
        composer = VideoComposer()
        subtitle_config = config.SUBTITLE_CONFIG.copy()
        
        # ç”ŸæˆSRTå†…å®¹
        srt_lines = []
        subtitle_index = 1
        current_time = 0.0
        
        for i, segment in enumerate(script_data["segments"]):
            content = segment["content"]
            duration = segment_durations[i] if i < len(segment_durations) else 0.0
            
            # åˆ†å‰²æ–‡æœ¬
            subtitle_texts = composer.split_text_for_subtitle(
                content,
                subtitle_config["max_chars_per_line"],
                subtitle_config["max_lines"]
            )
            
            # è®¡ç®—æ¯è¡Œæ—¶é•¿
            if len(subtitle_texts) == 0:
                continue
                
            line_durations = []
            if len(subtitle_texts) == 1:
                line_durations = [duration]
            else:
                lengths = [max(1.0, len(t)) for t in subtitle_texts]
                total_len = sum(lengths)
                acc = 0.0
                for idx, length in enumerate(lengths):
                    if idx < len(lengths) - 1:
                        d = duration * (length / total_len)
                        line_durations.append(d)
                        acc += d
                    else:
                        line_durations.append(max(0.0, duration - acc))
            
            # ç”ŸæˆSRTæ¡ç›®
            for subtitle_text, subtitle_duration in zip(subtitle_texts, line_durations):
                start_time = current_time
                end_time = current_time + subtitle_duration
                
                # SRTæ—¶é—´æ ¼å¼
                start_srt = _format_srt_time(start_time)
                end_srt = _format_srt_time(end_time)
                
                srt_lines.append(f"{subtitle_index}")
                srt_lines.append(f"{start_srt} --> {end_srt}")
                srt_lines.append(subtitle_text.strip())
                srt_lines.append("")
                
                subtitle_index += 1
                current_time = end_time
        
        # å†™å…¥SRTæ–‡ä»¶
        project_name = os.path.basename(voice_dir.rstrip('/').rstrip('\\'))
        if project_name == "voice":
            project_name = os.path.basename(os.path.dirname(voice_dir.rstrip('/').rstrip('\\')))
        
        srt_filename = f"{project_name}_subtitles.srt"
        srt_path = os.path.join(voice_dir, srt_filename)
        
        with open(srt_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(srt_lines))
        
        return srt_path
        
    except Exception as e:
        raise ValueError(f"SRTå­—å¹•å¯¼å‡ºé”™è¯¯: {e}")


def _format_srt_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´ä¸ºSRTæ ¼å¼ (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millisecs = int((seconds % 1) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"


