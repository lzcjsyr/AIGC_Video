"""
è§†é¢‘åˆæˆå™¨ - ç»Ÿä¸€çš„è§†é¢‘åˆæˆå¤„ç†æ¨¡å—ï¼ˆè¿ç§»è‡³ coreï¼‰
æ•´åˆè§†é¢‘åˆæˆã€å­—å¹•ç”Ÿæˆã€éŸ³é¢‘æ··åˆç­‰åŠŸèƒ½
"""

import os
import re
import numpy as np
from typing import List, Dict, Any, Optional, Tuple

# MoviePy 2.x imports (no editor module)
from moviepy import (
    ImageClip,
    TextClip,
    ColorClip,
    CompositeVideoClip,
    CompositeAudioClip,
    concatenate_videoclips,
    AudioFileClip,
    concatenate_audioclips,
)

from config import config
from utils import logger, FileProcessingError
from prompts import IMAGE_STYLE_PRESETS as IMAGE_STYLE_PRESETS_PROMPTS


class VideoComposer:
    """ç»Ÿä¸€çš„è§†é¢‘åˆæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§†é¢‘åˆæˆå™¨"""
        pass
    
    def compose_video(self, image_paths: List[str], audio_paths: List[str], output_path: str, 
                     script_data: Dict[str, Any] = None, enable_subtitles: bool = False,
                     bgm_audio_path: Optional[str] = None, bgm_volume: float = 0.15,
                     narration_volume: float = 1.0,
                     opening_image_path: Optional[str] = None,
                     opening_golden_quote: Optional[str] = None,
                     opening_narration_audio_path: Optional[str] = None) -> str:
        """
        åˆæˆæœ€ç»ˆè§†é¢‘
        
        Args:
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨  
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            script_data: è„šæœ¬æ•°æ®ï¼Œç”¨äºç”Ÿæˆå­—å¹•
            enable_subtitles: æ˜¯å¦å¯ç”¨å­—å¹•
            bgm_audio_path: èƒŒæ™¯éŸ³ä¹è·¯å¾„
            bgm_volume: èƒŒæ™¯éŸ³ä¹éŸ³é‡
            narration_volume: å£æ’­éŸ³é‡
            opening_image_path: å¼€åœºå›¾ç‰‡è·¯å¾„
            opening_golden_quote: å¼€åœºé‡‘å¥
            opening_narration_audio_path: å¼€åœºå£æ’­éŸ³é¢‘è·¯å¾„
        
        Returns:
            str: è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        try:
            if len(image_paths) != len(audio_paths):
                raise ValueError("å›¾åƒæ–‡ä»¶æ•°é‡ä¸éŸ³é¢‘æ–‡ä»¶æ•°é‡ä¸åŒ¹é…")
            
            video_clips = []
            audio_clips = []
            
            # åˆ›å»ºå¼€åœºç‰‡æ®µ
            opening_seconds = self._create_opening_segment(
                opening_image_path, opening_golden_quote, 
                opening_narration_audio_path, video_clips
            )
            
            # åˆ›å»ºä¸»è¦è§†é¢‘ç‰‡æ®µ
            self._create_main_segments(image_paths, audio_paths, video_clips, audio_clips)
            
            # è¿æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
            print("æ­£åœ¨åˆæˆæœ€ç»ˆè§†é¢‘...")
            final_video = concatenate_videoclips(video_clips, method="compose")
            
            # æ·»åŠ å­—å¹•
            final_video = self._add_subtitles(final_video, script_data, enable_subtitles, 
                                            audio_clips, opening_seconds)
            
            # è°ƒæ•´å£æ’­éŸ³é‡
            final_video = self._adjust_narration_volume(final_video, narration_volume)
            
            # æ·»åŠ è§†è§‰æ•ˆæœ
            final_video = self._add_visual_effects(final_video, image_paths)
            
            # æ·»åŠ èƒŒæ™¯éŸ³ä¹
            final_video = self._add_background_music(final_video, bgm_audio_path, bgm_volume)
            
            # è¾“å‡ºè§†é¢‘
            self._export_video(final_video, output_path)
            
            # é‡Šæ”¾èµ„æº
            self._cleanup_resources(video_clips, audio_clips, final_video)
            
            print(f"æœ€ç»ˆè§†é¢‘å·²ä¿å­˜: {output_path}")
            return output_path
            
        except Exception as e:
            raise ValueError(f"è§†é¢‘åˆæˆé”™è¯¯: {e}")
    
    def _create_opening_segment(self, opening_image_path: Optional[str], 
                              opening_golden_quote: Optional[str],
                              opening_narration_audio_path: Optional[str], 
                              video_clips: List) -> float:
        """åˆ›å»ºå¼€åœºç‰‡æ®µ"""
        opening_seconds = 0.0
        opening_voice_clip = None
        
        # è®¡ç®—å¼€åœºæ—¶é•¿
        try:
            if opening_narration_audio_path and os.path.exists(opening_narration_audio_path):
                opening_voice_clip = AudioFileClip(opening_narration_audio_path)
                hold_after = float(getattr(config, "OPENING_HOLD_AFTER_NARRATION_SECONDS", 2.0))
                opening_seconds = float(opening_voice_clip.duration) + max(0.0, hold_after)
        except Exception as e:
            logger.warning(f"å¼€åœºå£æ’­éŸ³é¢‘åŠ è½½å¤±è´¥: {e}ï¼Œå°†é€€å›å›ºå®šæ—¶é•¿å¼€åœº")
            opening_voice_clip = None
        
        if opening_image_path and os.path.exists(opening_image_path) and opening_seconds > 1e-3:
            try:
                print("æ­£åœ¨åˆ›å»ºå¼€åœºç‰‡æ®µâ€¦")
                opening_base = ImageClip(opening_image_path).with_duration(opening_seconds)
                
                # æ·»åŠ å¼€åœºé‡‘å¥
                if opening_golden_quote and opening_golden_quote.strip():
                    opening_clip = self._add_opening_quote(opening_base, opening_golden_quote, opening_seconds)
                else:
                    opening_clip = opening_base
                
                # ç»‘å®šå¼€åœºéŸ³é¢‘
                if opening_voice_clip is not None:
                    try:
                        opening_clip = opening_clip.with_audio(opening_voice_clip)
                    except Exception as e:
                        logger.warning(f"ä¸ºå¼€åœºç‰‡æ®µç»‘å®šéŸ³é¢‘å¤±è´¥: {e}")
                
                # æ·»åŠ æ¸éšæ•ˆæœ
                opening_clip = self._add_opening_fade_effect(opening_clip, opening_voice_clip, opening_seconds)
                
                video_clips.append(opening_clip)
                
            except Exception as e:
                logger.warning(f"å¼€åœºç‰‡æ®µç”Ÿæˆå¤±è´¥: {e}ï¼Œå°†è·³è¿‡å¼€åœº")
        
        return opening_seconds
    
    def _add_opening_quote(self, opening_base, opening_golden_quote: str, opening_seconds: float):
        """æ·»åŠ å¼€åœºé‡‘å¥æ–‡å­—å åŠ """
        subtitle_config = config.SUBTITLE_CONFIG.copy()
        resolved_font = self.resolve_font_path(subtitle_config.get("font_family"))
        
        quote_style = getattr(config, "OPENING_QUOTE_STYLE", {}) or {}
        base_font = int(config.SUBTITLE_CONFIG.get("font_size", 36))
        scale = float(quote_style.get("font_scale", 1.3))
        font_size = int(quote_style.get("font_size", base_font * scale))
        text_color = quote_style.get("color", config.SUBTITLE_CONFIG.get("color", "white"))
        stroke_color = quote_style.get("stroke_color", config.SUBTITLE_CONFIG.get("stroke_color", "black"))
        stroke_width = int(quote_style.get("stroke_width", max(3, int(config.SUBTITLE_CONFIG.get("stroke_width", 3)))))
        pos = quote_style.get("position", ("center", "center"))
        
        # å¤„ç†æ–‡å­—æ¢è¡Œ
        try:
            max_chars = int(quote_style.get("max_chars_per_line", 18))
            max_q_lines = int(quote_style.get("max_lines", 4))
            candidate_lines = self.split_text_for_subtitle(opening_golden_quote, max_chars, max_q_lines)
            wrapped_quote = "\n".join(candidate_lines[:max_q_lines]) if candidate_lines else opening_golden_quote
        except Exception:
            wrapped_quote = opening_golden_quote
        
        # åˆ›å»ºæ–‡å­—å‰ªè¾‘
        text_clip = TextClip(
            text=wrapped_quote,
            font_size=font_size,
            color=text_color,
            font=resolved_font or config.SUBTITLE_CONFIG.get("font_family"),
            stroke_color=stroke_color,
            stroke_width=stroke_width
        ).with_position(pos).with_duration(opening_seconds)
        
        return CompositeVideoClip([opening_base, text_clip])
    
    def _add_opening_fade_effect(self, opening_clip, opening_voice_clip, opening_seconds: float):
        """æ·»åŠ å¼€åœºæ¸éšæ•ˆæœ"""
        try:
            if opening_voice_clip is not None:
                hold_after = float(getattr(config, "OPENING_HOLD_AFTER_NARRATION_SECONDS", 2.0))
                if hold_after > 1e-3:
                    voice_duration = float(opening_voice_clip.duration)
                    fade_start_time = voice_duration
                    fade_duration = hold_after
                    
                    def _opening_fade_out(gf, t):
                        try:
                            if t < fade_start_time:
                                return gf(t)
                            elif t >= opening_seconds:
                                return 0.0 * gf(t)
                            else:
                                fade_progress = (t - fade_start_time) / fade_duration
                                alpha = max(0.0, 1.0 - fade_progress)
                                return alpha * gf(t)
                        except Exception:
                            return gf(t)
                    
                    opening_clip = opening_clip.transform(_opening_fade_out, keep_duration=True)
                    print(f"ğŸ¬ å·²ä¸ºå¼€åœºç‰‡æ®µæ·»åŠ {hold_after}sæ¸éšæ•ˆæœ")
        except Exception as e:
            logger.warning(f"å¼€åœºç‰‡æ®µæ¸éšæ•ˆæœæ·»åŠ å¤±è´¥: {e}")
        
        return opening_clip
    
    def _create_main_segments(self, image_paths: List[str], audio_paths: List[str], 
                            video_clips: List, audio_clips: List):
        """åˆ›å»ºä¸»è¦è§†é¢‘ç‰‡æ®µ"""
        for i, (image_path, audio_path) in enumerate(zip(image_paths, audio_paths)):
            print(f"æ­£åœ¨å¤„ç†ç¬¬{i+1}æ®µè§†é¢‘...")
            
            # åŠ è½½éŸ³é¢‘è·å–æ—¶é•¿
            audio_clip = AudioFileClip(audio_path)
            duration = audio_clip.duration
            
            # åˆ›å»ºå›¾åƒå‰ªè¾‘
            image_clip = ImageClip(image_path).with_duration(duration)
            
            # ç»„åˆå›¾åƒå’ŒéŸ³é¢‘
            video_clip = image_clip.with_audio(audio_clip)
            video_clips.append(video_clip)
            audio_clips.append(audio_clip)
    
    def _add_subtitles(self, final_video, script_data: Dict[str, Any], enable_subtitles: bool, 
                      audio_clips: List, opening_seconds: float):
        """æ·»åŠ å­—å¹•"""
        effective_subtitles = bool(enable_subtitles) and bool(getattr(config, "SUBTITLE_CONFIG", {}).get("enabled", True))
        if effective_subtitles and script_data:
            print("æ­£åœ¨æ·»åŠ å­—å¹•...")
            try:
                subtitle_config = config.SUBTITLE_CONFIG.copy()
                subtitle_config["video_size"] = final_video.size
                subtitle_config["segment_durations"] = [ac.duration for ac in audio_clips]
                subtitle_config["offset_seconds"] = opening_seconds
                subtitle_clips = self.create_subtitle_clips(script_data, subtitle_config)
                
                if subtitle_clips:
                    final_video = CompositeVideoClip([final_video] + subtitle_clips)
                    print(f"å·²æ·»åŠ  {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
                else:
                    print("æœªç”Ÿæˆä»»ä½•å­—å¹•å‰ªè¾‘")
            except Exception as e:
                logger.warning(f"æ·»åŠ å­—å¹•å¤±è´¥: {str(e)}ï¼Œç»§ç»­ç”Ÿæˆæ— å­—å¹•è§†é¢‘")
        
        return final_video
    
    def _adjust_narration_volume(self, final_video, narration_volume: float):
        """è°ƒæ•´å£æ’­éŸ³é‡"""
        try:
            if final_video.audio is not None and narration_volume is not None:
                narration_audio = final_video.audio
                if isinstance(narration_volume, (int, float)) and abs(float(narration_volume) - 1.0) > 1e-9:
                    try:
                        # MoviePy 1.x
                        narration_audio = narration_audio.volumex(float(narration_volume))
                    except Exception:
                        try:
                            # MoviePy 2.x unified transform
                            narration_audio = narration_audio.transform(lambda gf, t: float(narration_volume) * gf(t), keep_duration=True)
                        except Exception:
                            pass
                    final_video = final_video.with_audio(narration_audio)
                    print(f"ğŸ”Š å£æ’­éŸ³é‡è°ƒæ•´ä¸º: {float(narration_volume)}")
        except Exception as e:
            logger.warning(f"å£æ’­éŸ³é‡è°ƒæ•´å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨åŸå§‹éŸ³é‡")
        
        return final_video
    
    def _add_visual_effects(self, final_video, image_paths: List[str]):
        """æ·»åŠ è§†è§‰æ•ˆæœï¼ˆå¼€åœºæ¸æ˜¾å’Œç‰‡å°¾æ¸éšï¼‰"""
        # å¼€åœºæ¸æ˜¾
        try:
            fade_in_seconds = float(getattr(config, "OPENING_FADEIN_SECONDS", 0.0))
            if fade_in_seconds > 1e-3:
                def _fade_in_frame(gf, t):
                    try:
                        alpha = min(1.0, max(0.0, float(t) / float(fade_in_seconds)))
                    except Exception:
                        alpha = 1.0
                    return alpha * gf(t)
                
                final_video = final_video.transform(_fade_in_frame, keep_duration=True)
                print(f"ğŸ¬ å·²æ·»åŠ å¼€åœºæ¸æ˜¾ {fade_in_seconds}s")
        except Exception as e:
            logger.warning(f"å¼€åœºæ¸æ˜¾æ•ˆæœæ·»åŠ å¤±è´¥: {e}")
        
        # ç‰‡å°¾æ¸éš
        try:
            tail_seconds = float(getattr(config, "ENDING_FADE_SECONDS", 2.5))
            if isinstance(image_paths, list) and len(image_paths) > 0 and tail_seconds > 1e-3:
                last_image_path = image_paths[-1]
                tail_clip = ImageClip(last_image_path).with_duration(tail_seconds)
                
                def _fade_frame(gf, t):
                    try:
                        alpha = max(0.0, 1.0 - float(t) / float(tail_seconds))
                    except Exception:
                        alpha = 0.0
                    return alpha * gf(t)
                
                tail_clip = tail_clip.transform(_fade_frame, keep_duration=True)
                final_video = concatenate_videoclips([final_video, tail_clip], method="compose")
                print(f"ğŸ¬ å·²æ·»åŠ ç‰‡å°¾é™å¸§ {tail_seconds}s å¹¶æ¸éš")
        except Exception as e:
            logger.warning(f"ç‰‡å°¾é™å¸§æ·»åŠ å¤±è´¥: {e}")
        
        return final_video
    
    def _add_background_music(self, final_video, bgm_audio_path: Optional[str], bgm_volume: float):
        """æ·»åŠ èƒŒæ™¯éŸ³ä¹"""
        if not bgm_audio_path or not os.path.exists(bgm_audio_path):
            if bgm_audio_path:
                print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ä¸å­˜åœ¨: {bgm_audio_path}")
            else:
                print("â„¹ï¸ æœªæŒ‡å®šèƒŒæ™¯éŸ³ä¹æ–‡ä»¶")
            return final_video
        
        try:
            print(f"ğŸµ å¼€å§‹å¤„ç†èƒŒæ™¯éŸ³ä¹: {bgm_audio_path}")
            bgm_clip = AudioFileClip(bgm_audio_path)
            print(f"ğŸµ BGMåŠ è½½æˆåŠŸï¼Œæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
            
            # è°ƒæ•´BGMéŸ³é‡
            if isinstance(bgm_volume, (int, float)) and abs(float(bgm_volume) - 1.0) > 1e-9:
                try:
                    bgm_clip = bgm_clip.volumex(float(bgm_volume))
                except Exception:
                    try:
                        bgm_clip = bgm_clip.transform(lambda gf, t: float(bgm_volume) * gf(t), keep_duration=True)
                    except Exception:
                        pass
                print(f"ğŸµ BGMéŸ³é‡è°ƒæ•´ä¸º: {float(bgm_volume)}")
            
            # è°ƒæ•´BGMé•¿åº¦
            bgm_clip = self._adjust_bgm_duration(bgm_clip, final_video.duration)
            
            if bgm_clip is not None:
                # åº”ç”¨éŸ³é¢‘æ•ˆæœ
                bgm_clip = self._apply_audio_effects(bgm_clip, final_video)
                
                # åˆæˆéŸ³é¢‘
                if final_video.audio is not None:
                    mixed_audio = CompositeAudioClip([final_video.audio, bgm_clip])
                    print("ğŸµ BGMä¸å£æ’­éŸ³é¢‘åˆæˆå®Œæˆ")
                else:
                    mixed_audio = CompositeAudioClip([bgm_clip])
                    print("ğŸµ ä»…æ·»åŠ BGMéŸ³é¢‘ï¼ˆæ— å£æ’­éŸ³é¢‘ï¼‰")
                
                final_video = final_video.with_audio(mixed_audio)
                print("ğŸµ èƒŒæ™¯éŸ³ä¹æ·»åŠ æˆåŠŸï¼")
        
        except Exception as e:
            print(f"âŒ èƒŒæ™¯éŸ³ä¹å¤„ç†å¼‚å¸¸: {str(e)}")
            logger.warning(f"èƒŒæ™¯éŸ³ä¹å¤„ç†å¤±è´¥: {str(e)}ï¼Œå°†ç»§ç»­ç”Ÿæˆæ— èƒŒæ™¯éŸ³ä¹çš„è§†é¢‘")
        
        return final_video
    
    def _adjust_bgm_duration(self, bgm_clip, target_duration: float):
        """è°ƒæ•´BGMæ—¶é•¿ï¼šä¼˜å…ˆæ‰‹åŠ¨å¹³é“ºå¾ªç¯ï¼Œå§‹ç»ˆé“ºæ»¡å¹¶è£å‰ªåˆ°ç›®æ ‡æ—¶é•¿"""
        try:
            print(f"ğŸµ è§†é¢‘æ€»æ—¶é•¿: {target_duration:.2f}ç§’ï¼ŒBGMæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")

            # åŸºæœ¬æ ¡éªŒ
            if target_duration <= 0:
                return bgm_clip
            unit_duration = float(bgm_clip.duration)
            if unit_duration <= 1e-6:
                raise RuntimeError("BGMæºæ—¶é•¿ä¸º0")

            # è‹¥BGMé•¿äºç›®æ ‡ï¼Œç›´æ¥è£å‰ª
            if unit_duration >= target_duration - 1e-6:
                try:
                    return bgm_clip.with_duration(target_duration)
                except Exception:
                    # å…œåº•ï¼šå­ç‰‡æ®µè£å‰ª
                    return bgm_clip.subclip(0, target_duration)

            # æ‰‹åŠ¨å¹³é“ºï¼šé‡å¤æ‹¼æ¥ + æœ«æ®µç²¾ç¡®è£å‰ª
            clips = []
            accumulated = 0.0
            # å…ˆæ•´æ®µé‡å¤
            while accumulated + unit_duration <= target_duration - 1e-6:
                clips.append(bgm_clip.subclip(0, unit_duration))
                accumulated += unit_duration
            # æœ«æ®µè£å‰ª
            remaining = max(0.0, target_duration - accumulated)
            if remaining > 1e-6:
                clips.append(bgm_clip.subclip(0, remaining))

            looped = concatenate_audioclips(clips)
            print(f"ğŸµ BGMé•¿åº¦é€‚é…å®Œæˆï¼ˆmanual loopï¼‰ï¼Œæœ€ç»ˆæ—¶é•¿: {looped.duration:.2f}ç§’")
            return looped

        except Exception as e:
            print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹é•¿åº¦é€‚é…å¤±è´¥: {e}ï¼Œå°†ä¸æ·»åŠ BGMç»§ç»­ç”Ÿæˆ")
            logger.warning(f"èƒŒæ™¯éŸ³ä¹å¾ªç¯/è£å‰ªå¤±è´¥: {e}")
            return None
    
    def _apply_audio_effects(self, bgm_clip, final_video):
        """åº”ç”¨éŸ³é¢‘æ•ˆæœï¼ˆDuckingå’Œæ·¡å‡ºï¼‰"""
        # è‡ªåŠ¨Ducking
        if getattr(config, "AUDIO_DUCKING_ENABLED", False) and final_video.audio is not None:
            try:
                bgm_clip = self._apply_ducking_effect(bgm_clip, final_video)
            except Exception as e:
                logger.warning(f"è‡ªåŠ¨Duckingå¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æ’å®šéŸ³é‡BGM")
        
        # ç‰‡å°¾æ·¡å‡º
        try:
            total_dur = float(final_video.duration)
            fade_tail = float(getattr(config, "ENDING_FADE_SECONDS", 2.5))
            fade_gain = self._create_linear_fade_out_gain(total_dur, fade_tail)
            bgm_clip = bgm_clip.transform(
                lambda gf, t: ((fade_gain(t)[:, None]) if hasattr(t, "__len__") else fade_gain(t)) * gf(t),
                keep_duration=True,
            )
            print(f"ğŸšï¸ å·²æ·»åŠ BGMç‰‡å°¾{fade_tail}sæ·¡å‡º")
        except Exception as e:
            logger.warning(f"BGMæ·¡å‡ºåº”ç”¨å¤±è´¥: {e}")
        
        return bgm_clip
    
    def _apply_ducking_effect(self, bgm_clip, final_video):
        """åº”ç”¨è‡ªåŠ¨Duckingæ•ˆæœ"""
        strength = float(getattr(config, "AUDIO_DUCKING_STRENGTH", 0.7))
        smooth_sec = float(getattr(config, "AUDIO_DUCKING_SMOOTH_SECONDS", 0.12))
        total_dur = float(final_video.duration)
        
        # é‡‡æ ·é¢‘ç‡
        env_fps = 20.0
        num_samples = max(2, int(total_dur * env_fps) + 1)
        times = np.linspace(0.0, total_dur, num_samples)
        
        # ä¼°ç®—å£æ’­ç¬æ—¶å¹…åº¦
        amp = np.zeros_like(times)
        for i, t in enumerate(times):
            try:
                frame = final_video.audio.get_frame(float(min(max(0.0, t), total_dur - 1e-6)))
                amp[i] = float(np.mean(np.abs(frame)))
            except Exception:
                amp[i] = 0.0
        
        # å¹³æ»‘å¤„ç†
        win = max(1, int(smooth_sec * env_fps))
        if win > 1:
            kernel = np.ones(win, dtype=float) / win
            amp = np.convolve(amp, kernel, mode="same")
        
        # å½’ä¸€åŒ–
        max_amp = float(np.max(amp)) if np.max(amp) > 1e-8 else 1.0
        env = amp / max_amp
        
        # è®¡ç®—duckingå¢ç›Šæ›²çº¿
        gains = 1.0 - strength * env
        gains = np.clip(gains, 0.0, 1.0)
        
        # æ„å»ºæ—¶é—´å˜å¢ç›Šå‡½æ•°
        def _gain_lookup(t_any):
            def _lookup_scalar(ts: float) -> float:
                if ts <= 0.0:
                    return float(gains[0])
                if ts >= total_dur:
                    return float(gains[-1])
                idx = int(ts * env_fps)
                idx = max(0, min(idx, gains.shape[0] - 1))
                return float(gains[idx])
            
            if hasattr(t_any, "__len__"):
                return np.array([_lookup_scalar(float(ts)) for ts in t_any])
            return _lookup_scalar(float(t_any))
        
        # åº”ç”¨æ—¶é—´å˜å¢ç›Š
        bgm_clip = bgm_clip.transform(
            lambda gf, t: (
                (_gain_lookup(t)[:, None] if hasattr(t, "__len__") else _gain_lookup(t))
                * gf(t)
            ),
            keep_duration=True,
        )
        print(f"ğŸšï¸ å·²å¯ç”¨è‡ªåŠ¨Duckingï¼ˆstrength={strength}, smooth={smooth_sec}sï¼‰")
        
        return bgm_clip
    
    def _create_linear_fade_out_gain(self, total: float, tail: float):
        """åˆ›å»ºçº¿æ€§æ·¡å‡ºå¢ç›Šå‡½æ•°"""
        cutoff = max(0.0, total - tail)
        
        def _gain_any(t_any):
            def _scalar(ts: float) -> float:
                if ts <= cutoff:
                    return 1.0
                if ts >= total:
                    return 0.0
                return max(0.0, 1.0 - (ts - cutoff) / tail)
            
            if hasattr(t_any, "__len__"):
                return np.array([_scalar(float(ts)) for ts in t_any])
            return _scalar(float(t_any))
        
        return _gain_any
    
    def _export_video(self, final_video, output_path: str):
        """å¯¼å‡ºè§†é¢‘"""
        moviepy_logger = 'bar'
        
        try:
            # ä¼˜å…ˆå°è¯•macOSç¡¬ä»¶ç¼–ç 
            final_video.write_videofile(
                output_path,
                fps=15,
                codec='h264_videotoolbox',
                audio_codec='aac',
                bitrate='5M',
                ffmpeg_params=['-pix_fmt', 'yuv420p', '-movflags', '+faststart'],
                logger=moviepy_logger
            )
        except Exception as e:
            print(f"âš ï¸ ç¡¬ä»¶ç¼–ç ä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œå›é€€åˆ°è½¯ä»¶ç¼–ç : {e}")
            # å›é€€åˆ°è½¯ä»¶ç¼–ç 
            final_video.write_videofile(
                output_path,
                fps=15,
                codec='libx264',
                audio_codec='aac',
                preset='veryfast',
                threads=os.cpu_count() or 4,
                ffmpeg_params=['-crf', '23', '-pix_fmt', 'yuv420p', '-movflags', '+faststart'],
                logger=moviepy_logger
            )
    
    def _cleanup_resources(self, video_clips: List, audio_clips: List, final_video):
        """é‡Šæ”¾èµ„æº"""
        for clip in video_clips:
            clip.close()
        for aclip in audio_clips:
            aclip.close()
        final_video.close()
    
    def create_subtitle_clips(self, script_data: Dict[str, Any], 
                            subtitle_config: Dict[str, Any] = None) -> List:
        """åˆ›å»ºå­—å¹•å‰ªè¾‘åˆ—è¡¨"""
        if subtitle_config is None:
            subtitle_config = config.SUBTITLE_CONFIG.copy()
        
        subtitle_clips = []
        current_time = float(subtitle_config.get("offset_seconds", 0.0))
        
        logger.info("å¼€å§‹åˆ›å»ºå­—å¹•å‰ªè¾‘...")
        
        # è§£æå­—ä½“
        resolved_font = self.resolve_font_path(subtitle_config.get("font_family"))
        if not resolved_font:
            logger.warning("æœªèƒ½è§£æåˆ°å¯ç”¨ä¸­æ–‡å­—ä½“")
        
        # è¯»å–è§†é¢‘å°ºå¯¸
        video_size = subtitle_config.get("video_size", (1280, 720))
        video_width, video_height = video_size
        
        segment_durations = subtitle_config.get("segment_durations", [])
        
        # æ ‡ç‚¹æ›¿æ¢æ¨¡å¼
        punctuation_pattern = r"[-.,!?;:\"ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šï¼ˆï¼‰()\[\]{}ã€ã€‘â€”â€¦â€“ã€]+"
        
        for i, segment in enumerate(script_data["segments"], 1):
            content = segment["content"]
            
            # è·å–æ—¶é•¿
            duration = None
            if isinstance(segment_durations, list) and len(segment_durations) >= i:
                duration = float(segment_durations[i-1])
            if duration is None:
                duration = float(segment.get("estimated_duration", 0))
            
            logger.debug(f"å¤„ç†ç¬¬{i}æ®µå­—å¹•ï¼Œæ—¶é•¿: {duration}ç§’")
            
            # åˆ†å‰²æ–‡æœ¬
            subtitle_texts = self.split_text_for_subtitle(
                content,
                subtitle_config["max_chars_per_line"],
                subtitle_config["max_lines"]
            )
            
            # è®¡ç®—æ¯è¡Œå­—å¹•æ—¶é•¿
            subtitle_start_time = current_time
            line_durations = self._calculate_subtitle_durations(subtitle_texts, duration)
            
            for subtitle_text, subtitle_duration in zip(subtitle_texts, line_durations):
                try:
                    # å¤„ç†æ ‡ç‚¹
                    display_text = re.sub(punctuation_pattern, "  ", subtitle_text)
                    display_text = re.sub(r" {3,}", "  ", display_text).rstrip()
                    
                    # åˆ›å»ºå­—å¹•å‰ªè¾‘
                    clips_to_add = self._create_subtitle_clips_internal(
                        display_text, subtitle_start_time, subtitle_duration,
                        subtitle_config, resolved_font, video_width, video_height
                    )
                    subtitle_clips.extend(clips_to_add)
                    
                    logger.debug(f"åˆ›å»ºå­—å¹•: '{subtitle_text[:20]}...' æ—¶é—´: {subtitle_start_time:.1f}-{subtitle_start_time+subtitle_duration:.1f}s")
                    subtitle_start_time += subtitle_duration
                    
                except Exception as e:
                    logger.warning(f"åˆ›å»ºå­—å¹•å¤±è´¥: {str(e)}ï¼Œè·³è¿‡æ­¤å­—å¹•")
                    continue
            
            current_time += duration
        
        logger.info(f"å­—å¹•åˆ›å»ºå®Œæˆï¼Œå…±åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
        return subtitle_clips
    
    def _calculate_subtitle_durations(self, subtitle_texts: List[str], total_duration: float) -> List[float]:
        """è®¡ç®—æ¯è¡Œå­—å¹•çš„æ˜¾ç¤ºæ—¶é•¿"""
        if len(subtitle_texts) == 0:
            return [total_duration]
        
        lengths = [max(1, len(t)) for t in subtitle_texts]
        total_len = sum(lengths)
        line_durations = []
        acc = 0.0
        
        for idx, L in enumerate(lengths):
            if idx < len(lengths) - 1:
                d = total_duration * (L / total_len)
                line_durations.append(d)
                acc += d
            else:
                line_durations.append(max(0.0, total_duration - acc))
        
        return line_durations
    
    def _create_subtitle_clips_internal(self, display_text: str, start_time: float, duration: float,
                                       subtitle_config: Dict, resolved_font: Optional[str], 
                                       video_width: int, video_height: int) -> List:
        """å†…éƒ¨å­—å¹•å‰ªè¾‘åˆ›å»ºå‡½æ•°"""
        clips_to_add = []
        position = subtitle_config["position"]
        margin_bottom = int(subtitle_config.get("margin_bottom", 0))
        anchor_x = position[0] if isinstance(position, tuple) else "center"
        
        # åˆ›å»ºä¸»è¦æ–‡å­—å‰ªè¾‘
        main_clip = TextClip(
            text=display_text,
            font_size=subtitle_config["font_size"],
            color=subtitle_config["color"],
            font=resolved_font or subtitle_config["font_family"],
            stroke_color=subtitle_config["stroke_color"],
            stroke_width=subtitle_config["stroke_width"]
        )
        
        # æ·»åŠ èƒŒæ™¯æ¡ï¼ˆéœ€è¦å…ˆè®¡ç®—ï¼Œç¡®å®šæ–‡å­—ä½ç½®ï¼‰
        bg_color = subtitle_config.get("background_color")
        bg_opacity = float(subtitle_config.get("background_opacity", 0))
        if bg_color and bg_opacity > 0.0:
            bg_height = int(
                subtitle_config["font_size"] * subtitle_config.get("max_lines", 2)
                + subtitle_config.get("line_spacing", 10) + 4
            )
            text_width = main_clip.w
            bg_padding = int(subtitle_config.get("background_padding", 20))
            bg_width = text_width + bg_padding
            
            # èƒŒæ™¯ä½ç½®
            y_bg = max(0, video_height - margin_bottom - bg_height)
            bg_clip = ColorClip(size=(bg_width, bg_height), color=bg_color)
            if hasattr(bg_clip, "with_opacity"):
                bg_clip = bg_clip.with_opacity(bg_opacity)
            bg_clip = bg_clip.with_position(("center", y_bg)).with_start(start_time).with_duration(duration)
            
            # æ–‡å­—åœ¨èƒŒæ™¯ä¸­å‚ç›´å±…ä¸­
            y_text_centered = y_bg + (bg_height - main_clip.h) // 2
            main_pos = (anchor_x, y_text_centered)
            clips_to_add.append(bg_clip)
        else:
            # æ— èƒŒæ™¯æ—¶ä½¿ç”¨åŸæ¥çš„ä½ç½®è®¡ç®—
            if isinstance(position, tuple) and len(position) == 2 and position[1] == "bottom":
                baseline_safe_padding = int(subtitle_config.get("baseline_safe_padding", 4))
                y_text = max(0, video_height - margin_bottom - main_clip.h - baseline_safe_padding)
                main_pos = (anchor_x, y_text)
            else:
                main_pos = position
        
        main_clip = main_clip.with_position(main_pos).with_start(start_time).with_duration(duration)
        
        # æ·»åŠ é˜´å½±
        if subtitle_config.get("shadow_enabled", False):
            shadow_color = subtitle_config.get("shadow_color", "black")
            shadow_offset = subtitle_config.get("shadow_offset", (2, 2))
            shadow_x = main_pos[0] if isinstance(main_pos[0], int) else 0
            shadow_y = main_pos[1] if isinstance(main_pos[1], int) else 0
            
            try:
                shadow_pos = (shadow_x + shadow_offset[0], shadow_y + shadow_offset[1])
            except:
                shadow_pos = main_pos
            
            shadow_clip = TextClip(
                text=display_text,
                font_size=subtitle_config["font_size"],
                color=shadow_color,
                font=resolved_font or subtitle_config["font_family"]
            ).with_position(shadow_pos).with_start(start_time).with_duration(duration)
            
            clips_to_add.extend([shadow_clip, main_clip])
        else:
            clips_to_add.append(main_clip)
        
        return clips_to_add
    
    def split_text_for_subtitle(self, text: str, max_chars_per_line: int = 20, max_lines: int = 2) -> List[str]:
        """å°†é•¿æ–‡æœ¬åˆ†å‰²ä¸ºé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥"""
        if len(text) <= max_chars_per_line:
            return [text]
        
        # ç¬¬ä¸€å±‚ï¼šæŒ‰ä¸»è¦æ ‡ç‚¹åˆ‡åˆ†
        heavy_punctuation = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ï¼Œ', ',', 'ï¼›', ';']
        segments = []
        current_segment = ""
        
        for char in text:
            current_segment += char
            if char in heavy_punctuation:
                segments.append(current_segment.strip())
                current_segment = ""
        
        if current_segment.strip():
            segments.append(current_segment.strip())
        
        # ç¬¬äºŒå±‚ï¼šå¤„ç†è¶…é•¿ç‰‡æ®µ
        final_parts = []
        for segment in segments:
            if len(segment) <= max_chars_per_line:
                final_parts.append(segment)
            else:
                # æŒ‰é€—å·è¿›ä¸€æ­¥åˆ‡åˆ†
                comma_parts = []
                light_punctuation = ['ã€', ';', 'ï¼›']
                current_part = ""
                
                for char in segment:
                    current_part += char
                    if char in light_punctuation and len(current_part) >= max_chars_per_line * 0.6:
                        comma_parts.append(current_part.strip())
                        current_part = ""
                
                if current_part.strip():
                    comma_parts.append(current_part.strip())
                
                # ç¬¬ä¸‰å±‚ï¼šç¡¬åˆ‡åˆ†
                for part in comma_parts:
                    if len(part) <= max_chars_per_line:
                        final_parts.append(part)
                    else:
                        final_parts.extend(self._split_text_evenly(part, max_chars_per_line))
        
        return final_parts
    
    def _split_text_evenly(self, text: str, max_chars_per_line: int) -> List[str]:
        """å°†æ–‡æœ¬å‡åŒ€åˆ‡åˆ†"""
        if len(text) <= max_chars_per_line:
            return [text]
        
        total_chars = len(text)
        num_segments = (total_chars + max_chars_per_line - 1) // max_chars_per_line
        
        base_length = total_chars // num_segments
        remainder = total_chars % num_segments
        
        result = []
        start = 0
        
        for i in range(num_segments):
            length = base_length + (1 if i < remainder else 0)
            end = start + length
            result.append(text[start:end])
            start = end
        
        return result
    
    def resolve_font_path(self, preferred: Optional[str]) -> Optional[str]:
        """è§£æå­—ä½“è·¯å¾„"""
        if preferred and os.path.exists(preferred):
            return preferred
        
        # å¸¸è§ä¸­æ–‡å­—ä½“è·¯å¾„
        common_fonts = [
            "/System/Library/Fonts/STHeiti Light.ttc",  # macOS
            "/System/Library/Fonts/PingFang.ttc",       # macOS
            "/Windows/Fonts/simhei.ttf",                # Windows
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # Linux
        ]
        
        for font_path in common_fonts:
            if os.path.exists(font_path):
                return font_path
        
        return None
    
    def get_image_style(self, style_name: str = "style05") -> str:
        """è·å–å›¾åƒé£æ ¼å­—ç¬¦ä¸²ï¼ˆæ¥æºäº prompts.IMAGE_STYLE_PRESETSï¼‰"""
        try:
            return IMAGE_STYLE_PRESETS_PROMPTS.get(
                style_name,
                next(iter(IMAGE_STYLE_PRESETS_PROMPTS.values()))
            )
        except Exception:
            # å…œåº•ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²é¿å…å´©æºƒ
            return ""