"""
è§†é¢‘åˆæˆå™¨ - ç»Ÿä¸€çš„è§†é¢‘åˆæˆå¤„ç†æ¨¡å—ï¼ˆè¿ç§»è‡³ coreï¼‰
æ•´åˆè§†é¢‘åˆæˆã€å­—å¹•ç”Ÿæˆã€éŸ³é¢‘æ··åˆç­‰åŠŸèƒ½
"""

import os
import re
import numpy as np
from typing import List, Dict, Any, Optional, Tuple

# MoviePy 2.x imports (no editor module)
from moviepy import (
    ImageClip,
    VideoFileClip,
    TextClip,
    ColorClip,
    CompositeVideoClip,
    CompositeAudioClip,
    concatenate_videoclips,
    AudioFileClip,
    concatenate_audioclips,
)

from config import config
from utils import logger, FileProcessingError, VideoProcessingError, handle_video_operation


class VideoComposer:
    """ç»Ÿä¸€çš„è§†é¢‘åˆæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–è§†é¢‘åˆæˆå™¨"""
        pass
    
    def compose_video(self, image_paths: List[str], audio_paths: List[str], output_path: str,
                     script_data: Dict[str, Any] = None, enable_subtitles: bool = False,
                     bgm_audio_path: Optional[str] = None, bgm_volume: float = 0.15,
                     narration_volume: float = 1.0,
                     opening_image_path: Optional[str] = None,
                     opening_golden_quote: Optional[str] = None,
                     opening_narration_audio_path: Optional[str] = None,
                     image_size: str = "1280x720",
                     opening_quote: bool = True) -> str:
        """
        åˆæˆæœ€ç»ˆè§†é¢‘
        
        Args:
            image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
            audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨  
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            script_data: è„šæœ¬æ•°æ®ï¼Œç”¨äºç”Ÿæˆå­—å¹•
            enable_subtitles: æ˜¯å¦å¯ç”¨å­—å¹•
            bgm_audio_path: èƒŒæ™¯éŸ³ä¹è·¯å¾„
            bgm_volume: èƒŒæ™¯éŸ³ä¹éŸ³é‡
            narration_volume: å£æ’­éŸ³é‡
            opening_image_path: å¼€åœºå›¾ç‰‡è·¯å¾„
            opening_golden_quote: å¼€åœºé‡‘å¥
            opening_narration_audio_path: å¼€åœºå£æ’­éŸ³é¢‘è·¯å¾„
            image_size: ç›®æ ‡å›¾åƒå°ºå¯¸ï¼Œå¦‚"1280x720"
            opening_quote: æ˜¯å¦åŒ…å«å¼€åœºé‡‘å¥
        
        Returns:
            str: è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        try:
            if len(image_paths) != len(audio_paths):
                raise ValueError("å›¾åƒæ–‡ä»¶æ•°é‡ä¸éŸ³é¢‘æ–‡ä»¶æ•°é‡ä¸åŒ¹é…")
            
            # è§£æç›®æ ‡å°ºå¯¸
            target_size = self._parse_image_size(image_size)
            print(f"ç›®æ ‡è§†é¢‘å°ºå¯¸: {target_size[0]}x{target_size[1]}")
            
            # æ£€æµ‹æ˜¯å¦åŒ…å«è§†é¢‘ç´ æï¼Œå†³å®šè¾“å‡ºå¸§ç‡
            has_videos = self._has_video_materials(image_paths)
            target_fps = 30 if has_videos else 15
            print(f"æ£€æµ‹åˆ°{'è§†é¢‘' if has_videos else 'å›¾ç‰‡'}ç´ æï¼Œä½¿ç”¨{target_fps}fpsè¾“å‡º")
            
            video_clips = []
            audio_clips = []
            
            # åˆ›å»ºå¼€åœºç‰‡æ®µ
            opening_seconds = self._create_opening_segment(
                opening_image_path, opening_golden_quote,
                opening_narration_audio_path, video_clips, target_size, opening_quote
            )
            
            # åˆ›å»ºä¸»è¦è§†é¢‘ç‰‡æ®µ
            self._create_main_segments(image_paths, audio_paths, video_clips, audio_clips, target_size)
            
            # è¿æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
            print("æ­£åœ¨åˆæˆæœ€ç»ˆè§†é¢‘...")
            final_video = concatenate_videoclips(video_clips, method="chain")
            
            # æ·»åŠ å­—å¹•
            final_video = self._add_subtitles(final_video, script_data, enable_subtitles, 
                                            audio_clips, opening_seconds)
            
            # è°ƒæ•´å£æ’­éŸ³é‡
            final_video = self._adjust_narration_volume(final_video, narration_volume)
            
            # æ·»åŠ è§†è§‰æ•ˆæœ
            final_video = self._add_visual_effects(final_video, image_paths, target_size)
            
            # æ·»åŠ èƒŒæ™¯éŸ³ä¹
            final_video = self._add_background_music(final_video, bgm_audio_path, bgm_volume)
            
            # è¾“å‡ºè§†é¢‘
            self._export_video(final_video, output_path, target_fps)
            
            # é‡Šæ”¾èµ„æº
            self._cleanup_resources(video_clips, audio_clips, final_video)
            
            print(f"æœ€ç»ˆè§†é¢‘å·²ä¿å­˜: {output_path}")
            return output_path
            
        except Exception as e:
            raise ValueError(f"è§†é¢‘åˆæˆé”™è¯¯: {e}")
    
    @handle_video_operation("å¼€åœºç‰‡æ®µç”Ÿæˆ", critical=False, fallback_value=0.0)
    def _create_opening_segment(self, opening_image_path: Optional[str],
                              opening_golden_quote: Optional[str],
                              opening_narration_audio_path: Optional[str],
                              video_clips: List, target_size: Tuple[int, int],
                              opening_quote: bool = True) -> float:
        """åˆ›å»ºå¼€åœºç‰‡æ®µ"""
        opening_seconds = 0.0
        opening_voice_clip = None

        # å¦‚æœä¸åŒ…å«å¼€åœºé‡‘å¥ï¼Œç›´æ¥è¿”å›
        if not opening_quote:
            return opening_seconds

        # è®¡ç®—å¼€åœºæ—¶é•¿
        if opening_narration_audio_path and os.path.exists(opening_narration_audio_path):
            opening_voice_clip = AudioFileClip(opening_narration_audio_path)
            hold_after = float(getattr(config, "OPENING_HOLD_AFTER_NARRATION_SECONDS", 2.0))
            opening_seconds = float(opening_voice_clip.duration) + max(0.0, hold_after)

        if opening_image_path and os.path.exists(opening_image_path) and opening_seconds > 1e-3:
            print("æ­£åœ¨åˆ›å»ºå¼€åœºç‰‡æ®µâ€¦")
            opening_base = ImageClip(opening_image_path).with_duration(opening_seconds)
            # è°ƒæ•´å¼€åœºå›¾ç‰‡å°ºå¯¸åˆ°ç›®æ ‡å°ºå¯¸
            opening_base = self._resize_image(opening_base, target_size)
            
            # æ·»åŠ å¼€åœºé‡‘å¥
            if opening_golden_quote and opening_golden_quote.strip():
                opening_clip = self._add_opening_quote(opening_base, opening_golden_quote, opening_seconds)
            else:
                opening_clip = opening_base
            
            # ç»‘å®šå¼€åœºéŸ³é¢‘
            if opening_voice_clip is not None:
                opening_clip = opening_clip.with_audio(opening_voice_clip)
            
            # æ·»åŠ æ¸éšæ•ˆæœ
            opening_clip = self._add_opening_fade_effect(opening_clip, opening_voice_clip, opening_seconds)
            
            video_clips.append(opening_clip)
        
        return opening_seconds
    
    def _add_opening_quote(self, opening_base, opening_golden_quote: str, opening_seconds: float):
        """æ·»åŠ å¼€åœºé‡‘å¥æ–‡å­—å åŠ """
        subtitle_config = config.SUBTITLE_CONFIG.copy()
        resolved_font = self.resolve_font_path(subtitle_config.get("font_family"))
        
        quote_style = getattr(config, "OPENING_QUOTE_STYLE", {}) or {}
        base_font = int(config.SUBTITLE_CONFIG.get("font_size", 36))
        scale = float(quote_style.get("font_scale", 1.3))
        font_size = int(quote_style.get("font_size", base_font * scale))
        text_color = quote_style.get("color", config.SUBTITLE_CONFIG.get("color", "white"))
        stroke_color = quote_style.get("stroke_color", config.SUBTITLE_CONFIG.get("stroke_color", "black"))
        stroke_width = int(quote_style.get("stroke_width", max(3, int(config.SUBTITLE_CONFIG.get("stroke_width", 3)))))
        pos = quote_style.get("position", ("center", "center"))
        
        # å¤„ç†æ–‡å­—æ¢è¡Œ
        try:
            max_chars = int(quote_style.get("max_chars_per_line", 18))
            max_q_lines = int(quote_style.get("max_lines", 4))
            candidate_lines = self.split_text_for_subtitle(opening_golden_quote, max_chars, max_q_lines)
            lines = candidate_lines[:max_q_lines] if candidate_lines else [opening_golden_quote]
        except Exception:
            lines = [opening_golden_quote]
        
        # åˆ›å»ºå¤šè¡Œæ–‡å­—å‰ªè¾‘å®ç°è¡Œé—´è·æ§åˆ¶
        line_spacing = int(quote_style.get("line_spacing", 8))
        text_clips = []
        
        # è®¡ç®—æ€»é«˜åº¦ä»¥å®ç°å±…ä¸­ï¼ˆç»å¯¹åƒç´ åŸºå‡†ï¼‰
        total_height = len(lines) * font_size + (len(lines) - 1) * line_spacing
        video_height = opening_base.h
        top_y = max(0, (int(video_height) - int(total_height)) // 2)
        
        for i, line in enumerate(lines):
            if line.strip():
                y_abs = int(top_y + i * (font_size + line_spacing))
                line_clip = TextClip(
                    text=line,
                    font_size=font_size,
                    color=text_color,
                    font=resolved_font or config.SUBTITLE_CONFIG.get("font_family"),
                    stroke_color=stroke_color,
                    stroke_width=stroke_width
                ).with_start(0).with_duration(opening_seconds).with_position(("center", y_abs))
                text_clips.append(line_clip)
        
        return CompositeVideoClip([opening_base] + text_clips)
    
    def _add_opening_fade_effect(self, opening_clip, opening_voice_clip, opening_seconds: float):
        """ä¸ºå¼€åœºç‰‡æ®µæ·»åŠ æ¸éšæ•ˆæœï¼ˆä»…é™å¼€åœºï¼Œæ—¶é•¿è¾ƒçŸ­ï¼Œå¯¹æ€§èƒ½å½±å“å¯å¿½ç•¥ï¼‰"""
        try:
            if opening_voice_clip is not None:
                hold_after = float(getattr(config, "OPENING_HOLD_AFTER_NARRATION_SECONDS", 2.0))
                if hold_after > 1e-3:
                    voice_duration = float(opening_voice_clip.duration)
                    fade_start_time = voice_duration
                    fade_duration = hold_after

                    def _opening_fade_out(gf, t):
                        try:
                            if t < fade_start_time:
                                return gf(t)
                            elif t >= opening_seconds:
                                return 0.0 * gf(t)
                            else:
                                fade_progress = (t - fade_start_time) / fade_duration
                                alpha = max(0.0, 1.0 - fade_progress)
                                return alpha * gf(t)
                        except Exception:
                            return gf(t)

                    opening_clip = opening_clip.transform(_opening_fade_out, keep_duration=True)
        except Exception as e:
            logger.warning(f"å¼€åœºç‰‡æ®µæ¸éšæ•ˆæœæ·»åŠ å¤±è´¥: {e}")
        return opening_clip
    
    def _create_main_segments(self, image_paths: List[str], audio_paths: List[str], 
                            video_clips: List, audio_clips: List, target_size: Tuple[int, int]):
        """åˆ›å»ºä¸»è¦è§†é¢‘ç‰‡æ®µï¼ˆæ”¯æŒå›¾ç‰‡å’Œè§†é¢‘æ··åˆï¼‰"""
        for i, (media_path, audio_path) in enumerate(zip(image_paths, audio_paths)):
            print(f"æ­£åœ¨å¤„ç†ç¬¬{i+1}æ®µç´ æ...")
            
            audio_clip = AudioFileClip(audio_path)
            
            if self._is_video_file(media_path):
                # è§†é¢‘ç´ æå¤„ç†
                video_clip = self._create_video_segment(media_path, audio_clip, target_size)
            else:
                # å›¾ç‰‡ç´ æå¤„ç†
                image_clip = ImageClip(media_path).with_duration(audio_clip.duration)
                # è°ƒæ•´å›¾ç‰‡å°ºå¯¸åˆ°ç›®æ ‡å°ºå¯¸
                image_clip = self._resize_image(image_clip, target_size)
                video_clip = image_clip.with_audio(audio_clip)
            
            video_clips.append(video_clip)
            audio_clips.append(audio_clip)
    
    @handle_video_operation("å­—å¹•æ·»åŠ ", critical=False, fallback_value=lambda self, final_video, *args: final_video)
    def _add_subtitles(self, final_video, script_data: Dict[str, Any], enable_subtitles: bool, 
                      audio_clips: List, opening_seconds: float):
        """æ·»åŠ å­—å¹•"""
        effective_subtitles = bool(enable_subtitles) and bool(getattr(config, "SUBTITLE_CONFIG", {}).get("enabled", True))
        if effective_subtitles and script_data:
            print("æ­£åœ¨æ·»åŠ å­—å¹•...")
            subtitle_config = config.SUBTITLE_CONFIG.copy()
            subtitle_config["video_size"] = final_video.size
            subtitle_config["segment_durations"] = [ac.duration for ac in audio_clips]
            subtitle_config["offset_seconds"] = opening_seconds
            subtitle_clips = self.create_subtitle_clips(script_data, subtitle_config)
            
            if subtitle_clips:
                final_video = CompositeVideoClip([final_video] + subtitle_clips)
                print(f"å·²æ·»åŠ  {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
            else:
                print("æœªç”Ÿæˆä»»ä½•å­—å¹•å‰ªè¾‘")
        
        return final_video
    
    def _adjust_narration_volume(self, final_video, narration_volume: float):
        """è°ƒæ•´å£æ’­éŸ³é‡"""
        try:
            if final_video.audio is not None and narration_volume is not None:
                narration_audio = final_video.audio
                if isinstance(narration_volume, (int, float)) and abs(float(narration_volume) - 1.0) > 1e-9:
                    narration_audio = narration_audio.with_volume_scaled(float(narration_volume))
                    final_video = final_video.with_audio(narration_audio)
                    print(f"ğŸ”Š å£æ’­éŸ³é‡è°ƒæ•´ä¸º: {float(narration_volume)}")
        except Exception as e:
            logger.warning(f"å£æ’­éŸ³é‡è°ƒæ•´å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨åŸå§‹éŸ³é‡")
        
        return final_video
    
    @handle_video_operation("è§†è§‰æ•ˆæœæ·»åŠ ", critical=False, fallback_value=lambda self, final_video, *args: final_video)
    def _add_visual_effects(self, final_video, image_paths: List[str], target_size: Tuple[int, int]):
        """æ·»åŠ è§†è§‰æ•ˆæœï¼ˆå¼€åœºæ¸æ˜¾å’Œç‰‡å°¾æ¸éšï¼‰"""
        # æ€§èƒ½ä¼˜åŒ–ï¼šè·³è¿‡é€å¸§å¼€åœºæ¸æ˜¾
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šä»…æ·»åŠ ç‰‡å°¾é™å¸§ï¼Œä¸åšé€å¸§æ¸éš
        tail_seconds = float(getattr(config, "ENDING_FADE_SECONDS", 2.5))
        if isinstance(image_paths, list) and len(image_paths) > 0 and tail_seconds > 1e-3:
            last_image_path = image_paths[-1]
            tail_clip = ImageClip(last_image_path).with_duration(tail_seconds)
            # è°ƒæ•´ç‰‡å°¾å›¾ç‰‡å°ºå¯¸åˆ°ç›®æ ‡å°ºå¯¸
            tail_clip = self._resize_image(tail_clip, target_size)
            final_video = concatenate_videoclips([final_video, tail_clip], method="chain")
            print(f"ğŸ¬ å·²æ·»åŠ ç‰‡å°¾é™å¸§ {tail_seconds}s")
        
        return final_video
    
    @handle_video_operation("èƒŒæ™¯éŸ³ä¹æ·»åŠ ", critical=False, fallback_value=lambda self, final_video, *args: final_video)
    def _add_background_music(self, final_video, bgm_audio_path: Optional[str], bgm_volume: float):
        """æ·»åŠ èƒŒæ™¯éŸ³ä¹"""
        if not bgm_audio_path or not os.path.exists(bgm_audio_path):
            if bgm_audio_path:
                print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ä¸å­˜åœ¨: {bgm_audio_path}")
            else:
                print("â„¹ï¸ æœªæŒ‡å®šèƒŒæ™¯éŸ³ä¹æ–‡ä»¶")
            return final_video
            
        print(f"ğŸµ å¼€å§‹å¤„ç†èƒŒæ™¯éŸ³ä¹: {bgm_audio_path}")
        bgm_clip = AudioFileClip(bgm_audio_path)
        print(f"ğŸµ BGMåŠ è½½æˆåŠŸï¼Œæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
        
        # è°ƒæ•´BGMéŸ³é‡
        if isinstance(bgm_volume, (int, float)) and abs(float(bgm_volume) - 1.0) > 1e-9:
            bgm_clip = bgm_clip.with_volume_scaled(float(bgm_volume))
            print(f"ğŸµ BGMéŸ³é‡è°ƒæ•´ä¸º: {float(bgm_volume)}")
        
        # è°ƒæ•´BGMé•¿åº¦
        bgm_clip = self._adjust_bgm_duration(bgm_clip, final_video.duration)
        
        if bgm_clip is not None:
            # åº”ç”¨éŸ³é¢‘æ•ˆæœ
            bgm_clip = self._apply_audio_effects(bgm_clip, final_video)
            
            # åˆæˆéŸ³é¢‘
            if final_video.audio is not None:
                mixed_audio = CompositeAudioClip([final_video.audio, bgm_clip])
                print("ğŸµ BGMä¸å£æ’­éŸ³é¢‘åˆæˆå®Œæˆ")
            else:
                mixed_audio = CompositeAudioClip([bgm_clip])
                print("ğŸµ ä»…æ·»åŠ BGMéŸ³é¢‘ï¼ˆæ— å£æ’­éŸ³é¢‘ï¼‰")
            
            final_video = final_video.with_audio(mixed_audio)
            print("ğŸµ èƒŒæ™¯éŸ³ä¹æ·»åŠ æˆåŠŸï¼")
        
        return final_video
    
    def _adjust_bgm_duration(self, bgm_clip, target_duration: float):
        """è°ƒæ•´BGMæ—¶é•¿ï¼šä¼˜å…ˆæ‰‹åŠ¨å¹³é“ºå¾ªç¯ï¼Œå§‹ç»ˆé“ºæ»¡å¹¶è£å‰ªåˆ°ç›®æ ‡æ—¶é•¿"""
        try:
            print(f"ğŸµ è§†é¢‘æ€»æ—¶é•¿: {target_duration:.2f}ç§’ï¼ŒBGMæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")

            # åŸºæœ¬æ ¡éªŒ
            if target_duration <= 0:
                return bgm_clip
            unit_duration = float(bgm_clip.duration)
            if unit_duration <= 1e-6:
                raise RuntimeError("BGMæºæ—¶é•¿ä¸º0")

            # è‹¥BGMé•¿äºç›®æ ‡ï¼Œç›´æ¥è£å‰ª
            if unit_duration >= target_duration - 1e-6:
                try:
                    return bgm_clip.with_duration(target_duration)
                except Exception:
                    # å…œåº•ï¼šå­ç‰‡æ®µè£å‰ª
                    return bgm_clip.subclipped(0, target_duration)

            # æ‰‹åŠ¨å¹³é“ºï¼šé‡å¤æ‹¼æ¥ + æœ«æ®µç²¾ç¡®è£å‰ª
            clips = []
            accumulated = 0.0
            # å…ˆæ•´æ®µé‡å¤
            while accumulated + unit_duration <= target_duration - 1e-6:
                clips.append(bgm_clip.subclipped(0, unit_duration))
                accumulated += unit_duration
            # æœ«æ®µè£å‰ª
            remaining = max(0.0, target_duration - accumulated)
            if remaining > 1e-6:
                clips.append(bgm_clip.subclipped(0, remaining))

            looped = concatenate_audioclips(clips)
            print(f"ğŸµ BGMé•¿åº¦é€‚é…å®Œæˆï¼ˆmanual loopï¼‰ï¼Œæœ€ç»ˆæ—¶é•¿: {looped.duration:.2f}ç§’")
            return looped

        except Exception as e:
            print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹é•¿åº¦é€‚é…å¤±è´¥: {e}ï¼Œå°†ä¸æ·»åŠ BGMç»§ç»­ç”Ÿæˆ")
            logger.warning(f"èƒŒæ™¯éŸ³ä¹å¾ªç¯/è£å‰ªå¤±è´¥: {e}")
            return None
    
    def _apply_audio_effects(self, bgm_clip, final_video):
        """åº”ç”¨éŸ³é¢‘æ•ˆæœï¼ˆDuckingå’Œæ·¡å‡ºï¼‰"""
        # æ€§èƒ½ä¼˜åŒ–ï¼šè·³è¿‡é€é‡‡æ ·Duckingä¸æ·¡å‡ºï¼Œç›´æ¥è¿”å›
        return bgm_clip
    
    def _apply_ducking_effect(self, bgm_clip, final_video):
        """åº”ç”¨è‡ªåŠ¨Duckingæ•ˆæœ"""
        strength = float(getattr(config, "AUDIO_DUCKING_STRENGTH", 0.7))
        smooth_sec = float(getattr(config, "AUDIO_DUCKING_SMOOTH_SECONDS", 0.12))
        total_dur = float(final_video.duration)
        
        # é‡‡æ ·é¢‘ç‡
        env_fps = 20.0
        num_samples = max(2, int(total_dur * env_fps) + 1)
        times = np.linspace(0.0, total_dur, num_samples)
        
        # ä¼°ç®—å£æ’­ç¬æ—¶å¹…åº¦
        amp = np.zeros_like(times)
        for i, t in enumerate(times):
            try:
                frame = final_video.audio.get_frame(float(min(max(0.0, t), total_dur - 1e-6)))
                amp[i] = float(np.mean(np.abs(frame)))
            except Exception:
                amp[i] = 0.0
        
        # å¹³æ»‘å¤„ç†
        win = max(1, int(smooth_sec * env_fps))
        if win > 1:
            kernel = np.ones(win, dtype=float) / win
            amp = np.convolve(amp, kernel, mode="same")
        
        # å½’ä¸€åŒ–
        max_amp = float(np.max(amp)) if np.max(amp) > 1e-8 else 1.0
        env = amp / max_amp
        
        # è®¡ç®—duckingå¢ç›Šæ›²çº¿
        gains = 1.0 - strength * env
        gains = np.clip(gains, 0.0, 1.0)
        
        # æ„å»ºæ—¶é—´å˜å¢ç›Šå‡½æ•°
        def ducking_gain_lookup(t_any):
            def lookup_single(ts: float) -> float:
                if ts <= 0.0:
                    return float(gains[0])
                if ts >= total_dur:
                    return float(gains[-1])
                idx = max(0, min(int(ts * env_fps), gains.shape[0] - 1))
                return float(gains[idx])
            
            if hasattr(t_any, "__len__"):
                return np.array([lookup_single(float(ts)) for ts in t_any])
            return lookup_single(float(t_any))
        
        # åº”ç”¨æ—¶é—´å˜å¢ç›Š
        bgm_clip = bgm_clip.transform(
            lambda gf, t: (
                (ducking_gain_lookup(t)[:, None] if hasattr(t, "__len__") else ducking_gain_lookup(t))
                * gf(t)
            ),
            keep_duration=True,
        )
        print(f"ğŸšï¸ å·²å¯ç”¨è‡ªåŠ¨Duckingï¼ˆstrength={strength}, smooth={smooth_sec}sï¼‰")
        
        return bgm_clip
    
    def _create_linear_fade_out_gain(self, total: float, tail: float):
        """åˆ›å»ºçº¿æ€§æ·¡å‡ºå¢ç›Šå‡½æ•°"""
        cutoff = max(0.0, total - tail)
        
        def linear_fade_gain(t_any):
            def calc_single_gain(ts: float) -> float:
                if ts <= cutoff:
                    return 1.0
                if ts >= total:
                    return 0.0
                return max(0.0, 1.0 - (ts - cutoff) / tail)
            
            if hasattr(t_any, "__len__"):
                return np.array([calc_single_gain(float(ts)) for ts in t_any])
            return calc_single_gain(float(t_any))
        
        return linear_fade_gain
    
    def _export_video(self, final_video, output_path: str, fps: int = 15):
        """å¯¼å‡ºè§†é¢‘"""
        moviepy_logger = 'bar'
        
        try:
            # ä½¿ç”¨ffmpegè§†é¢‘æ»¤é•œå®ç°æ·¡å…¥/æ·¡å‡ºï¼ˆä»…è§†é¢‘ï¼Œä¸å¤„ç†éŸ³é¢‘ï¼Œé¿å…ä¸stream copyå†²çªï¼‰
            fade_in_seconds = float(getattr(config, "OPENING_FADEIN_SECONDS", 0.0))
            tail_seconds = float(getattr(config, "ENDING_FADE_SECONDS", 0.0))
            total_duration = float(getattr(final_video, "duration", 0.0) or 0.0)
            vf_parts = []
            if fade_in_seconds > 1e-3:
                vf_parts.append(f"fade=t=in:st=0:d={fade_in_seconds}")
            if tail_seconds > 1e-3 and total_duration > 0.0:
                fade_out_start = max(0.0, total_duration - tail_seconds)
                vf_parts.append(f"fade=t=out:st={fade_out_start}:d={tail_seconds}")
            vf_filter = ",".join(vf_parts) if vf_parts else None

            # ä¼˜å…ˆå°è¯•macOSç¡¬ä»¶ç¼–ç 
            bitrate = '8M' if fps == 30 else '3M'
            audio_bitrate = '128k' if fps == 30 else '96k'
            bufsize = '12M' if fps == 30 else '6M'
            final_video.write_videofile(
                output_path,
                fps=fps,
                codec='h264_videotoolbox',
                audio_codec='aac',
                audio_bitrate=audio_bitrate,
                bitrate=bitrate,
                ffmpeg_params=(
                    ['-pix_fmt', 'yuv420p', '-movflags', '+faststart', '-maxrate', bitrate, '-bufsize', bufsize, '-profile:v', 'main', '-level', '3.1']
                    + (['-vf', vf_filter] if vf_filter else [])
                ),
                logger=moviepy_logger
            )
        except Exception as e:
            print(f"âš ï¸ ç¡¬ä»¶ç¼–ç ä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œå›é€€åˆ°è½¯ä»¶ç¼–ç : {e}")
            # å›é€€åˆ°è½¯ä»¶ç¼–ç 
            audio_bitrate = '128k' if fps == 30 else '96k'
            crf = '20' if fps == 30 else '25'
            preset = 'medium'
            final_video.write_videofile(
                output_path,
                fps=fps,
                codec='libx264',
                audio_codec='aac',
                audio_bitrate=audio_bitrate,
                preset=preset,
                threads=os.cpu_count() or 4,
                ffmpeg_params=(
                    ['-crf', crf, '-pix_fmt', 'yuv420p', '-movflags', '+faststart']
                    + (['-vf', vf_filter] if vf_filter else [])
                ),
                logger=moviepy_logger
            )
    
    def _cleanup_resources(self, video_clips: List, audio_clips: List, final_video):
        """é‡Šæ”¾èµ„æº"""
        for clip in video_clips:
            clip.close()
        for aclip in audio_clips:
            aclip.close()
        final_video.close()
    
    def create_subtitle_clips(self, script_data: Dict[str, Any], 
                            subtitle_config: Dict[str, Any] = None) -> List:
        """åˆ›å»ºå­—å¹•å‰ªè¾‘åˆ—è¡¨"""
        if subtitle_config is None:
            subtitle_config = config.SUBTITLE_CONFIG.copy()
        
        subtitle_clips = []
        current_time = float(subtitle_config.get("offset_seconds", 0.0))
        
        logger.info("å¼€å§‹åˆ›å»ºå­—å¹•å‰ªè¾‘...")
        
        # è§£æå­—ä½“
        resolved_font = self.resolve_font_path(subtitle_config.get("font_family"))
        if not resolved_font:
            logger.warning("æœªèƒ½è§£æåˆ°å¯ç”¨ä¸­æ–‡å­—ä½“")
        
        # è¯»å–è§†é¢‘å°ºå¯¸
        video_size = subtitle_config["video_size"]
        video_width, video_height = video_size
        
        segment_durations = subtitle_config.get("segment_durations", [])
        
        # æ ‡ç‚¹æ›¿æ¢æ¨¡å¼
        punctuation_pattern = r"[-.,!?;:\"ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šï¼ˆï¼‰()\[\]{}ã€ã€‘â€”â€¦â€“ã€]+"
        
        for i, segment in enumerate(script_data["segments"], 1):
            content = segment["content"]
            
            # è·å–æ—¶é•¿ - ä¼˜å…ˆä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿
            duration = float(segment.get("estimated_duration", 0))
            if isinstance(segment_durations, list) and len(segment_durations) >= i:
                duration = float(segment_durations[i-1])  # å®é™…éŸ³é¢‘æ—¶é•¿è¦†ç›–ä¼°ç®—å€¼
            
            logger.debug(f"å¤„ç†ç¬¬{i}æ®µå­—å¹•ï¼Œæ—¶é•¿: {duration}ç§’")
            
            # åˆ†å‰²æ–‡æœ¬
            subtitle_texts = self.split_text_for_subtitle(
                content,
                subtitle_config["max_chars_per_line"],
                subtitle_config["max_lines"]
            )
            
            # è®¡ç®—æ¯è¡Œå­—å¹•æ—¶é•¿
            subtitle_start_time = current_time
            line_durations = self._calculate_subtitle_durations(subtitle_texts, duration)
            
            for subtitle_text, subtitle_duration in zip(subtitle_texts, line_durations):
                try:
                    # å¤„ç†æ ‡ç‚¹
                    display_text = re.sub(punctuation_pattern, "  ", subtitle_text)
                    display_text = re.sub(r" {3,}", "  ", display_text).rstrip()
                    
                    # åˆ›å»ºå­—å¹•å‰ªè¾‘
                    clips_to_add = self._create_subtitle_clips_internal(
                        display_text, subtitle_start_time, subtitle_duration,
                        subtitle_config, resolved_font, video_width, video_height
                    )
                    subtitle_clips.extend(clips_to_add)
                    
                    logger.debug(f"åˆ›å»ºå­—å¹•: '{subtitle_text[:20]}...' æ—¶é—´: {subtitle_start_time:.1f}-{subtitle_start_time+subtitle_duration:.1f}s")
                    subtitle_start_time += subtitle_duration
                    
                except Exception as e:
                    logger.warning(f"åˆ›å»ºå­—å¹•å¤±è´¥: {str(e)}ï¼Œè·³è¿‡æ­¤å­—å¹•")
                    continue
            
            current_time += duration
        
        logger.info(f"å­—å¹•åˆ›å»ºå®Œæˆï¼Œå…±åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
        return subtitle_clips
    
    def _calculate_mixed_length(self, text: str) -> float:
        """è®¡ç®—æ··åˆä¸­è‹±æ–‡æœ¬çš„ç­‰æ•ˆé•¿åº¦"""
        import re
        import unicodedata
        # ä¸­æ–‡æŒ‰å­—è®¡æ•°ï¼ˆCJKç»Ÿä¸€è¡¨æ„æ–‡å­—ï¼‰
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))
        # è‹±æ–‡æŒ‰è¯è®¡æ•°ï¼ˆå…è®¸ don't / co-op ç­‰å¸¦æ’‡å·æˆ–è¿å­—ç¬¦ï¼‰
        english_words = len(re.findall(r"[A-Za-z]+(?:['-][A-Za-z]+)*", text))
        # æ•°å­—æŒ‰ä½è®¡æ•°
        numbers = len(re.findall(r'\d', text))
        # å…¶ä»–å¤–æ–‡å­—ç¬¦ï¼ˆéASCIIå­—æ¯ã€éCJKï¼‰ä½œä¸ºå­—æ¯æŒ‰1è®¡æ•°
        ascii_alpha = re.compile(r"[A-Za-z]")
        cjk_pattern = re.compile(r"[\u4e00-\u9fff]")
        other_letters = 0
        for ch in text:
            if cjk_pattern.match(ch):
                continue
            if ascii_alpha.match(ch):
                continue
            if unicodedata.category(ch).startswith('L'):
                other_letters += 1
        # æ ‡ç‚¹ä¸è®¡å…¥
        return chinese_chars * 1.0 + english_words * 1.5 + numbers * 1.0 + other_letters * 1.0
    
    def _calculate_subtitle_durations(self, subtitle_texts: List[str], total_duration: float) -> List[float]:
        """è®¡ç®—æ¯è¡Œå­—å¹•çš„æ˜¾ç¤ºæ—¶é•¿"""
        if len(subtitle_texts) == 0:
            return [total_duration]
        
        lengths = [max(1.0, self._calculate_mixed_length(t)) for t in subtitle_texts]
        total_len = sum(lengths)
        line_durations = []
        acc = 0.0
        
        for idx, L in enumerate(lengths):
            if idx < len(lengths) - 1:
                d = total_duration * (L / total_len)
                line_durations.append(d)
                acc += d
            else:
                line_durations.append(max(0.0, total_duration - acc))
        
        return line_durations
    
    def _create_subtitle_clips_internal(self, display_text: str, start_time: float, duration: float,
                                       subtitle_config: Dict, resolved_font: Optional[str], 
                                       video_width: int, video_height: int) -> List:
        """å†…éƒ¨å­—å¹•å‰ªè¾‘åˆ›å»ºå‡½æ•°"""
        clips_to_add = []
        position = subtitle_config["position"]
        margin_bottom = int(subtitle_config.get("margin_bottom", 0))
        anchor_x = position[0] if isinstance(position, tuple) else "center"
        
        # åˆ›å»ºä¸»è¦æ–‡å­—å‰ªè¾‘
        main_clip = TextClip(
            text=display_text,
            font_size=subtitle_config["font_size"],
            color=subtitle_config["color"],
            font=resolved_font or subtitle_config["font_family"],
            stroke_color=subtitle_config["stroke_color"],
            stroke_width=subtitle_config["stroke_width"]
        )
        
        # æ·»åŠ èƒŒæ™¯æ¡ï¼ˆéœ€è¦å…ˆè®¡ç®—ï¼Œç¡®å®šæ–‡å­—ä½ç½®ï¼‰
        bg_color = subtitle_config.get("background_color")
        bg_opacity = float(subtitle_config.get("background_opacity", 0))
        if bg_color and bg_opacity > 0.0:
            bg_height = int(
                subtitle_config["font_size"] * subtitle_config.get("max_lines", 2)
                + subtitle_config.get("line_spacing", 10) 
                + subtitle_config.get("background_vertical_padding", 10)
            )
            text_width = main_clip.w
            bg_padding = int(subtitle_config.get("background_horizontal_padding", 20))
            # é™åˆ¶èƒŒæ™¯å®½åº¦ä¸è¶…è¿‡è§†é¢‘å®½åº¦çš„90%
            max_bg_width = int(video_width * 0.9)
            bg_width = min(text_width + bg_padding, max_bg_width)
            
            # èƒŒæ™¯ä½ç½®
            y_bg = max(0, video_height - margin_bottom - bg_height)
            bg_clip = ColorClip(size=(bg_width, bg_height), color=bg_color)
            if hasattr(bg_clip, "with_opacity"):
                bg_clip = bg_clip.with_opacity(bg_opacity)
            # å…ˆè®¾å®šæ—¶é—´ï¼Œå†è®¾å®šä½ç½®ï¼Œé¿å…æ—¶é—´è½´å±æ€§è¢«è¦†ç›–
            bg_clip = bg_clip.with_start(start_time).with_duration(duration).with_position(("center", y_bg))
            
            # æ–‡å­—åœ¨èƒŒæ™¯ä¸­å‚ç›´å±…ä¸­
            y_text_centered = y_bg + (bg_height - main_clip.h) // 2
            main_pos = (anchor_x, y_text_centered)
            clips_to_add.append(bg_clip)
        else:
            # æ— èƒŒæ™¯æ—¶ä½¿ç”¨åŸæ¥çš„ä½ç½®è®¡ç®—
            if isinstance(position, tuple) and len(position) == 2 and position[1] == "bottom":
                baseline_safe_padding = int(subtitle_config.get("baseline_safe_padding", 4))
                y_text = max(0, video_height - margin_bottom - main_clip.h - baseline_safe_padding)
                main_pos = (anchor_x, y_text)
            else:
                main_pos = position
        
        # å…ˆè®¾å®šæ—¶é—´ï¼Œå†è®¾å®šä½ç½®ï¼Œé¿å…æ—¶é—´è½´å±æ€§è¢«è¦†ç›–
        main_clip = main_clip.with_start(start_time).with_duration(duration).with_position(main_pos)
        
        # æ·»åŠ é˜´å½±
        if subtitle_config.get("shadow_enabled", False):
            shadow_color = subtitle_config.get("shadow_color", "black")
            shadow_offset = subtitle_config.get("shadow_offset", (2, 2))
            shadow_x = main_pos[0] if isinstance(main_pos[0], int) else 0
            shadow_y = main_pos[1] if isinstance(main_pos[1], int) else 0
            
            try:
                shadow_pos = (shadow_x + shadow_offset[0], shadow_y + shadow_offset[1])
            except:
                shadow_pos = main_pos
            
            shadow_clip = TextClip(
                text=display_text,
                font_size=subtitle_config["font_size"],
                color=shadow_color,
                font=resolved_font or subtitle_config["font_family"]
            ).with_start(start_time).with_duration(duration).with_position(shadow_pos)
            
            clips_to_add.extend([shadow_clip, main_clip])
        else:
            clips_to_add.append(main_clip)
        
        return clips_to_add
    
    def split_text_for_subtitle(self, text: str, max_chars_per_line: int = 20, max_lines: int = 2) -> List[str]:
        """å°†é•¿æ–‡æœ¬åˆ†å‰²ä¸ºé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥"""
        if len(text) <= max_chars_per_line:
            return [text]
        
        # ç¬¬ä¸€å±‚ï¼šæŒ‰ä¸»è¦æ ‡ç‚¹åˆ‡åˆ†
        heavy_punctuation = ['ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?', 'ï¼Œ', ',', 'ï¼›', ';', ' ']
        segments = []
        current_segment = ""
        
        for char in text:
            current_segment += char
            if char in heavy_punctuation:
                segments.append(current_segment.strip())
                current_segment = ""
        
        if current_segment.strip():
            segments.append(current_segment.strip())
        
        # ç¬¬äºŒå±‚ï¼šå¤„ç†è¶…é•¿ç‰‡æ®µ
        final_parts = []
        for segment in segments:
            if len(segment) <= max_chars_per_line:
                final_parts.append(segment)
            else:
                # æŒ‰é€—å·è¿›ä¸€æ­¥åˆ‡åˆ†
                comma_parts = []
                light_punctuation = ['ã€', ';', 'ï¼›']
                current_part = ""
                
                for char in segment:
                    current_part += char
                    if char in light_punctuation and len(current_part) >= max_chars_per_line * 0.6:
                        comma_parts.append(current_part.strip())
                        current_part = ""
                
                if current_part.strip():
                    comma_parts.append(current_part.strip())
                
                # ç¬¬ä¸‰å±‚ï¼šç¡¬åˆ‡åˆ†
                for part in comma_parts:
                    if len(part) <= max_chars_per_line:
                        final_parts.append(part)
                    else:
                        final_parts.extend(self._split_text_evenly(part, max_chars_per_line))
        
        # è¿”å›å®Œæ•´çš„è¡Œåºåˆ—ï¼ˆæ˜¾ç¤ºå±‚é¢ä»æŒ‰ max_lines æ§åˆ¶â€œåŒæ—¶æ˜¾ç¤ºâ€çš„è¡Œæ•°ï¼‰
        return final_parts
    
    def _split_text_evenly(self, text: str, max_chars_per_line: int) -> List[str]:
        """å°†æ–‡æœ¬å‡åŒ€åˆ‡åˆ†"""
        if len(text) <= max_chars_per_line:
            return [text]
        
        total_chars = len(text)
        num_segments = (total_chars + max_chars_per_line - 1) // max_chars_per_line
        
        base_length = total_chars // num_segments
        remainder = total_chars % num_segments
        
        result = []
        start = 0
        
        for i in range(num_segments):
            length = base_length + (1 if i < remainder else 0)
            end = start + length
            result.append(text[start:end])
            start = end
        
        return result
    
    def resolve_font_path(self, preferred: Optional[str]) -> Optional[str]:
        """è§£æå­—ä½“è·¯å¾„"""
        if preferred and os.path.exists(preferred):
            return preferred
        
        # å¸¸è§ä¸­æ–‡å­—ä½“è·¯å¾„
        common_fonts = [
            "/System/Library/Fonts/STHeiti Light.ttc",  # macOS
            "/System/Library/Fonts/PingFang.ttc",       # macOS
            "/Windows/Fonts/simhei.ttf",                # Windows
            "/usr/share/fonts/truetype/wqy/wqy-microhei.ttc",  # Linux
        ]
        
        for font_path in common_fonts:
            if os.path.exists(font_path):
                return font_path
        
        return None
    
    def _is_video_file(self, file_path: str) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶"""
        file_extension = os.path.splitext(file_path)[1].lower()
        return file_extension in config.VIDEO_MATERIAL_CONFIG["supported_formats"]
    
    def _has_video_materials(self, media_paths: List[str]) -> bool:
        """æ£€æµ‹æ˜¯å¦åŒ…å«è§†é¢‘ç´ æ"""
        return any(self._is_video_file(path) for path in media_paths)
    
    def _create_video_segment(self, video_path: str, audio_clip, target_size: Tuple[int, int]) -> Any:
        """åˆ›å»ºè§†é¢‘ç‰‡æ®µ"""
        print(f"å¤„ç†è§†é¢‘ç´ æ: {os.path.basename(video_path)}")
        
        # åŠ è½½è§†é¢‘æ–‡ä»¶
        video_clip = VideoFileClip(video_path)
        original_duration = video_clip.duration
        target_duration = audio_clip.duration
        
        print(f"  åŸè§†é¢‘æ—¶é•¿: {original_duration:.2f}sï¼Œç›®æ ‡æ—¶é•¿: {target_duration:.2f}s")
        
        # ç§»é™¤åŸéŸ³é¢‘ï¼Œè°ƒæ•´å°ºå¯¸
        video_clip = video_clip.without_audio()
        video_clip = self._resize_video(video_clip, target_size)
        
        if original_duration < target_duration:
            # è§†é¢‘æ¯”éŸ³é¢‘çŸ­ï¼šæ‹‰ä¼¸åˆ°ç›®æ ‡é•¿åº¦ï¼ˆä¿æŒç°æœ‰é€»è¾‘ï¼‰
            speed_factor = original_duration / target_duration
            print(f"  è§†é¢‘è¾ƒçŸ­ï¼Œæ‹‰ä¼¸ç³»æ•°: {speed_factor:.3f}")
            video_clip = video_clip.with_duration(target_duration)
        elif original_duration > target_duration:
            # è§†é¢‘æ¯”éŸ³é¢‘é•¿ï¼šä»å¤´å¼€å§‹è£å‰ªåˆ°ç›®æ ‡é•¿åº¦
            print(f"  è§†é¢‘è¾ƒé•¿ï¼Œä»å¤´è£å‰ªåˆ° {target_duration:.2f}s")
            video_clip = video_clip.subclipped(0, target_duration)
        else:
            # æ—¶é•¿ç›¸ç­‰æˆ–æå…¶æ¥è¿‘ï¼Œæ— éœ€å¤„ç†
            print(f"  è§†é¢‘æ—¶é•¿ä¸éŸ³é¢‘åŒ¹é…ï¼Œæ— éœ€è°ƒæ•´")
        
        return video_clip.with_audio(audio_clip)
    
    def _resize_video(self, video_clip, target_size: Tuple[int, int]) -> Any:
        """è°ƒæ•´è§†é¢‘å°ºå¯¸åˆ°æŒ‡å®šå°ºå¯¸"""
        target_w, target_h = target_size
        original_w, original_h = video_clip.size
        
        # æŒ‰æ¯”ä¾‹ç¼©æ”¾å¹¶è£å‰ª
        scale_w = target_w / original_w
        scale_h = target_h / original_h
        
        if scale_w > scale_h:
            video_clip = video_clip.resized(width=target_w)
            if video_clip.h > target_h:
                y_start = (video_clip.h - target_h) // 2
                video_clip = video_clip.cropped(y1=y_start, y2=y_start + target_h)
        else:
            video_clip = video_clip.resized(height=target_h)
            if video_clip.w > target_w:
                x_start = (video_clip.w - target_w) // 2
                video_clip = video_clip.cropped(x1=x_start, x2=x_start + target_w)
        
        return video_clip
    
    def _parse_image_size(self, image_size: str) -> Tuple[int, int]:
        """è§£æå›¾åƒå°ºå¯¸å­—ç¬¦ä¸²ï¼Œå¦‚ "1024x1024" -> (1024, 1024)"""
        try:
            width_str, height_str = image_size.lower().split('x')
            width = int(width_str.strip())
            height = int(height_str.strip())
            return (width, height)
        except (ValueError, AttributeError) as e:
            logger.warning(f"æ— æ³•è§£æå›¾åƒå°ºå¯¸ '{image_size}'ï¼Œä½¿ç”¨é»˜è®¤1280x720: {e}")
            return (1280, 720)
    
    def _resize_image(self, image_clip, target_size: Tuple[int, int]) -> Any:
        """è°ƒæ•´å›¾ç‰‡å°ºå¯¸åˆ°æŒ‡å®šå°ºå¯¸"""
        target_w, target_h = target_size
        original_w, original_h = image_clip.size
        
        # å¦‚æœåŸå›¾å°ºå¯¸å·²ç»åŒ¹é…ï¼Œç›´æ¥è¿”å›
        if original_w == target_w and original_h == target_h:
            return image_clip
        
        # æŒ‰æ¯”ä¾‹ç¼©æ”¾å¹¶è£å‰ªï¼ˆä¸è§†é¢‘å¤„ç†é€»è¾‘ä¸€è‡´ï¼‰
        scale_w = target_w / original_w
        scale_h = target_h / original_h
        
        if scale_w > scale_h:
            image_clip = image_clip.resized(width=target_w)
            if image_clip.h > target_h:
                y_start = (image_clip.h - target_h) // 2
                image_clip = image_clip.cropped(y1=y_start, y2=y_start + target_h)
        else:
            image_clip = image_clip.resized(height=target_h)
            if image_clip.w > target_w:
                x_start = (image_clip.w - target_w) // 2
                image_clip = image_clip.cropped(x1=x_start, x2=x_start + target_w)
        
        return image_clip
    
