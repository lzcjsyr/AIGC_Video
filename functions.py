"""
æ™ºèƒ½è§†é¢‘åˆ¶ä½œç³»ç»Ÿ - æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
åŒ…å«æ–‡æ¡£è¯»å–ã€æ™ºèƒ½å¤„ç†ã€å›¾åƒç”Ÿæˆã€è¯­éŸ³åˆæˆã€è§†é¢‘åˆ¶ä½œç­‰åŠŸèƒ½
"""

from moviepy import ImageClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips, VideoFileClip, TextClip, ColorClip, CompositeAudioClip
# MoviePy 2.x: ä½¿ç”¨ç±»æ•ˆæœ API
try:
    from moviepy.audio.fx.AudioLoop import AudioLoop  # type: ignore
except Exception:
    AudioLoop = None  # fallback later
from moviepy.audio.fx.MultiplyVolume import MultiplyVolume  # type: ignore
try:
    from moviepy.audio.AudioClip import concatenate_audioclips  # type: ignore
except Exception:
    concatenate_audioclips = None  # fallback later
from typing import Optional, Dict, Any, List, Tuple
from io import BytesIO
from PIL import Image
import requests
import json
import os
import re
import datetime
import ebooklib
from ebooklib import epub
import PyPDF2
import pdfplumber

from prompts import summarize_system_prompt, keywords_extraction_prompt, IMAGE_STYLE_PRESETS
from genai_api import text_to_text, text_to_image_doubao, text_to_audio_bytedance
from config import config
try:
    from proglog import TqdmProgressBar  # type: ignore
except Exception:
    TqdmProgressBar = None
from utils import (
    logger, FileProcessingError, APIError, VideoProcessingError,
    log_function_call, ensure_directory_exists, clean_text, 
    validate_file_format, safe_json_loads, save_json_file,
    calculate_duration, ProgressTracker, interactive_file_selector
)
from utils import parse_json_robust
import numpy as np

################ Document Reading ################
@log_function_call
def read_document(file_path: str) -> Tuple[str, int]:
    """
    è¯»å–EPUBæˆ–PDFæ–‡æ¡£ï¼Œè¿”å›å†…å®¹å’Œå­—æ•°
    
    Args:
        file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
    
    Returns:
        Tuple[str, int]: (æ–‡æ¡£å†…å®¹, å­—æ•°)
    """
    # éªŒè¯æ–‡ä»¶æ ¼å¼
    validate_file_format(file_path, config.SUPPORTED_INPUT_FORMATS)
    
    file_extension = os.path.splitext(file_path)[1].lower()
    
    logger.info(f"å¼€å§‹è¯»å–{file_extension.upper()}æ–‡ä»¶: {os.path.basename(file_path)}")
    
    if file_extension == '.epub':
        return read_epub(file_path)
    elif file_extension == '.pdf':
        return read_pdf(file_path)
    else:
        raise FileProcessingError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}")

def read_epub(file_path: str) -> Tuple[str, int]:
    """è¯»å–EPUBæ–‡ä»¶å†…å®¹"""
    try:
        book = epub.read_epub(file_path)
        content_parts = []
        
        logger.debug("æ­£åœ¨æå–EPUBæ–‡ä»¶ä¸­çš„æ–‡æœ¬å†…å®¹...")
        
        # è·å–æ‰€æœ‰æ–‡æœ¬å†…å®¹
        for item in book.get_items():
            if item.get_type() == ebooklib.ITEM_DOCUMENT:
                content = item.get_content().decode('utf-8')
                # æ¸…ç†HTMLæ ‡ç­¾å’Œæ ¼å¼åŒ–æ–‡æœ¬
                content = clean_text(content)
                if content:
                    content_parts.append(content)
        
        if not content_parts:
            raise FileProcessingError("EPUBæ–‡ä»¶ä¸­æœªæ‰¾åˆ°å¯è¯»å–çš„æ–‡æœ¬å†…å®¹")
        
        full_content = ' '.join(content_parts)
        word_count = len(full_content)
        
        logger.info(f"EPUBæ–‡ä»¶è¯»å–æˆåŠŸï¼Œæ€»å­—æ•°: {word_count:,}å­—")
        return full_content, word_count
    
    except Exception as e:
        logger.error(f"è¯»å–EPUBæ–‡ä»¶å¤±è´¥: {str(e)}")
        raise FileProcessingError(f"è¯»å–EPUBæ–‡ä»¶å¤±è´¥: {str(e)}")

def read_pdf(file_path: str) -> Tuple[str, int]:
    """è¯»å–PDFæ–‡ä»¶å†…å®¹"""
    try:
        content_parts = []
        
        logger.debug("æ­£åœ¨ä½¿ç”¨pdfplumberæå–PDFæ–‡æœ¬...")
        
        # å…ˆå°è¯•pdfplumberï¼ˆæ›´å‡†ç¡®çš„æ–‡æœ¬æå–ï¼‰
        with pdfplumber.open(file_path) as pdf:
            for i, page in enumerate(pdf.pages, 1):
                text = page.extract_text()
                if text:
                    content_parts.append(text)
                    logger.debug(f"å·²æå–ç¬¬{i}é¡µå†…å®¹ï¼Œå­—ç¬¦æ•°: {len(text)}")
        
        # å¦‚æœpdfplumberæ²¡æœ‰æå–åˆ°å†…å®¹ï¼Œå°è¯•PyPDF2
        if not content_parts:
            logger.debug("pdfplumberæœªæå–åˆ°å†…å®¹ï¼Œå°è¯•ä½¿ç”¨PyPDF2...")
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for i, page in enumerate(pdf_reader.pages, 1):
                    text = page.extract_text()
                    if text:
                        content_parts.append(text)
                        logger.debug(f"å·²æå–ç¬¬{i}é¡µå†…å®¹ï¼Œå­—ç¬¦æ•°: {len(text)}")
        
        if not content_parts:
            raise FileProcessingError("æ— æ³•ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹ï¼Œå¯èƒ½æ˜¯æ‰«æç‰ˆPDF")
        
        full_content = ' '.join(content_parts)
        # æ¸…ç†æ–‡æœ¬
        full_content = clean_text(full_content)
        word_count = len(full_content)
        
        logger.info(f"PDFæ–‡ä»¶è¯»å–æˆåŠŸï¼Œæ€»å­—æ•°: {word_count:,}å­—")
        return full_content, word_count
    
    except Exception as e:
        logger.error(f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}")
        raise FileProcessingError(f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}")

################ Intelligent Summarization ################
def intelligent_summarize(server: str, model: str, content: str, target_length: int, num_segments: int) -> Dict[str, Any]:
    """
    æ™ºèƒ½ç¼©å†™ - ç¬¬ä¸€æ¬¡LLMå¤„ç†
    å°†é•¿ç¯‡å†…å®¹å‹ç¼©ä¸ºæŒ‡å®šé•¿åº¦çš„å£æ’­ç¨¿
    """
    try:
        user_message = f"""è¯·å°†ä»¥ä¸‹å†…å®¹æ™ºèƒ½å‹ç¼©ä¸º{target_length}å­—çš„å£æ’­ç¨¿ï¼Œåˆ†æˆ{num_segments}æ®µï¼Œæ¯æ®µçº¦{target_length//num_segments}å­—ã€‚

åŸæ–‡å†…å®¹ï¼š
{content}

è¦æ±‚ï¼š
1. ä¿æŒå†…å®¹çš„æ ¸å¿ƒä¿¡æ¯å’Œé€»è¾‘ç»“æ„
2. è¯­è¨€è¦é€‚åˆå£æ’­ï¼Œè‡ªç„¶æµç•…
3. åˆ†æˆ{num_segments}æ®µï¼Œæ¯æ®µç‹¬ç«‹å®Œæ•´
4. æ€»å­—æ•°æ§åˆ¶åœ¨{target_length}å­—å·¦å³
"""
        
        output = text_to_text(
            server=server, 
            model=model, 
            prompt=user_message, 
            system_message=summarize_system_prompt, 
            max_tokens=4096, 
            temperature=0.7
        )
        
        if output is None:
            raise ValueError("æœªèƒ½ä» API è·å–å“åº”ã€‚")
        
        # é²æ£’è§£æï¼ˆå…ˆå¸¸è§„ï¼Œå¤±è´¥åˆ™ä¿®å¤ï¼‰
        parsed_content = parse_json_robust(output)
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        required_keys = ["title", "segments"]
        if not all(key in parsed_content for key in required_keys):
            missing_keys = [key for key in required_keys if key not in parsed_content]
            raise ValueError(f"ç”Ÿæˆçš„ JSON ç¼ºå°‘å¿…éœ€çš„ Key: {', '.join(missing_keys)}")
        
        # æ·»åŠ ç³»ç»Ÿå­—æ®µ
        total_length = sum(len(segment['content']) for segment in parsed_content['segments'])
        
        enhanced_data = {
            "title": parsed_content["title"],
            "total_length": total_length,
            "target_segments": num_segments,
            "actual_segments": len(parsed_content["segments"]),
            "created_time": datetime.datetime.now().isoformat(),
            "model_info": {
                "llm_server": server,
                "llm_model": model,
                "generation_type": "script_generation"
            },
            "segments": []
        }
        
        # å¤„ç†æ¯ä¸ªæ®µè½ï¼Œæ·»åŠ è¯¦ç»†ä¿¡æ¯
        for i, segment in enumerate(parsed_content["segments"], 1):
            content_text = segment["content"]
            length = len(content_text)
            # æŒ‰ç…§æ¯åˆ†é’Ÿ300å­—è®¡ç®—æ’­æ”¾æ—¶é•¿
            estimated_duration = length / 300 * 60
            
            enhanced_data["segments"].append({
                "index": i,
                "content": content_text,
                "length": length,
                "estimated_duration": round(estimated_duration, 1)
            })
        
        return enhanced_data
    
    except json.JSONDecodeError:
        raise ValueError("è§£æ JSON è¾“å‡ºå¤±è´¥")
    except Exception as e:
        raise ValueError(f"æ™ºèƒ½ç¼©å†™å¤„ç†é”™è¯¯: {e}")

################ Keywords Extraction ################
def extract_keywords(server: str, model: str, script_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    å…³é”®è¯æå– - ç¬¬äºŒæ¬¡LLMå¤„ç†
    ä¸ºæ¯ä¸ªæ®µè½æå–å…³é”®è¯å’Œæ°›å›´è¯
    """
    try:
        segments_text = []
        for segment in script_data["segments"]:
            segments_text.append(f"ç¬¬{segment['index']}æ®µ: {segment['content']}")
        
        user_message = f"""è¯·ä¸ºä»¥ä¸‹æ¯ä¸ªæ®µè½æå–å…³é”®è¯å’Œæ°›å›´è¯ï¼Œç”¨äºå›¾åƒç”Ÿæˆï¼š

{chr(10).join(segments_text)}
"""
        
        output = text_to_text(
            server=server,
            model=model,
            prompt=user_message,
            system_message=keywords_extraction_prompt,
            max_tokens=4096,
            temperature=0.5
        )
        
        if output is None:
            raise ValueError("æœªèƒ½ä» API è·å–å“åº”ã€‚")
        
        # é²æ£’è§£æï¼ˆå…ˆå¸¸è§„ï¼Œå¤±è´¥åˆ™ä¿®å¤ï¼‰
        keywords_data = parse_json_robust(output)
        
        # éªŒè¯æ ¼å¼
        if "segments" not in keywords_data:
            raise ValueError("å…³é”®è¯æ•°æ®æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘segmentså­—æ®µ")
        
        # ç¡®ä¿æ®µè½æ•°é‡åŒ¹é…
        if len(keywords_data["segments"]) != len(script_data["segments"]):
            raise ValueError("å…³é”®è¯æ®µè½æ•°é‡ä¸å£æ’­ç¨¿ä¸åŒ¹é…")
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯
        keywords_data["model_info"] = {
            "llm_server": server,
            "llm_model": model,
            "generation_type": "keywords_extraction"
        }
        keywords_data["created_time"] = datetime.datetime.now().isoformat()
        
        return keywords_data
    
    except json.JSONDecodeError:
        raise ValueError("è§£æå…³é”®è¯ JSON è¾“å‡ºå¤±è´¥")
    except Exception as e:
        raise ValueError(f"å…³é”®è¯æå–é”™è¯¯: {e}")

################ Image Generation ################
def generate_images_for_segments(server: str, model: str, keywords_data: Dict[str, Any], 
                                image_style_preset: str, image_size: str, output_dir: str) -> List[str]:
    """
    ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆå›¾åƒ
    
    Args:
        server: å›¾åƒç”ŸæˆæœåŠ¡å•†
        model: å›¾åƒç”Ÿæˆæ¨¡å‹
        keywords_data: å…³é”®è¯æ•°æ®
        image_style_preset: å›¾åƒé£æ ¼é¢„è®¾åç§°
        image_size: å›¾åƒå°ºå¯¸
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        List[str]: ç”Ÿæˆå›¾åƒçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    try:
        image_paths = []
        
        # è·å–å›¾åƒé£æ ¼å­—ç¬¦ä¸²
        image_style = get_image_style(image_style_preset)
        logger.info(f"ä½¿ç”¨å›¾åƒé£æ ¼: {image_style_preset} -> {image_style}")
        
        for i, segment_keywords in enumerate(keywords_data["segments"], 1):
            keywords = segment_keywords.get("keywords", [])
            atmosphere = segment_keywords.get("atmosphere", [])
            
            # æ„å»ºå›¾åƒæç¤ºè¯
            prompt_parts = []
            if image_style:
                prompt_parts.append(image_style)
            
            prompt_parts.extend(keywords)
            prompt_parts.extend(atmosphere)
            prompt_parts.append("é«˜è´¨é‡ï¼Œç»†èŠ‚ä¸°å¯Œï¼Œä¸“ä¸šæ‘„å½±")
            
            final_prompt = ", ".join(prompt_parts)
            
            print(f"æ­£åœ¨ç”Ÿæˆç¬¬{i}æ®µå›¾åƒ...")
            
            # è°ƒç”¨è±†åŒ…å›¾åƒç”ŸæˆAPI
            image_url = text_to_image_doubao(
                prompt=final_prompt,
                size=image_size,
                model=model
            )
            
            if image_url:
                # ä¸‹è½½å¹¶ä¿å­˜å›¾åƒ
                response = requests.get(image_url)
                if response.status_code == 200:
                    image_path = os.path.join(output_dir, f"segment_{i}.png")
                    with open(image_path, 'wb') as f:
                        f.write(response.content)
                    image_paths.append(image_path)
                    print(f"ç¬¬{i}æ®µå›¾åƒå·²ä¿å­˜: {image_path}")
                else:
                    raise ValueError(f"ä¸‹è½½ç¬¬{i}æ®µå›¾åƒå¤±è´¥")
            else:
                raise ValueError(f"ç”Ÿæˆç¬¬{i}æ®µå›¾åƒå¤±è´¥")
        
        return image_paths
    
    except Exception as e:
        raise ValueError(f"å›¾åƒç”Ÿæˆé”™è¯¯: {e}")

################ Voice Synthesis ################
def synthesize_voice_for_segments(server: str, voice: str, script_data: Dict[str, Any], output_dir: str) -> List[str]:
    """
    ä¸ºæ¯ä¸ªæ®µè½åˆæˆè¯­éŸ³
    """
    try:
        audio_paths = []
        
        # ä»script_dataä¸­è·å–titleï¼Œç”¨äºæ–‡ä»¶å‘½å
        title = script_data.get('title', 'untitled')
        # æ¸…ç†titleä¸­çš„ç‰¹æ®Šå­—ç¬¦ï¼Œç¡®ä¿æ–‡ä»¶åå®‰å…¨
        safe_title = title.replace(' ', '_').replace('/', '_').replace('\\', '_').replace(':', '_').replace('?', '_').replace('*', '_').replace('"', '_').replace('<', '_').replace('>', '_').replace('|', '_')
        
        for segment in script_data["segments"]:
            segment_index = segment["index"]
            content = segment["content"]
            
            print(f"æ­£åœ¨ç”Ÿæˆç¬¬{segment_index}æ®µè¯­éŸ³...")
            
            # ç”Ÿæˆè¯­éŸ³æ–‡ä»¶è·¯å¾„ï¼š{title}_{åºå·}.wav
            audio_filename = f"{safe_title}_{segment_index}.wav"
            audio_path = os.path.join(output_dir, audio_filename)
            
            # è°ƒç”¨è¯­éŸ³åˆæˆAPI - æ ¹æ®è¯­éŸ³éŸ³è‰²æ™ºèƒ½é€‰æ‹©æ¥å£
            if server == "bytedance":
                # ä½¿ç”¨å­—èŠ‚è¯­éŸ³åˆæˆå¤§æ¨¡å‹æ¥å£
                success = text_to_audio_bytedance(
                    text=content,
                    output_filename=audio_path,
                    voice=voice
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„TTSæœåŠ¡å•†: {server}")
            
            if success:
                audio_paths.append(audio_path)
                print(f"ç¬¬{segment_index}æ®µè¯­éŸ³å·²ä¿å­˜: {audio_path}")
            else:
                raise ValueError(f"ç”Ÿæˆç¬¬{segment_index}æ®µè¯­éŸ³å¤±è´¥")
        
        return audio_paths
    
    except Exception as e:
        raise ValueError(f"è¯­éŸ³åˆæˆé”™è¯¯: {e}")

################ Video Composition ################
def compose_final_video(image_paths: List[str], audio_paths: List[str], output_path: str, 
                       script_data: Dict[str, Any] = None, enable_subtitles: bool = False,
                       bgm_audio_path: Optional[str] = None, bgm_volume: float = 0.15,
                       narration_volume: float = 1.0) -> str:
    """
    åˆæˆæœ€ç»ˆè§†é¢‘
    
    Args:
        image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        script_data: è„šæœ¬æ•°æ®ï¼Œç”¨äºç”Ÿæˆå­—å¹•
        enable_subtitles: æ˜¯å¦å¯ç”¨å­—å¹•
    
    Returns:
        str: è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    try:
        if len(image_paths) != len(audio_paths):
            raise ValueError("å›¾åƒæ–‡ä»¶æ•°é‡ä¸éŸ³é¢‘æ–‡ä»¶æ•°é‡ä¸åŒ¹é…")
        
        video_clips = []
        audio_clips = []
        
        # ä¸ºæ¯ä¸ªæ®µè½åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        for i, (image_path, audio_path) in enumerate(zip(image_paths, audio_paths)):
            print(f"æ­£åœ¨å¤„ç†ç¬¬{i+1}æ®µè§†é¢‘...")
            
            # åŠ è½½éŸ³é¢‘è·å–æ—¶é•¿
            audio_clip = AudioFileClip(audio_path)
            duration = audio_clip.duration
            
            # åˆ›å»ºå›¾åƒå‰ªè¾‘ï¼Œè®¾ç½®æŒç»­æ—¶é—´ä¸ºéŸ³é¢‘é•¿åº¦ (MoviePy 2.x ä½¿ç”¨ with_duration)
            image_clip = ImageClip(image_path).with_duration(duration)
            
            # ç»„åˆå›¾åƒå’ŒéŸ³é¢‘ (MoviePy 2.x ä½¿ç”¨ with_audio)
            video_clip = image_clip.with_audio(audio_clip)
            video_clips.append(video_clip)
            audio_clips.append(audio_clip)
        
        # è¿æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
        print("æ­£åœ¨åˆæˆæœ€ç»ˆè§†é¢‘...")
        # ä½¿ç”¨ compose æ–¹å¼åˆå¹¶ï¼Œé¿å…éŸ³é¢‘è½¨ä¸¢å¤±æˆ–ä¸åŒå°ºå¯¸å¯¼è‡´çš„é—®é¢˜
        final_video = concatenate_videoclips(video_clips, method="compose")
        
        # æ·»åŠ å­—å¹•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if enable_subtitles and script_data:
            print("æ­£åœ¨æ·»åŠ å­—å¹•...")
            try:
                # ä¼ å…¥æœ€ç»ˆè§†é¢‘å°ºå¯¸ï¼Œä¾¿äºå­—å¹•è®¡ç®—è¾¹è·/èƒŒæ™¯
                subtitle_config = config.SUBTITLE_CONFIG.copy()
                subtitle_config["video_size"] = final_video.size
                # ä¼ å…¥æ¯æ®µéŸ³é¢‘çœŸå®æ—¶é•¿ç”¨äºç²¾å‡†å¯¹é½
                subtitle_config["segment_durations"] = [ac.duration for ac in audio_clips]
                subtitle_clips = create_subtitle_clips(script_data, subtitle_config)
                if subtitle_clips:
                    # å°†å­—å¹•ä¸è§†é¢‘åˆæˆ
                    final_video = CompositeVideoClip([final_video] + subtitle_clips)
                    print(f"å·²æ·»åŠ  {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
                else:
                    print("æœªç”Ÿæˆä»»ä½•å­—å¹•å‰ªè¾‘")
            except Exception as e:
                logger.warning(f"æ·»åŠ å­—å¹•å¤±è´¥: {str(e)}ï¼Œç»§ç»­ç”Ÿæˆæ— å­—å¹•è§†é¢‘")

        # è°ƒæ•´å£æ’­éŸ³é‡ï¼ˆåœ¨ä¸BGMæ··éŸ³å‰ï¼‰â€”â€”MoviePy 2.x ä½¿ç”¨ MultiplyVolume
        try:
            if final_video.audio is not None and narration_volume is not None:
                narration_audio = final_video.audio
                if isinstance(narration_volume, (int, float)) and abs(float(narration_volume) - 1.0) > 1e-9:
                    narration_audio = narration_audio.with_effects([MultiplyVolume(float(narration_volume))])
                    final_video = final_video.with_audio(narration_audio)
                    print(f"ğŸ”Š å£æ’­éŸ³é‡è°ƒæ•´ä¸º: {float(narration_volume)}")
        except Exception as e:
            logger.warning(f"å£æ’­éŸ³é‡è°ƒæ•´å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨åŸå§‹éŸ³é‡")
        
        # å¯é€‰ï¼šå åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆä¸å£æ’­æ··éŸ³ï¼‰
        bgm_clip = None
        try:
            if bgm_audio_path and os.path.exists(bgm_audio_path):
                print(f"ğŸµ å¼€å§‹å¤„ç†èƒŒæ™¯éŸ³ä¹: {bgm_audio_path}")
                bgm_clip = AudioFileClip(bgm_audio_path)
                print(f"ğŸµ BGMåŠ è½½æˆåŠŸï¼Œæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
                
                # è°ƒæ•´ BGM éŸ³é‡ï¼ˆMoviePy 2.x MultiplyVolumeï¼‰
                try:
                    if isinstance(bgm_volume, (int, float)) and abs(float(bgm_volume) - 1.0) > 1e-9:
                        bgm_clip = bgm_clip.with_effects([MultiplyVolume(float(bgm_volume))])
                        print(f"ğŸµ BGMéŸ³é‡è°ƒæ•´ä¸º: {float(bgm_volume)}")
                except Exception:
                    print("âš ï¸ BGMéŸ³é‡è°ƒæ•´å¤±è´¥ï¼Œä½¿ç”¨åŸéŸ³é‡")
                    pass
                
                # å¾ªç¯æˆ–è£å‰ªè‡³è§†é¢‘æ€»æ—¶é•¿ï¼ˆä¼˜å…ˆä½¿ç”¨ audio_loopï¼Œæ›´ç¨³å¥ï¼‰
                try:
                    target_duration = final_video.duration
                    print(f"ğŸµ è§†é¢‘æ€»æ—¶é•¿: {target_duration:.2f}ç§’ï¼ŒBGMæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")

                    if AudioLoop is not None:
                        # ä½¿ç”¨ 2.x çš„ AudioLoop æ•ˆæœç±»
                        bgm_clip = bgm_clip.with_effects([AudioLoop(duration=target_duration)])
                        print(f"ğŸµ BGMé•¿åº¦é€‚é…å®Œæˆï¼ˆAudioLoopï¼‰ï¼Œæœ€ç»ˆæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
                    else:
                        # å°è¯•æ‰‹åŠ¨å¾ªç¯ç›´è‡³åŒ¹é…é•¿åº¦ï¼Œå¦åˆ™è£å‰ª
                        print("â„¹ï¸ audio_loop ä¸å¯ç”¨ï¼Œå°è¯•æ‰‹åŠ¨å¾ªç¯BGMâ€¦")
                        if concatenate_audioclips is not None:
                            try:
                                repeats = int(target_duration // bgm_clip.duration)
                                remainder = float(max(0.0, target_duration - repeats * bgm_clip.duration))
                                clips_to_concat = []
                                if repeats > 0:
                                    clips_to_concat.extend([bgm_clip] * repeats)
                                if remainder > 0:
                                    if hasattr(bgm_clip, "with_duration"):
                                        clips_to_concat.append(bgm_clip.with_duration(remainder))
                                if clips_to_concat:
                                    bgm_clip = concatenate_audioclips(clips_to_concat)
                                    print(f"ğŸµ BGMé•¿åº¦é€‚é…å®Œæˆï¼ˆmanual loopï¼‰ï¼Œæœ€ç»ˆæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
                                else:
                                    # æçŸ­è§†é¢‘ï¼šè£å‰ª
                                    if hasattr(bgm_clip, "with_duration"):
                                        bgm_clip = bgm_clip.with_duration(min(bgm_clip.duration, target_duration))
                                        print("âš ï¸ å·²å°†BGMè£å‰ªåˆ°ç›®æ ‡æ—¶é•¿")
                                    else:
                                        raise RuntimeError("æ— æ³•é€‚é…BGMé•¿åº¦ï¼šç¼ºå°‘with_durationèƒ½åŠ›")
                            except Exception as _manual_err:
                                print(f"âš ï¸ æ‰‹åŠ¨å¾ªç¯å¤±è´¥: {_manual_err}ï¼Œå›é€€ä¸ºè£å‰ªå¤„ç†")
                                if hasattr(bgm_clip, "with_duration"):
                                    bgm_clip = bgm_clip.with_duration(min(bgm_clip.duration, target_duration))
                                    print("âš ï¸ å·²å°†BGMè£å‰ªåˆ°ç›®æ ‡æ—¶é•¿")
                                else:
                                    raise RuntimeError("audio_loop ä¸å¯ç”¨ï¼Œæ‰‹åŠ¨å¾ªç¯å¤±è´¥ï¼Œä¸”ä¸æ”¯æŒ with_duration")
                        else:
                            # æ— æ³•æ‹¼æ¥ï¼šè£å‰ª
                            if hasattr(bgm_clip, "with_duration"):
                                bgm_clip = bgm_clip.with_duration(min(bgm_clip.duration, target_duration))
                                print("âš ï¸ audio_loop ä¸å¯ç”¨ï¼Œå·²å°†BGMè£å‰ªåˆ°ç›®æ ‡æ—¶é•¿")
                            else:
                                raise RuntimeError("audio_loop ä¸å¯ç”¨ï¼Œä¸”ä¸æ”¯æŒ with_duration")

                except Exception as loop_err:
                    print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹é•¿åº¦é€‚é…å¤±è´¥: {loop_err}ï¼Œå°†ä¸æ·»åŠ BGMç»§ç»­ç”Ÿæˆ")
                    logger.warning(f"èƒŒæ™¯éŸ³ä¹å¾ªç¯/è£å‰ªå¤±è´¥: {loop_err}ï¼Œå°†ä¸æ·»åŠ BGMç»§ç»­ç”Ÿæˆ")
                    bgm_clip = None
                    
                # åˆæˆå¤åˆéŸ³é¢‘
                if bgm_clip is not None:
                    print("ğŸµ å¼€å§‹åˆæˆèƒŒæ™¯éŸ³ä¹å’Œå£æ’­éŸ³é¢‘")
                    if final_video.audio is not None:
                        # å¯é€‰ï¼šè‡ªåŠ¨ Duckingï¼Œæ ¹æ®å£æ’­åŒ…ç»œåŠ¨æ€å‹ä½ BGMï¼ˆMoviePy 2.x é€šè¿‡ transform å®ç°æ—¶é—´å˜å¢ç›Šï¼‰
                        try:
                            if getattr(config, "AUDIO_DUCKING_ENABLED", False):
                                strength = float(getattr(config, "AUDIO_DUCKING_STRENGTH", 0.7))
                                smooth_sec = float(getattr(config, "AUDIO_DUCKING_SMOOTH_SECONDS", 0.12))
                                total_dur = float(final_video.duration)
                                # é‡‡æ ·é¢‘ç‡ï¼ˆåŒ…ç»œè®¡ç®—ï¼‰ï¼Œ20Hz è¶³å¤Ÿå¹³æ»‘ä¸”å¼€é”€ä½
                                env_fps = 20.0
                                num_samples = max(2, int(total_dur * env_fps) + 1)
                                times = np.linspace(0.0, total_dur, num_samples)
                                # ä¼°ç®—å£æ’­ç¬æ—¶å¹…åº¦ï¼ˆç»å¯¹å€¼ï¼Œé€šé“å–å‡å€¼ï¼‰
                                amp = np.zeros_like(times)
                                for i, t in enumerate(times):
                                    try:
                                        frame = final_video.audio.get_frame(float(min(max(0.0, t), total_dur - 1e-6)))
                                        # frame å½¢å¦‚ [L, R]
                                        amp[i] = float(np.mean(np.abs(frame)))
                                    except Exception:
                                        amp[i] = 0.0
                                # å¹³æ»‘ï¼ˆç®€å•æ»‘åŠ¨å¹³å‡çª—å£ï¼‰
                                win = max(1, int(smooth_sec * env_fps))
                                if win > 1:
                                    kernel = np.ones(win, dtype=float) / win
                                    amp = np.convolve(amp, kernel, mode="same")
                                # å½’ä¸€åŒ–
                                max_amp = float(np.max(amp)) if np.max(amp) > 1e-8 else 1.0
                                env = amp / max_amp
                                # è®¡ç®— duck å¢ç›Šæ›²çº¿ï¼šå£æ’­å¼º -> BGM æ›´ä½
                                gains = 1.0 - strength * env
                                gains = np.clip(gains, 0.0, 1.0)
                                # æ„å»ºæ—¶é—´å˜å¢ç›Šå‡½æ•°ï¼ˆæ”¯æŒæ ‡é‡/å‘é‡ tï¼‰
                                def _gain_lookup(t_any):
                                    import numpy as _np
                                    def _lookup_scalar(ts: float) -> float:
                                        if ts <= 0.0:
                                            return float(gains[0])
                                        if ts >= total_dur:
                                            return float(gains[-1])
                                        idx = int(ts * env_fps)
                                        if idx < 0:
                                            idx = 0
                                        if idx >= gains.shape[0]:
                                            idx = gains.shape[0] - 1
                                        return float(gains[idx])
                                    if hasattr(t_any, "__len__"):
                                        return _np.array([_lookup_scalar(float(ts)) for ts in t_any])
                                    return _lookup_scalar(float(t_any))

                                # åº”ç”¨æ—¶é—´å˜å¢ç›Šåˆ° BGMï¼ˆä½¿ç”¨ transformï¼‰ï¼Œæ³¨æ„å¤šå£°é“å¹¿æ’­ç»´åº¦
                                bgm_clip = bgm_clip.transform(
                                    lambda gf, t: (
                                        (_gain_lookup(t)[:, None] if hasattr(t, "__len__") else _gain_lookup(t))
                                        * gf(t)
                                    ),
                                    keep_duration=True,
                                )
                                print(f"ğŸšï¸ å·²å¯ç”¨è‡ªåŠ¨Duckingï¼ˆstrength={strength}, smooth={smooth_sec}sï¼‰")
                        except Exception as duck_err:
                            logger.warning(f"è‡ªåŠ¨Duckingå¤±è´¥: {duck_err}ï¼Œå°†ä½¿ç”¨æ’å®šéŸ³é‡BGM")

                        mixed_audio = CompositeAudioClip([final_video.audio, bgm_clip])
                        print("ğŸµ BGMä¸å£æ’­éŸ³é¢‘åˆæˆå®Œæˆ")
                    else:
                        mixed_audio = CompositeAudioClip([bgm_clip])
                        print("ğŸµ ä»…æ·»åŠ BGMéŸ³é¢‘ï¼ˆæ— å£æ’­éŸ³é¢‘ï¼‰")
                    final_video = final_video.with_audio(mixed_audio)
                    print("ğŸµ èƒŒæ™¯éŸ³ä¹æ·»åŠ æˆåŠŸï¼")
                else:
                    print("âŒ BGMå¤„ç†å¤±è´¥ï¼Œç”Ÿæˆæ— èƒŒæ™¯éŸ³ä¹è§†é¢‘")
            else:
                if bgm_audio_path:
                    print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ä¸å­˜åœ¨: {bgm_audio_path}")
                else:
                    print("â„¹ï¸ æœªæŒ‡å®šèƒŒæ™¯éŸ³ä¹æ–‡ä»¶")
        except Exception as e:
            print(f"âŒ èƒŒæ™¯éŸ³ä¹å¤„ç†å¼‚å¸¸: {str(e)}")
            logger.warning(f"èƒŒæ™¯éŸ³ä¹å¤„ç†å¤±è´¥: {str(e)}ï¼Œå°†ç»§ç»­ç”Ÿæˆæ— èƒŒæ™¯éŸ³ä¹çš„è§†é¢‘")

        # è¾“å‡ºæœ€ç»ˆè§†é¢‘ï¼ˆä½¿ç”¨å•è¡Œè¿›åº¦æ¡ï¼Œé¿å…ç»ˆç«¯åˆ·å±ï¼‰
        moviepy_logger = None
        try:
            if TqdmProgressBar is not None:
                moviepy_logger = TqdmProgressBar(tqdm_kwargs={"leave": False, "mininterval": 0.2})
            else:
                moviepy_logger = 'bar'
        except Exception:
            moviepy_logger = 'bar'

        final_video.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            logger=moviepy_logger
        )
        
        # é‡Šæ”¾èµ„æº
        for clip in video_clips:
            clip.close()
        for aclip in audio_clips:
            aclip.close()
        final_video.close()
        if bgm_clip is not None:
            try:
                bgm_clip.close()
            except Exception:
                pass
        
        print(f"æœ€ç»ˆè§†é¢‘å·²ä¿å­˜: {output_path}")
        return output_path
    
    except Exception as e:
        raise ValueError(f"è§†é¢‘åˆæˆé”™è¯¯: {e}")

################ Style Helper Functions ################
def get_image_style(style_name: str = "cinematic") -> str:
    """
    è·å–å›¾åƒé£æ ¼å­—ç¬¦ä¸²
    
    Args:
        style_name: é£æ ¼åç§°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç¬¬ä¸€ä¸ªé£æ ¼
    
    Returns:
        str: å›¾åƒé£æ ¼æè¿°å­—ç¬¦ä¸²
    """
    return IMAGE_STYLE_PRESETS.get(style_name, list(IMAGE_STYLE_PRESETS.values())[0])

def split_text_for_subtitle(text: str, max_chars_per_line: int = 20, max_lines: int = 2) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å‰²ä¸ºé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥ï¼Œä¸¥æ ¼æŒ‰æ¯è¡Œå­—ç¬¦æ•°é™åˆ¶
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_chars_per_line: æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°
        max_lines: æœ€å¤§è¡Œæ•°
    
    Returns:
        List[str]: åˆ†å‰²åçš„å­—å¹•æ–‡æœ¬åˆ—è¡¨
    """
    # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†
    if len(text) <= max_chars_per_line:
        return [text]
    
    # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²
    sentences = []
    current = ""
    for char in text:
        current += char
        if char in "ã€‚ï¼ï¼Ÿ":
            sentences.append(current.strip())
            current = ""
    
    if current.strip():
        sentences.append(current.strip())
    
    # å¦‚æœæ²¡æœ‰å¥å­åˆ†éš”ç¬¦ï¼Œå¼ºåˆ¶æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†
    if not sentences:
        result = []
        for i in range(0, len(text), max_chars_per_line):
            result.append(text[i:i + max_chars_per_line])
        return result
    
    # ç»„åˆå¥å­ï¼Œä¸¥æ ¼æŒ‰æ¯è¡Œå­—ç¬¦æ•°é™åˆ¶
    result = []
    current_subtitle = ""
    
    for sentence in sentences:
        # å¦‚æœå•ä¸ªå¥å­å°±è¶…è¿‡äº†æ¯è¡Œé™åˆ¶ï¼Œå¼ºåˆ¶åˆ‡åˆ†
        if len(sentence) > max_chars_per_line:
            if current_subtitle:
                result.append(current_subtitle)
                current_subtitle = ""
            # å¼ºåˆ¶æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†é•¿å¥å­
            for i in range(0, len(sentence), max_chars_per_line):
                result.append(sentence[i:i + max_chars_per_line])
        elif not current_subtitle:
            current_subtitle = sentence
        elif len(current_subtitle + sentence) <= max_chars_per_line:
            current_subtitle += sentence
        else:
            result.append(current_subtitle)
            current_subtitle = sentence
    
    if current_subtitle:
        result.append(current_subtitle)
    
    return result

def create_subtitle_clips(script_data: Dict[str, Any], subtitle_config: Dict[str, Any] = None) -> List[TextClip]:
    """
    åˆ›å»ºå­—å¹•å‰ªè¾‘åˆ—è¡¨
    
    Args:
        script_data: è„šæœ¬æ•°æ®ï¼ŒåŒ…å«segmentsä¿¡æ¯
        subtitle_config: å­—å¹•é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    
    Returns:
        List[TextClip]: å­—å¹•å‰ªè¾‘åˆ—è¡¨
    """
    if subtitle_config is None:
        from config import config
        subtitle_config = config.SUBTITLE_CONFIG.copy()
    
    subtitle_clips = []
    current_time = 0
    
    logger.info("å¼€å§‹åˆ›å»ºå­—å¹•å‰ªè¾‘...")
    
    # è§£æå¯ç”¨å­—ä½“ï¼ˆä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿä¸­çš„ä¸­æ–‡å­—ä½“æ–‡ä»¶è·¯å¾„ï¼Œé¿å…ä¸­æ–‡ç¼ºå­—ï¼‰
    def _resolve_font_path(preferred: Optional[str]) -> Optional[str]:
        # è‹¥ç›´æ¥ä¼ å…¥çš„æ˜¯å¯ç”¨è·¯å¾„ï¼Œåˆ™ç›´æ¥ä½¿ç”¨
        if preferred and os.path.exists(preferred):
            return preferred
        # å¸¸è§ macOS ä¸­æ–‡å­—ä½“æ–‡ä»¶è·¯å¾„å€™é€‰
        candidate_paths = [
            "/System/Library/Fonts/PingFang.ttc",
            "/System/Library/Fonts/Hiragino Sans GB.ttc",
            "/System/Library/Fonts/Supplemental/Songti.ttc",
            "/System/Library/Fonts/STHeiti Light.ttc",
            "/System/Library/Fonts/Supplemental/SimHei.ttf",
            "/System/Library/Fonts/Supplemental/SimSun.ttf",
            "/Library/Fonts/Arial Unicode.ttf",
            "/Library/Fonts/Arial Unicode MS.ttf",
        ]
        for path in candidate_paths:
            if os.path.exists(path):
                return path
        return preferred  # é€€å›åˆ°ä¼ å…¥åç§°ï¼ˆç”± PIL è‡ªè¡Œè§£æï¼‰

    resolved_font = _resolve_font_path(subtitle_config.get("font_family"))
    if not resolved_font:
        logger.warning("æœªèƒ½è§£æåˆ°å¯ç”¨ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½å¯¼è‡´å­—å¹•æ— æ³•æ˜¾ç¤ºä¸­æ–‡å­—ç¬¦ã€‚å»ºè®®åœ¨ config.SUBTITLE_CONFIG.font_family æŒ‡å®šå­—ä½“æ–‡ä»¶è·¯å¾„ã€‚")

    # è¯»å–è§†é¢‘å°ºå¯¸ï¼ˆç”¨äºè®¡ç®—åº•éƒ¨è¾¹è·å’ŒèƒŒæ™¯æ¡ï¼‰
    video_size = subtitle_config.get("video_size", (1280, 720))
    video_width, video_height = video_size

    segment_durations = subtitle_config.get("segment_durations", [])

    for i, segment in enumerate(script_data["segments"], 1):
        content = segment["content"]
        # ä¼˜å…ˆä½¿ç”¨çœŸå®éŸ³é¢‘æ—¶é•¿ï¼Œå…¶æ¬¡å›é€€åˆ°ä¼°ç®—æ—¶é•¿
        duration = None
        if isinstance(segment_durations, list) and len(segment_durations) >= i:
            duration = float(segment_durations[i-1])
        if duration is None:
            duration = float(segment.get("estimated_duration", 0))
        
        logger.debug(f"å¤„ç†ç¬¬{i}æ®µå­—å¹•ï¼Œæ—¶é•¿: {duration}ç§’")
        
        # åˆ†å‰²é•¿æ–‡æœ¬ä¸ºé€‚åˆæ˜¾ç¤ºçš„å­—å¹•
        subtitle_texts = split_text_for_subtitle(
            content,
            subtitle_config["max_chars_per_line"],
            subtitle_config["max_lines"]
        )
        
        # è®¡ç®—æ¯è¡Œå­—å¹•çš„æ˜¾ç¤ºæ—¶é•¿ï¼šæŒ‰è¡Œå­—ç¬¦æ•°å æ¯”åˆ†é…ï¼Œç¡®ä¿æ€»å’Œ==æ®µæ—¶é•¿
        subtitle_start_time = current_time
        line_durations: List[float] = []
        if len(subtitle_texts) > 0:
            lengths = [max(1, len(t)) for t in subtitle_texts]
            total_len = sum(lengths)
            acc = 0.0
            for idx, L in enumerate(lengths):
                if idx < len(lengths) - 1:
                    d = duration * (L / total_len)
                    line_durations.append(d)
                    acc += d
                else:
                    line_durations.append(max(0.0, duration - acc))
        else:
            line_durations = [duration]
        
        for subtitle_text, subtitle_duration in zip(subtitle_texts, line_durations):
            try:
                # è®¾ç½®ä½ç½®
                position = subtitle_config["position"]
                margin_bottom = int(subtitle_config.get("margin_bottom", 0))
                anchor_x = position[0] if isinstance(position, tuple) else "center"
                
                # åˆ›å»ºå­—å¹•å‰ªè¾‘ï¼ˆå¯èƒ½åŒ…å«é˜´å½±æ•ˆæœï¼‰
                if subtitle_config.get("shadow_enabled", False):
                    # åˆ›å»ºé˜´å½±æ•ˆæœï¼šå…ˆåˆ›å»ºé˜´å½±æ–‡æœ¬ï¼Œå†åˆ›å»ºä¸»æ–‡æœ¬
                    shadow_offset = subtitle_config.get("shadow_offset", (2, 2))
                    shadow_color = subtitle_config.get("shadow_color", "black")
                    
                    # åˆ›å»ºé˜´å½±æ–‡æœ¬å‰ªè¾‘
                    shadow_clip = TextClip(
                        text=subtitle_text,
                        font_size=subtitle_config["font_size"],
                        color=shadow_color,
                        font=resolved_font or subtitle_config["font_family"]
                    )
                    
                    # åˆ›å»ºä¸»æ–‡æœ¬å‰ªè¾‘
                    main_clip = TextClip(
                        text=subtitle_text,
                        font_size=subtitle_config["font_size"],
                        color=subtitle_config["color"],
                        font=resolved_font or subtitle_config["font_family"],
                        stroke_color=subtitle_config["stroke_color"],
                        stroke_width=subtitle_config["stroke_width"]
                    )
                    
                    # è®¡ç®—é˜´å½±ä½ç½®ï¼ˆç®€åŒ–å¤„ç†ï¼Œä½¿ç”¨ç›¸åŒçš„ä¸»è¦ä½ç½®ä½†ç¨å¾®åç§»ï¼‰
                    # å¯¹äºé˜´å½±æ•ˆæœï¼Œæˆ‘ä»¬ä½¿ç”¨ç›¸åŒçš„åŸºç¡€ä½ç½®ï¼Œè®©MoviePyçš„strokeæ•ˆæœæ¥å¤„ç†é˜´å½±
                    shadow_pos = position
                    
                    # è®¾ç½®æ—¶é—´å’Œä½ç½®
                    # è®¡ç®—æ–‡æœ¬çš„å®é™… y åæ ‡ï¼ˆå½“å®šä½åˆ° bottom æ—¶ï¼Œä½¿ç”¨è¾¹è·é¿å…å‡ºç•Œï¼‰
                    if isinstance(position, tuple) and len(position) == 2 and position[1] == "bottom":
                        y_text = max(0, video_height - margin_bottom - main_clip.h)
                        main_pos = (anchor_x, y_text)
                        shadow_pos = (anchor_x, y_text)
                    else:
                        main_pos = position
                        shadow_pos = position
                    shadow_clip = shadow_clip.with_position(shadow_pos).with_start(subtitle_start_time).with_duration(subtitle_duration)
                    main_clip = main_clip.with_position(main_pos).with_start(subtitle_start_time).with_duration(subtitle_duration)
                    
                    clips_to_add = []
                    # èƒŒæ™¯æ¡
                    bg_color = subtitle_config.get("background_color")
                    bg_opacity = float(subtitle_config.get("background_opacity", 0))
                    if bg_color:
                        bg_height = int(subtitle_config["font_size"] * subtitle_config.get("max_lines", 2) + subtitle_config.get("line_spacing", 10) + 20)
                        bg_clip = ColorClip(size=(video_width, bg_height), color=bg_color)
                        if hasattr(bg_clip, "with_opacity"):
                            bg_clip = bg_clip.with_opacity(bg_opacity)
                        y_bg = max(0, video_height - margin_bottom - bg_height)
                        bg_clip = bg_clip.with_position(("center", y_bg)).with_start(subtitle_start_time).with_duration(subtitle_duration)
                        clips_to_add.append(bg_clip)
                    clips_to_add.extend([shadow_clip, main_clip])
                    subtitle_clips.extend(clips_to_add)
                    
                    logger.debug(f"åˆ›å»ºé˜´å½±å­—å¹•: '{subtitle_text[:20]}...' æ—¶é—´: {subtitle_start_time:.1f}-{subtitle_start_time+subtitle_duration:.1f}s")
                
                else:
                    # åˆ›å»ºæ™®é€šå­—å¹•æ–‡æœ¬å‰ªè¾‘ï¼ˆæ— é˜´å½±ï¼‰
                    txt_clip = TextClip(
                        text=subtitle_text,
                        font_size=subtitle_config["font_size"],
                        color=subtitle_config["color"],
                        font=resolved_font or subtitle_config["font_family"],
                        stroke_color=subtitle_config["stroke_color"],
                        stroke_width=subtitle_config["stroke_width"]
                    )
                    
                    # è®¡ç®—æ–‡æœ¬çš„å®é™… y åæ ‡ï¼ˆå½“å®šä½åˆ° bottom æ—¶ï¼Œä½¿ç”¨è¾¹è·é¿å…å‡ºç•Œï¼‰
                    if isinstance(position, tuple) and len(position) == 2 and position[1] == "bottom":
                        y_text = max(0, video_height - margin_bottom - txt_clip.h)
                        txt_pos = (anchor_x, y_text)
                    else:
                        txt_pos = position
                    txt_clip = txt_clip.with_position(txt_pos).with_start(subtitle_start_time).with_duration(subtitle_duration)

                    clips_to_add = []
                    # èƒŒæ™¯æ¡
                    bg_color = subtitle_config.get("background_color")
                    bg_opacity = float(subtitle_config.get("background_opacity", 0))
                    if bg_color:
                        bg_height = int(subtitle_config["font_size"] * subtitle_config.get("max_lines", 2) + subtitle_config.get("line_spacing", 10) + 20)
                        bg_clip = ColorClip(size=(video_width, bg_height), color=bg_color)
                        if hasattr(bg_clip, "with_opacity"):
                            bg_clip = bg_clip.with_opacity(bg_opacity)
                        y_bg = max(0, video_height - margin_bottom - bg_height)
                        bg_clip = bg_clip.with_position(("center", y_bg)).with_start(subtitle_start_time).with_duration(subtitle_duration)
                        clips_to_add.append(bg_clip)
                    clips_to_add.append(txt_clip)
                    subtitle_clips.extend(clips_to_add)
                    
                    logger.debug(f"åˆ›å»ºå­—å¹•: '{subtitle_text[:20]}...' æ—¶é—´: {subtitle_start_time:.1f}-{subtitle_start_time+subtitle_duration:.1f}s")
                
                subtitle_start_time += subtitle_duration
                
            except Exception as e:
                logger.warning(f"åˆ›å»ºå­—å¹•å¤±è´¥: {str(e)}ï¼Œè·³è¿‡æ­¤å­—å¹•")
                continue
        
        current_time += duration
    
    logger.info(f"å­—å¹•åˆ›å»ºå®Œæˆï¼Œå…±åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
    return subtitle_clips