"""
æ™ºèƒ½è§†é¢‘åˆ¶ä½œç³»ç»Ÿ - æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
åŒ…å«æ–‡æ¡£è¯»å–ã€æ™ºèƒ½å¤„ç†ã€å›¾åƒç”Ÿæˆã€è¯­éŸ³åˆæˆã€è§†é¢‘åˆ¶ä½œç­‰åŠŸèƒ½
"""

from moviepy import ImageClip, AudioFileClip, CompositeVideoClip, concatenate_videoclips, TextClip, ColorClip, CompositeAudioClip
# MoviePy 2.x: ä½¿ç”¨ç±»æ•ˆæœ API
try:
    from moviepy.audio.fx.AudioLoop import AudioLoop  # type: ignore
except Exception:
    AudioLoop = None  # fallback later
from moviepy.audio.fx.MultiplyVolume import MultiplyVolume  # type: ignore
from typing import Optional, Dict, Any, List, Tuple
import requests
import json
import os
import re
import datetime
import ebooklib
from ebooklib import epub
import PyPDF2
import pdfplumber

from prompts import summarize_system_prompt, keywords_extraction_prompt, IMAGE_STYLE_PRESETS
from genai_api import text_to_text, text_to_image_doubao, text_to_audio_bytedance
from config import config
 
from utils import (
    logger, FileProcessingError, APIError,
    log_function_call, ensure_directory_exists, clean_text, 
    validate_file_format
)
from utils import parse_json_robust
import numpy as np

# ç»Ÿä¸€å­—ä½“è§£æï¼šä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿä¸­æ–‡å­—ä½“è·¯å¾„ï¼Œå¤±è´¥å›é€€åˆ°ä¼ å…¥åç§°
def resolve_font_path(preferred: Optional[str]) -> Optional[str]:
    if preferred and os.path.exists(preferred):
        return preferred
    candidate_paths = [
        "/System/Library/Fonts/PingFang.ttc",
        "/System/Library/Fonts/Hiragino Sans GB.ttc",
        "/System/Library/Fonts/Supplemental/Songti.ttc",
        "/System/Library/Fonts/STHeiti Light.ttc",
        "/System/Library/Fonts/Supplemental/SimHei.ttf",
        "/System/Library/Fonts/Supplemental/SimSun.ttf",
        "/Library/Fonts/Arial Unicode.ttf",
        "/Library/Fonts/Arial Unicode MS.ttf",
    ]
    for path in candidate_paths:
        if os.path.exists(path):
            return path
    return preferred

# é€šç”¨ä¸‹è½½å™¨ï¼šä¸‹è½½äºŒè¿›åˆ¶å†…å®¹å¹¶ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„
def download_to_path(url: str, output_path: str, error_msg: str = "ä¸‹è½½å¤±è´¥") -> None:
    response = requests.get(url)
    if response.status_code != 200:
        raise ValueError(error_msg)
    with open(output_path, 'wb') as f:
        f.write(response.content)

################ Document Reading ################
@log_function_call
def read_document(file_path: str) -> Tuple[str, int]:
    """
    è¯»å–EPUBæˆ–PDFæ–‡æ¡£ï¼Œè¿”å›å†…å®¹å’Œå­—æ•°
    
    Args:
        file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
    
    Returns:
        Tuple[str, int]: (æ–‡æ¡£å†…å®¹, å­—æ•°)
    """
    # éªŒè¯æ–‡ä»¶æ ¼å¼
    validate_file_format(file_path, config.SUPPORTED_INPUT_FORMATS)
    
    file_extension = os.path.splitext(file_path)[1].lower()
    
    logger.info(f"å¼€å§‹è¯»å–{file_extension.upper()}æ–‡ä»¶: {os.path.basename(file_path)}")
    
    if file_extension == '.epub':
        return read_epub(file_path)
    elif file_extension == '.pdf':
        return read_pdf(file_path)
    else:
        raise FileProcessingError(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_extension}")

def read_epub(file_path: str) -> Tuple[str, int]:
    """è¯»å–EPUBæ–‡ä»¶å†…å®¹"""
    try:
        book = epub.read_epub(file_path)
        content_parts = []
        
        logger.debug("æ­£åœ¨æå–EPUBæ–‡ä»¶ä¸­çš„æ–‡æœ¬å†…å®¹...")
        
        # è·å–æ‰€æœ‰æ–‡æœ¬å†…å®¹
        for item in book.get_items():
            if item.get_type() == ebooklib.ITEM_DOCUMENT:
                content = item.get_content().decode('utf-8')
                # æ¸…ç†HTMLæ ‡ç­¾å’Œæ ¼å¼åŒ–æ–‡æœ¬
                content = clean_text(content)
                if content:
                    content_parts.append(content)
        
        if not content_parts:
            raise FileProcessingError("EPUBæ–‡ä»¶ä¸­æœªæ‰¾åˆ°å¯è¯»å–çš„æ–‡æœ¬å†…å®¹")
        
        full_content = ' '.join(content_parts)
        word_count = len(full_content)
        
        logger.info(f"EPUBæ–‡ä»¶è¯»å–æˆåŠŸï¼Œæ€»å­—æ•°: {word_count:,}å­—")
        return full_content, word_count
    
    except Exception as e:
        logger.error(f"è¯»å–EPUBæ–‡ä»¶å¤±è´¥: {str(e)}")
        raise FileProcessingError(f"è¯»å–EPUBæ–‡ä»¶å¤±è´¥: {str(e)}")

def read_pdf(file_path: str) -> Tuple[str, int]:
    """è¯»å–PDFæ–‡ä»¶å†…å®¹"""
    try:
        content_parts = []
        
        logger.debug("æ­£åœ¨ä½¿ç”¨pdfplumberæå–PDFæ–‡æœ¬...")
        
        # å…ˆå°è¯•pdfplumberï¼ˆæ›´å‡†ç¡®çš„æ–‡æœ¬æå–ï¼‰
        with pdfplumber.open(file_path) as pdf:
            for i, page in enumerate(pdf.pages, 1):
                text = page.extract_text()
                if text:
                    content_parts.append(text)
                    logger.debug(f"å·²æå–ç¬¬{i}é¡µå†…å®¹ï¼Œå­—ç¬¦æ•°: {len(text)}")
        
        # å¦‚æœpdfplumberæ²¡æœ‰æå–åˆ°å†…å®¹ï¼Œå°è¯•PyPDF2
        if not content_parts:
            logger.debug("pdfplumberæœªæå–åˆ°å†…å®¹ï¼Œå°è¯•ä½¿ç”¨PyPDF2...")
            with open(file_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for i, page in enumerate(pdf_reader.pages, 1):
                    text = page.extract_text()
                    if text:
                        content_parts.append(text)
                        logger.debug(f"å·²æå–ç¬¬{i}é¡µå†…å®¹ï¼Œå­—ç¬¦æ•°: {len(text)}")
        
        if not content_parts:
            raise FileProcessingError("æ— æ³•ä»PDFæ–‡ä»¶ä¸­æå–æ–‡æœ¬å†…å®¹ï¼Œå¯èƒ½æ˜¯æ‰«æç‰ˆPDF")
        
        full_content = ' '.join(content_parts)
        # æ¸…ç†æ–‡æœ¬
        full_content = clean_text(full_content)
        word_count = len(full_content)
        
        logger.info(f"PDFæ–‡ä»¶è¯»å–æˆåŠŸï¼Œæ€»å­—æ•°: {word_count:,}å­—")
        return full_content, word_count
    
    except Exception as e:
        logger.error(f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}")
        raise FileProcessingError(f"è¯»å–PDFæ–‡ä»¶å¤±è´¥: {str(e)}")

################ Intelligent Summarization ################
def intelligent_summarize(server: str, model: str, content: str, target_length: int, num_segments: int) -> Dict[str, Any]:
    """
    æ™ºèƒ½ç¼©å†™ - ç¬¬ä¸€æ¬¡LLMå¤„ç†
    å°†é•¿ç¯‡å†…å®¹å‹ç¼©ä¸ºæŒ‡å®šé•¿åº¦çš„å£æ’­ç¨¿
    """
    try:
        user_message = f"""è¯·å°†ä»¥ä¸‹å†…å®¹æ™ºèƒ½å‹ç¼©ä¸º{target_length}å­—çš„å£æ’­ç¨¿ï¼Œåˆ†æˆ{num_segments}æ®µï¼Œæ¯æ®µçº¦{target_length//num_segments}å­—ã€‚

åŸæ–‡å†…å®¹ï¼š
{content}

è¦æ±‚ï¼š
1. ä¿æŒå†…å®¹çš„æ ¸å¿ƒä¿¡æ¯å’Œé€»è¾‘ç»“æ„
2. è¯­è¨€è¦é€‚åˆå£æ’­ï¼Œè‡ªç„¶æµç•…
3. åˆ†æˆ{num_segments}æ®µï¼Œæ¯æ®µç‹¬ç«‹å®Œæ•´
4. æ€»å­—æ•°æ§åˆ¶åœ¨{target_length}å­—å·¦å³
"""
        
        output = text_to_text(
            server=server, 
            model=model, 
            prompt=user_message, 
            system_message=summarize_system_prompt, 
            max_tokens=4096, 
            temperature=0.7
        )
        
        if output is None:
            raise ValueError("æœªèƒ½ä» API è·å–å“åº”ã€‚")
        
        # é²æ£’è§£æï¼ˆå…ˆå¸¸è§„ï¼Œå¤±è´¥åˆ™ä¿®å¤ï¼‰
        parsed_content = parse_json_robust(output)
        
        # éªŒè¯å¿…éœ€å­—æ®µï¼ˆgolden_quote ä¸ºå¯é€‰ï¼‰
        required_keys = ["title", "segments"]
        if not all(key in parsed_content for key in required_keys):
            missing_keys = [key for key in required_keys if key not in parsed_content]
            raise ValueError(f"ç”Ÿæˆçš„ JSON ç¼ºå°‘å¿…éœ€çš„ Key: {', '.join(missing_keys)}")
        
        # æ·»åŠ ç³»ç»Ÿå­—æ®µ
        total_length = sum(len(segment['content']) for segment in parsed_content['segments'])
        
        enhanced_data = {
            "title": parsed_content["title"],
            "golden_quote": parsed_content.get("golden_quote", ""),
            "total_length": total_length,
            "target_segments": num_segments,
            "actual_segments": len(parsed_content["segments"]),
            "created_time": datetime.datetime.now().isoformat(),
            "model_info": {
                "llm_server": server,
                "llm_model": model,
                "generation_type": "script_generation"
            },
            "segments": []
        }
        
        # å¤„ç†æ¯ä¸ªæ®µè½ï¼Œæ·»åŠ è¯¦ç»†ä¿¡æ¯
        for i, segment in enumerate(parsed_content["segments"], 1):
            content_text = segment["content"]
            length = len(content_text)
            # ä½¿ç”¨é…ç½®çš„è¯­é€Ÿä¼°ç®—æ’­æ”¾æ—¶é•¿ï¼ˆæ¯åˆ†é’Ÿå­—æ•°ï¼‰
            wpm = int(getattr(config, "SPEECH_SPEED_WPM", 300))
            estimated_duration = length / max(1, wpm) * 60
            
            enhanced_data["segments"].append({
                "index": i,
                "content": content_text,
                "length": length,
                "estimated_duration": round(estimated_duration, 1)
            })
        
        return enhanced_data
    
    except json.JSONDecodeError:
        raise ValueError("è§£æ JSON è¾“å‡ºå¤±è´¥")
    except Exception as e:
        raise ValueError(f"æ™ºèƒ½ç¼©å†™å¤„ç†é”™è¯¯: {e}")

################ Keywords Extraction ################
def extract_keywords(server: str, model: str, script_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    å…³é”®è¯æå– - ç¬¬äºŒæ¬¡LLMå¤„ç†
    ä¸ºæ¯ä¸ªæ®µè½æå–å…³é”®è¯å’Œæ°›å›´è¯
    """
    try:
        segments_text = []
        for segment in script_data["segments"]:
            segments_text.append(f"ç¬¬{segment['index']}æ®µ: {segment['content']}")
        
        user_message = f"""è¯·ä¸ºä»¥ä¸‹æ¯ä¸ªæ®µè½æå–å…³é”®è¯å’Œæ°›å›´è¯ï¼Œç”¨äºå›¾åƒç”Ÿæˆï¼š

{chr(10).join(segments_text)}
"""
        
        output = text_to_text(
            server=server,
            model=model,
            prompt=user_message,
            system_message=keywords_extraction_prompt,
            max_tokens=4096,
            temperature=0.5
        )
        
        if output is None:
            raise ValueError("æœªèƒ½ä» API è·å–å“åº”ã€‚")
        
        # é²æ£’è§£æï¼ˆå…ˆå¸¸è§„ï¼Œå¤±è´¥åˆ™ä¿®å¤ï¼‰
        keywords_data = parse_json_robust(output)
        
        # éªŒè¯æ ¼å¼
        if "segments" not in keywords_data:
            raise ValueError("å…³é”®è¯æ•°æ®æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘segmentså­—æ®µ")
        
        # ç¡®ä¿æ®µè½æ•°é‡åŒ¹é…
        if len(keywords_data["segments"]) != len(script_data["segments"]):
            raise ValueError("å…³é”®è¯æ®µè½æ•°é‡ä¸å£æ’­ç¨¿ä¸åŒ¹é…")
        
        # æ·»åŠ æ¨¡å‹ä¿¡æ¯
        keywords_data["model_info"] = {
            "llm_server": server,
            "llm_model": model,
            "generation_type": "keywords_extraction"
        }
        keywords_data["created_time"] = datetime.datetime.now().isoformat()
        
        return keywords_data
    
    except json.JSONDecodeError:
        raise ValueError("è§£æå…³é”®è¯ JSON è¾“å‡ºå¤±è´¥")
    except Exception as e:
        raise ValueError(f"å…³é”®è¯æå–é”™è¯¯: {e}")

################ Image Generation ################
def generate_opening_image(server: str, model: str, keywords_data: Dict[str, Any],
                           image_style_preset: str, image_size: str, output_dir: str) -> Optional[str]:
    """
    åŸºäºå…³é”®è¯æ•°æ®ä¸­çš„ opening_image ç”Ÿæˆå¼€åœºå›¾åƒï¼ˆç®€æ´æŠ½è±¡ï¼‰ã€‚

    ä»…æ¶ˆè´¹ opening_image ä¸­çš„ä¸¤ç±»å­—æ®µï¼š
      - keywords: å…·è±¡å¯è§†åŒ–çš„ç”»é¢å…ƒç´ 
      - atmosphere: æŠ½è±¡æ°›å›´/é£æ ¼è¯ï¼ˆå¼ºè°ƒé«˜å¯¹æ¯”åº¦ã€å¼ºçƒˆå†²å‡»ç­‰ï¼‰

    è¿”å›ç”Ÿæˆçš„å¼€åœºå›¾åƒè·¯å¾„ï¼›è‹¥ç¼ºå°‘æ‰€éœ€å­—æ®µåˆ™è¿”å› Noneã€‚
    """
    try:
        opening = (keywords_data or {}).get("opening_image") or {}
        if not isinstance(opening, dict):
            return None

        # ä»…æ¶ˆè´¹ keywords / atmosphere
        keywords = opening.get("keywords", []) or []
        atmosphere = opening.get("atmosphere", []) or []

        # åŸºç¡€é£æ ¼ï¼šæç®€ã€æŠ½è±¡
        minimalist_style = get_image_style("minimalist")
        base_style_parts: List[str] = [minimalist_style, "ç®€æ´æŠ½è±¡", "ç•™ç™½", "å¹²å‡€æ„å›¾"]

        # å¼ºåŒ–æ°›å›´é»˜è®¤å€¼ï¼ˆè‹¥æœªè¦†ç›–ï¼‰
        emphasis = ["é«˜å¯¹æ¯”åº¦", "å¼ºçƒˆè§†è§‰å†²å‡»", "æˆå‰§æ€§å…‰å½±"]
        # åˆå¹¶ atmosphere ä¸é»˜è®¤å¼ºè°ƒè¯ï¼Œä¿åºå»é‡
        atmo_merged: List[str] = []
        for item in list(atmosphere) + emphasis:
            if item and item not in atmo_merged:
                atmo_merged.append(item)

        prompt_parts: List[str] = []
        prompt_parts.extend(base_style_parts)
        if isinstance(keywords, list):
            prompt_parts.extend(keywords[:8])
        prompt_parts.extend(atmo_merged[:6])
        prompt_parts.append("é«˜è´¨é‡ï¼Œä¸“ä¸šå½±åƒ")

        final_prompt = ", ".join([p for p in prompt_parts if p])

        # è°ƒç”¨è±†åŒ…å›¾åƒç”ŸæˆAPI
        image_url = text_to_image_doubao(
            prompt=final_prompt,
            size=image_size,
            model=model
        )

        if not image_url:
            raise ValueError("å¼€åœºå›¾åƒç”Ÿæˆå¤±è´¥")

        # ä¸‹è½½å¹¶ä¿å­˜
        ensure_directory_exists(output_dir)
        image_path = os.path.join(output_dir, "opening.png")
        download_to_path(image_url, image_path, error_msg="å¼€åœºå›¾åƒä¸‹è½½å¤±è´¥")
        print(f"å¼€åœºå›¾åƒå·²ä¿å­˜: {image_path}")
        return image_path
    except Exception as e:
        logger.warning(f"å¼€åœºå›¾åƒç”Ÿæˆå¤±è´¥: {e}")
        return None
def generate_images_for_segments(server: str, model: str, keywords_data: Dict[str, Any], 
                                image_style_preset: str, image_size: str, output_dir: str) -> List[str]:
    """
    ä¸ºæ¯ä¸ªæ®µè½ç”Ÿæˆå›¾åƒ
    
    Args:
        server: å›¾åƒç”ŸæˆæœåŠ¡å•†
        model: å›¾åƒç”Ÿæˆæ¨¡å‹
        keywords_data: å…³é”®è¯æ•°æ®
        image_style_preset: å›¾åƒé£æ ¼é¢„è®¾åç§°
        image_size: å›¾åƒå°ºå¯¸
        output_dir: è¾“å‡ºç›®å½•
    
    Returns:
        List[str]: ç”Ÿæˆå›¾åƒçš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    try:
        image_paths = []
        
        # è·å–å›¾åƒé£æ ¼å­—ç¬¦ä¸²
        image_style = get_image_style(image_style_preset)
        logger.info(f"ä½¿ç”¨å›¾åƒé£æ ¼: {image_style_preset} -> {image_style}")
        
        for i, segment_keywords in enumerate(keywords_data["segments"], 1):
            keywords = segment_keywords.get("keywords", [])
            atmosphere = segment_keywords.get("atmosphere", [])
            
            # æ„å»ºå›¾åƒæç¤ºè¯
            prompt_parts = []
            if image_style:
                prompt_parts.append(image_style)
            
            prompt_parts.extend(keywords)
            prompt_parts.extend(atmosphere)
            prompt_parts.append("é«˜è´¨é‡ï¼Œç»†èŠ‚ä¸°å¯Œï¼Œä¸“ä¸šæ‘„å½±")
            
            final_prompt = ", ".join(prompt_parts)
            
            print(f"æ­£åœ¨ç”Ÿæˆç¬¬{i}æ®µå›¾åƒ...")
            
            # è°ƒç”¨è±†åŒ…å›¾åƒç”ŸæˆAPI
            image_url = text_to_image_doubao(
                prompt=final_prompt,
                size=image_size,
                model=model
            )
            
            if image_url:
                # ä¸‹è½½å¹¶ä¿å­˜å›¾åƒ
                image_path = os.path.join(output_dir, f"segment_{i}.png")
                download_to_path(image_url, image_path, error_msg=f"ä¸‹è½½ç¬¬{i}æ®µå›¾åƒå¤±è´¥")
                image_paths.append(image_path)
                print(f"ç¬¬{i}æ®µå›¾åƒå·²ä¿å­˜: {image_path}")
            else:
                raise ValueError(f"ç”Ÿæˆç¬¬{i}æ®µå›¾åƒå¤±è´¥")
        
        return image_paths
    
    except Exception as e:
        raise ValueError(f"å›¾åƒç”Ÿæˆé”™è¯¯: {e}")

################ Voice Synthesis ################
def synthesize_voice_for_segments(server: str, voice: str, script_data: Dict[str, Any], output_dir: str) -> List[str]:
    """
    ä¸ºæ¯ä¸ªæ®µè½åˆæˆè¯­éŸ³
    """
    try:
        audio_paths = []
        
        for segment in script_data["segments"]:
            segment_index = segment["index"]
            content = segment["content"]
            
            print(f"æ­£åœ¨ç”Ÿæˆç¬¬{segment_index}æ®µè¯­éŸ³...")
            
            # ç”Ÿæˆè¯­éŸ³æ–‡ä»¶è·¯å¾„ï¼švoice_{åºå·}.wav
            audio_filename = f"voice_{segment_index}.wav"
            audio_path = os.path.join(output_dir, audio_filename)
            
            # è°ƒç”¨è¯­éŸ³åˆæˆAPI - æ ¹æ®è¯­éŸ³éŸ³è‰²æ™ºèƒ½é€‰æ‹©æ¥å£
            if server == "bytedance":
                # ä½¿ç”¨å­—èŠ‚è¯­éŸ³åˆæˆå¤§æ¨¡å‹æ¥å£
                success = text_to_audio_bytedance(
                    text=content,
                    output_filename=audio_path,
                    voice=voice
                )
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„TTSæœåŠ¡å•†: {server}")
            
            if success:
                audio_paths.append(audio_path)
                print(f"ç¬¬{segment_index}æ®µè¯­éŸ³å·²ä¿å­˜: {audio_path}")
            else:
                raise ValueError(f"ç”Ÿæˆç¬¬{segment_index}æ®µè¯­éŸ³å¤±è´¥")
        
        return audio_paths
    
    except Exception as e:
        raise ValueError(f"è¯­éŸ³åˆæˆé”™è¯¯: {e}")

################ Video Composition ################
def compose_final_video(image_paths: List[str], audio_paths: List[str], output_path: str, 
                       script_data: Dict[str, Any] = None, enable_subtitles: bool = False,
                       bgm_audio_path: Optional[str] = None, bgm_volume: float = 0.15,
                       narration_volume: float = 1.0,
                       opening_image_path: Optional[str] = None,
                       opening_golden_quote: Optional[str] = None,
                       opening_narration_audio_path: Optional[str] = None) -> str:
    """
    åˆæˆæœ€ç»ˆè§†é¢‘
    
    Args:
        image_paths: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        audio_paths: éŸ³é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        script_data: è„šæœ¬æ•°æ®ï¼Œç”¨äºç”Ÿæˆå­—å¹•
        enable_subtitles: æ˜¯å¦å¯ç”¨å­—å¹•
    
    Returns:
        str: è¾“å‡ºè§†é¢‘è·¯å¾„
    """
    try:
        if len(image_paths) != len(audio_paths):
            raise ValueError("å›¾åƒæ–‡ä»¶æ•°é‡ä¸éŸ³é¢‘æ–‡ä»¶æ•°é‡ä¸åŒ¹é…")
        
        video_clips = []
        audio_clips = []
        
        # å¯é€‰ï¼šåˆ›å»ºå¼€åœºç‰‡æ®µï¼ˆå›¾åƒ + å±…ä¸­é‡‘å¥ + å¯é€‰å¼€åœºå£æ’­ï¼‰
        # å¼€åœºæ—¶é•¿é€»è¾‘ï¼šè‹¥æä¾›å¼€åœºå£æ’­ => æ—¶é•¿=å£æ’­æ—¶é•¿+OPENING_HOLD_AFTER_NARRATION_SECONDSï¼›å¦åˆ™æ— å¼€åœº
        opening_seconds = 0.0
        opening_voice_clip = None
        # è‹¥æä¾›å¼€åœºå£æ’­éŸ³é¢‘ï¼Œåˆ™ä»¥â€œéŸ³é¢‘é•¿åº¦ + åœç•™æ—¶é•¿â€ä½œä¸ºæ€»å¼€åœºæ—¶é•¿
        try:
            if opening_narration_audio_path and os.path.exists(opening_narration_audio_path):
                opening_voice_clip = AudioFileClip(opening_narration_audio_path)
                hold_after = float(getattr(config, "OPENING_HOLD_AFTER_NARRATION_SECONDS", 2.0))
                opening_seconds = float(opening_voice_clip.duration) + max(0.0, hold_after)
        except Exception as _oaerr:
            logger.warning(f"å¼€åœºå£æ’­éŸ³é¢‘åŠ è½½å¤±è´¥: {_oaerr}ï¼Œå°†é€€å›å›ºå®šæ—¶é•¿å¼€åœº")
            opening_voice_clip = None
        
        if opening_image_path and os.path.exists(opening_image_path) and opening_seconds > 1e-3:
            try:
                print("æ­£åœ¨åˆ›å»ºå¼€åœºç‰‡æ®µâ€¦")
                opening_base = ImageClip(opening_image_path).with_duration(opening_seconds)

                # è§£æå¯ç”¨å­—ä½“ï¼ˆå‚è€ƒå­—å¹•é…ç½®ï¼‰
                subtitle_config = config.SUBTITLE_CONFIG.copy()

                resolved_font = resolve_font_path(subtitle_config.get("font_family"))
                quote_text = (opening_golden_quote or "").strip()
                if quote_text:
                    # è¯»å–å¼€åœºé‡‘å¥æ ·å¼ï¼ˆå¸¦é»˜è®¤å€¼å›é€€ï¼‰
                    quote_style = getattr(config, "OPENING_QUOTE_STYLE", {}) or {}
                    base_font = int(config.SUBTITLE_CONFIG.get("font_size", 36))
                    scale = float(quote_style.get("font_scale", 1.3))
                    font_size = int(quote_style.get("font_size", base_font * scale))
                    text_color = quote_style.get("color", config.SUBTITLE_CONFIG.get("color", "white"))
                    stroke_color = quote_style.get("stroke_color", config.SUBTITLE_CONFIG.get("stroke_color", "black"))
                    stroke_width = int(quote_style.get("stroke_width", max(3, int(config.SUBTITLE_CONFIG.get("stroke_width", 3)))))
                    pos = quote_style.get("position", ("center", "center"))

                    # å¼€åœºé‡‘å¥æ¢è¡Œï¼šæŒ‰ max_chars_per_line å’Œ max_lines æ§åˆ¶
                    try:
                        max_chars = int(quote_style.get("max_chars_per_line", 18))
                        max_q_lines = int(quote_style.get("max_lines", 4))
                        # å¤ç”¨å­—å¹•æ‹†åˆ†é€»è¾‘ï¼Œä¸¥æ ¼æŒ‰æ¯è¡Œå­—ç¬¦æ•°é™åˆ¶
                        candidate_lines = split_text_for_subtitle(quote_text, max_chars, max_q_lines)
                        wrapped_quote = "\n".join(candidate_lines[:max_q_lines]) if candidate_lines else quote_text
                    except Exception:
                        wrapped_quote = quote_text

                    # è¦†ç›–å­—ä½“è§£æï¼ˆä¼˜å…ˆé‡‡ç”¨ OPENING_QUOTE_STYLE.font_familyï¼‰
                    font_override = quote_style.get("font_family")
                    if font_override and os.path.exists(font_override):
                        resolved_font = font_override

                    # è¡Œé—´è·ä¸å­—é—´è·ï¼ˆMoviePy 2.x æ— ç›´æ¥å‚æ•°ï¼Œè¿™é‡Œé€šè¿‡é€è¡Œæ’ç‰ˆ+ç©ºæ ¼è¿‘ä¼¼å®ç°ï¼‰
                    line_spacing_px = int(quote_style.get("line_spacing", 0))
                    letter_spaces = int(quote_style.get("letter_spacing", 0))

                    def _apply_letter_spacing(s: str, n: int) -> str:
                        if n <= 0 or not s:
                            return s
                        return (" " * n).join(list(s))

                    def _make_text_clip(text: str) -> TextClip:
                        return TextClip(
                            text=text,
                            font_size=font_size,
                            color=text_color,
                            font=resolved_font or config.SUBTITLE_CONFIG.get("font_family"),
                            stroke_color=stroke_color,
                            stroke_width=stroke_width
                        )

                    try:
                        # é¢„å¤„ç†å­—é—´è·
                        lines = wrapped_quote.split("\n") if wrapped_quote else []
                        lines = [_apply_letter_spacing(ln, letter_spaces) for ln in lines] if lines else []

                        # æ— éœ€è‡ªå®šä¹‰è¡Œè·ï¼šç›´æ¥ç”¨å• TextClipï¼ˆå¤šè¡Œé€šè¿‡ \n æ¸²æŸ“ï¼‰
                        if line_spacing_px <= 0 or not (isinstance(pos, tuple) and pos == ("center", "center")):
                            processed = "\n".join(lines) if lines else wrapped_quote
                            text_clip = _make_text_clip(processed).with_position(pos).with_duration(opening_seconds)
                            opening_clip = CompositeVideoClip([opening_base, text_clip])
                        else:
                            # å±…ä¸­ä¸”éœ€è¦è¡Œè·ï¼šé€è¡Œæ’å¸ƒ
                            video_w, video_h = opening_base.size
                            line_clips: List[Any] = [_make_text_clip(ln) for ln in lines] if lines else []
                            if line_clips:
                                total_h = sum(c.h for c in line_clips) + line_spacing_px * (len(line_clips) - 1)
                                y_start = max(0, (video_h - total_h) // 2)
                                y_cur = y_start
                                placed: List[Any] = [opening_base]
                                for c in line_clips:
                                    placed.append(c.with_position(("center", y_cur)).with_duration(opening_seconds))
                                    y_cur += c.h + line_spacing_px
                                opening_clip = CompositeVideoClip(placed)
                            else:
                                text_clip = _make_text_clip(wrapped_quote).with_position(pos).with_duration(opening_seconds)
                                opening_clip = CompositeVideoClip([opening_base, text_clip])
                    except Exception:
                        text_clip = _make_text_clip(wrapped_quote).with_position(pos).with_duration(opening_seconds)
                        opening_clip = CompositeVideoClip([opening_base, text_clip])
                else:
                    opening_clip = opening_base

                # ç»‘å®šå¼€åœºå£æ’­éŸ³é¢‘ï¼ˆå¦‚å­˜åœ¨ï¼‰
                if opening_voice_clip is not None:
                    try:
                        opening_clip = opening_clip.with_audio(opening_voice_clip)
                    except Exception as _bindaerr:
                        logger.warning(f"ä¸ºå¼€åœºç‰‡æ®µç»‘å®šéŸ³é¢‘å¤±è´¥: {_bindaerr}")

                video_clips.append(opening_clip)
            except Exception as e:
                logger.warning(f"å¼€åœºç‰‡æ®µç”Ÿæˆå¤±è´¥: {e}ï¼Œå°†è·³è¿‡å¼€åœº")

        # ä¸ºæ¯ä¸ªæ®µè½åˆ›å»ºè§†é¢‘ç‰‡æ®µ
        for i, (image_path, audio_path) in enumerate(zip(image_paths, audio_paths)):
            print(f"æ­£åœ¨å¤„ç†ç¬¬{i+1}æ®µè§†é¢‘...")
            
            # åŠ è½½éŸ³é¢‘è·å–æ—¶é•¿
            audio_clip = AudioFileClip(audio_path)
            duration = audio_clip.duration
            
            # åˆ›å»ºå›¾åƒå‰ªè¾‘ï¼Œè®¾ç½®æŒç»­æ—¶é—´ä¸ºéŸ³é¢‘é•¿åº¦ (MoviePy 2.x ä½¿ç”¨ with_duration)
            image_clip = ImageClip(image_path).with_duration(duration)
            
            # ç»„åˆå›¾åƒå’ŒéŸ³é¢‘ (MoviePy 2.x ä½¿ç”¨ with_audio)
            video_clip = image_clip.with_audio(audio_clip)
            video_clips.append(video_clip)
            audio_clips.append(audio_clip)
        
        # è¿æ¥æ‰€æœ‰è§†é¢‘ç‰‡æ®µ
        print("æ­£åœ¨åˆæˆæœ€ç»ˆè§†é¢‘...")
        # ä½¿ç”¨ compose æ–¹å¼åˆå¹¶ï¼Œé¿å…éŸ³é¢‘è½¨ä¸¢å¤±æˆ–ä¸åŒå°ºå¯¸å¯¼è‡´çš„é—®é¢˜
        final_video = concatenate_videoclips(video_clips, method="compose")
        
        # æ·»åŠ å­—å¹•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        # ç”Ÿæ•ˆçš„å­—å¹•å¼€å…³éœ€åŒæ—¶æ»¡è¶³ï¼šè¿è¡Œæ—¶å‚æ•°ä¸å…¨å±€é…ç½®å‡ä¸º True
        effective_subtitles = bool(enable_subtitles) and bool(getattr(config, "SUBTITLE_CONFIG", {}).get("enabled", True))
        if effective_subtitles and script_data:
            print("æ­£åœ¨æ·»åŠ å­—å¹•...")
            try:
                # ä¼ å…¥æœ€ç»ˆè§†é¢‘å°ºå¯¸ï¼Œä¾¿äºå­—å¹•è®¡ç®—è¾¹è·/èƒŒæ™¯
                subtitle_config = config.SUBTITLE_CONFIG.copy()
                subtitle_config["video_size"] = final_video.size
                # ä¼ å…¥æ¯æ®µéŸ³é¢‘çœŸå®æ—¶é•¿ç”¨äºç²¾å‡†å¯¹é½
                subtitle_config["segment_durations"] = [ac.duration for ac in audio_clips]
                # å¼€åœºå­—å¹•åç§»ï¼šè®©ç¬¬ä¸€æ®µå­—å¹•ä»å¼€åœºç‰‡æ®µä¹‹åå¼€å§‹
                subtitle_config["offset_seconds"] = opening_seconds
                subtitle_clips = create_subtitle_clips(script_data, subtitle_config)
                if subtitle_clips:
                    # å°†å­—å¹•ä¸è§†é¢‘åˆæˆ
                    final_video = CompositeVideoClip([final_video] + subtitle_clips)
                    print(f"å·²æ·»åŠ  {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
                else:
                    print("æœªç”Ÿæˆä»»ä½•å­—å¹•å‰ªè¾‘")
            except Exception as e:
                logger.warning(f"æ·»åŠ å­—å¹•å¤±è´¥: {str(e)}ï¼Œç»§ç»­ç”Ÿæˆæ— å­—å¹•è§†é¢‘")

        # è°ƒæ•´å£æ’­éŸ³é‡ï¼ˆåœ¨ä¸BGMæ··éŸ³å‰ï¼‰â€”â€”MoviePy 2.x ä½¿ç”¨ MultiplyVolume
        try:
            if final_video.audio is not None and narration_volume is not None:
                narration_audio = final_video.audio
                if isinstance(narration_volume, (int, float)) and abs(float(narration_volume) - 1.0) > 1e-9:
                    narration_audio = narration_audio.with_effects([MultiplyVolume(float(narration_volume))])
                    final_video = final_video.with_audio(narration_audio)
                    print(f"ğŸ”Š å£æ’­éŸ³é‡è°ƒæ•´ä¸º: {float(narration_volume)}")
        except Exception as e:
            logger.warning(f"å£æ’­éŸ³é‡è°ƒæ•´å¤±è´¥: {str(e)}ï¼Œå°†ä½¿ç”¨åŸå§‹éŸ³é‡")

        # åœ¨è§†é¢‘å¼€å¤´åº”ç”¨è§†è§‰æ¸æ˜¾ï¼ˆä»é»‘åˆ°æ­£å¸¸ï¼‰
        try:
            fade_in_seconds = float(getattr(config, "OPENING_FADEIN_SECONDS", 0.0))
            if fade_in_seconds > 1e-3:
                def _fade_in_frame(gf, t):
                    try:
                        alpha = min(1.0, max(0.0, float(t) / float(fade_in_seconds)))
                    except Exception:
                        alpha = 1.0
                    return alpha * gf(t)
                try:
                    final_video = final_video.transform(_fade_in_frame, keep_duration=True)
                    print(f"ğŸ¬ å·²æ·»åŠ å¼€åœºæ¸æ˜¾ {fade_in_seconds}s")
                except Exception as _ferr:
                    logger.warning(f"å¼€åœºæ¸æ˜¾åº”ç”¨å¤±è´¥: {_ferr}")
        except Exception as e:
            logger.warning(f"è¯»å–å¼€åœºæ¸æ˜¾é…ç½®å¤±è´¥: {e}")
        
        # åœ¨ç‰‡å°¾è¿½åŠ  config.ENDING_FADE_SECONDS ç§’é™å¸§å¹¶æ¸éšï¼ˆä»…ç”»é¢ï¼Œæ— å£æ’­éŸ³é¢‘ï¼‰
        try:
            tail_seconds = float(getattr(config, "ENDING_FADE_SECONDS", 2.5))
            if isinstance(image_paths, list) and len(image_paths) > 0 and tail_seconds > 1e-3:
                last_image_path = image_paths[-1]
                tail_clip = ImageClip(last_image_path).with_duration(tail_seconds)
                # ä½¿ç”¨ transform å®ç°åˆ°é»‘åœºçš„çº¿æ€§æ¸éš
                def _fade_frame(gf, t):
                    try:
                        alpha = max(0.0, 1.0 - float(t) / float(tail_seconds))
                    except Exception:
                        alpha = 0.0
                    return alpha * gf(t)
                try:
                    tail_clip = tail_clip.transform(_fade_frame, keep_duration=True)
                except Exception:
                    pass
                final_video = concatenate_videoclips([final_video, tail_clip], method="compose")
                print(f"ğŸ¬ å·²æ·»åŠ ç‰‡å°¾é™å¸§ {tail_seconds}s å¹¶æ¸éš")
        except Exception as tail_err:
            logger.warning(f"ç‰‡å°¾é™å¸§æ·»åŠ å¤±è´¥: {tail_err}ï¼Œå°†ç»§ç»­ç”Ÿæˆæ— ç‰‡å°¾æ¸éšçš„è§†é¢‘")
        
        # å¯é€‰ï¼šå åŠ èƒŒæ™¯éŸ³ä¹ï¼ˆä¸å£æ’­æ··éŸ³ï¼‰
        bgm_clip = None
        try:
            if bgm_audio_path and os.path.exists(bgm_audio_path):
                print(f"ğŸµ å¼€å§‹å¤„ç†èƒŒæ™¯éŸ³ä¹: {bgm_audio_path}")
                bgm_clip = AudioFileClip(bgm_audio_path)
                print(f"ğŸµ BGMåŠ è½½æˆåŠŸï¼Œæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
                
                # è°ƒæ•´ BGM éŸ³é‡ï¼ˆMoviePy 2.x MultiplyVolumeï¼‰
                try:
                    if isinstance(bgm_volume, (int, float)) and abs(float(bgm_volume) - 1.0) > 1e-9:
                        bgm_clip = bgm_clip.with_effects([MultiplyVolume(float(bgm_volume))])
                        print(f"ğŸµ BGMéŸ³é‡è°ƒæ•´ä¸º: {float(bgm_volume)}")
                except Exception:
                    print("âš ï¸ BGMéŸ³é‡è°ƒæ•´å¤±è´¥ï¼Œä½¿ç”¨åŸéŸ³é‡")
                    pass
                
                # å¾ªç¯æˆ–è£å‰ªè‡³è§†é¢‘æ€»æ—¶é•¿ï¼ˆä¼˜å…ˆä½¿ç”¨ MoviePy 2.x çš„ AudioLoopï¼‰
                try:
                    target_duration = final_video.duration
                    print(f"ğŸµ è§†é¢‘æ€»æ—¶é•¿: {target_duration:.2f}ç§’ï¼ŒBGMæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
                    if AudioLoop is not None:
                        # ä½¿ç”¨ 2.x çš„ AudioLoop æ•ˆæœç±»
                        bgm_clip = bgm_clip.with_effects([AudioLoop(duration=target_duration)])
                        print(f"ğŸµ BGMé•¿åº¦é€‚é…å®Œæˆï¼ˆAudioLoopï¼‰ï¼Œæœ€ç»ˆæ—¶é•¿: {bgm_clip.duration:.2f}ç§’")
                    else:
                        # ç®€åŒ–çš„å›é€€ï¼šç›´æ¥è£å‰ªåˆ°ç›®æ ‡æ—¶é•¿ï¼ˆé¿å…å¤æ‚æ‰‹åŠ¨å¾ªç¯ï¼‰
                        if hasattr(bgm_clip, "with_duration"):
                            bgm_clip = bgm_clip.with_duration(min(bgm_clip.duration, target_duration))
                            print("âš ï¸ AudioLoop ä¸å¯ç”¨ï¼Œå·²å°†BGMè£å‰ªåˆ°ç›®æ ‡æ—¶é•¿")
                        else:
                            raise RuntimeError("AudioLoop ä¸å¯ç”¨ï¼Œä¸”ä¸æ”¯æŒ with_duration")

                except Exception as loop_err:
                    print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹é•¿åº¦é€‚é…å¤±è´¥: {loop_err}ï¼Œå°†ä¸æ·»åŠ BGMç»§ç»­ç”Ÿæˆ")
                    logger.warning(f"èƒŒæ™¯éŸ³ä¹å¾ªç¯/è£å‰ªå¤±è´¥: {loop_err}ï¼Œå°†ä¸æ·»åŠ BGMç»§ç»­ç”Ÿæˆ")
                    bgm_clip = None
                    
                # åˆæˆå¤åˆéŸ³é¢‘
                if bgm_clip is not None:
                    print("ğŸµ å¼€å§‹åˆæˆèƒŒæ™¯éŸ³ä¹å’Œå£æ’­éŸ³é¢‘")
                    # é€šç”¨çº¿æ€§æ·¡å‡ºå¢ç›Šå‡½æ•°ï¼ˆç”¨äºç‰‡å°¾æ·¡å‡ºï¼‰
                    def _linear_fade_out_gain(total: float, tail: float):
                        cutoff = max(0.0, total - tail)
                        def _gain_any(t_any):
                            import numpy as _np
                            def _scalar(ts: float) -> float:
                                if ts <= cutoff:
                                    return 1.0
                                if ts >= total:
                                    return 0.0
                                return max(0.0, 1.0 - (ts - cutoff) / tail)
                            if hasattr(t_any, "__len__"):
                                return _np.array([_scalar(float(ts)) for ts in t_any])
                            return _scalar(float(t_any))
                        return _gain_any
                    if final_video.audio is not None:
                        # å¯é€‰ï¼šè‡ªåŠ¨ Duckingï¼Œæ ¹æ®å£æ’­åŒ…ç»œåŠ¨æ€å‹ä½ BGMï¼ˆMoviePy 2.x é€šè¿‡ transform å®ç°æ—¶é—´å˜å¢ç›Šï¼‰
                        try:
                            if getattr(config, "AUDIO_DUCKING_ENABLED", False):
                                strength = float(getattr(config, "AUDIO_DUCKING_STRENGTH", 0.7))
                                smooth_sec = float(getattr(config, "AUDIO_DUCKING_SMOOTH_SECONDS", 0.12))
                                total_dur = float(final_video.duration)
                                # é‡‡æ ·é¢‘ç‡ï¼ˆåŒ…ç»œè®¡ç®—ï¼‰ï¼Œ20Hz è¶³å¤Ÿå¹³æ»‘ä¸”å¼€é”€ä½
                                env_fps = 20.0
                                num_samples = max(2, int(total_dur * env_fps) + 1)
                                times = np.linspace(0.0, total_dur, num_samples)
                                # ä¼°ç®—å£æ’­ç¬æ—¶å¹…åº¦ï¼ˆç»å¯¹å€¼ï¼Œé€šé“å–å‡å€¼ï¼‰
                                amp = np.zeros_like(times)
                                for i, t in enumerate(times):
                                    try:
                                        frame = final_video.audio.get_frame(float(min(max(0.0, t), total_dur - 1e-6)))
                                        # frame å½¢å¦‚ [L, R]
                                        amp[i] = float(np.mean(np.abs(frame)))
                                    except Exception:
                                        amp[i] = 0.0
                                # å¹³æ»‘ï¼ˆç®€å•æ»‘åŠ¨å¹³å‡çª—å£ï¼‰
                                win = max(1, int(smooth_sec * env_fps))
                                if win > 1:
                                    kernel = np.ones(win, dtype=float) / win
                                    amp = np.convolve(amp, kernel, mode="same")
                                # å½’ä¸€åŒ–
                                max_amp = float(np.max(amp)) if np.max(amp) > 1e-8 else 1.0
                                env = amp / max_amp
                                # è®¡ç®— duck å¢ç›Šæ›²çº¿ï¼šå£æ’­å¼º -> BGM æ›´ä½
                                gains = 1.0 - strength * env
                                gains = np.clip(gains, 0.0, 1.0)
                                # æ„å»ºæ—¶é—´å˜å¢ç›Šå‡½æ•°ï¼ˆæ”¯æŒæ ‡é‡/å‘é‡ tï¼‰
                                def _gain_lookup(t_any):
                                    import numpy as _np
                                    def _lookup_scalar(ts: float) -> float:
                                        if ts <= 0.0:
                                            return float(gains[0])
                                        if ts >= total_dur:
                                            return float(gains[-1])
                                        idx = int(ts * env_fps)
                                        if idx < 0:
                                            idx = 0
                                        if idx >= gains.shape[0]:
                                            idx = gains.shape[0] - 1
                                        return float(gains[idx])
                                    if hasattr(t_any, "__len__"):
                                        return _np.array([_lookup_scalar(float(ts)) for ts in t_any])
                                    return _lookup_scalar(float(t_any))

                                # åº”ç”¨æ—¶é—´å˜å¢ç›Šåˆ° BGMï¼ˆä½¿ç”¨ transformï¼‰ï¼Œæ³¨æ„å¤šå£°é“å¹¿æ’­ç»´åº¦
                                bgm_clip = bgm_clip.transform(
                                    lambda gf, t: (
                                        (_gain_lookup(t)[:, None] if hasattr(t, "__len__") else _gain_lookup(t))
                                        * gf(t)
                                    ),
                                    keep_duration=True,
                                )
                                print(f"ğŸšï¸ å·²å¯ç”¨è‡ªåŠ¨Duckingï¼ˆstrength={strength}, smooth={smooth_sec}sï¼‰")
                        except Exception as duck_err:
                            logger.warning(f"è‡ªåŠ¨Duckingå¤±è´¥: {duck_err}ï¼Œå°†ä½¿ç”¨æ’å®šéŸ³é‡BGM")
                        # åœ¨ç‰‡å°¾å¯¹ BGM åšæ·¡å‡ºï¼ˆä¸å½±å“å£æ’­ï¼Œå› ä¸ºå°¾æ®µæ— å£æ’­ï¼‰
                        try:
                            total_dur = float(final_video.duration)
                            fade_tail = float(getattr(config, "ENDING_FADE_SECONDS", 2.5))
                            fade_gain = _linear_fade_out_gain(total_dur, fade_tail)
                            bgm_clip = bgm_clip.transform(
                                lambda gf, t: ((fade_gain(t)[:, None]) if hasattr(t, "__len__") else fade_gain(t)) * gf(t),
                                keep_duration=True,
                            )
                            print(f"ğŸšï¸ å·²æ·»åŠ BGMç‰‡å°¾{fade_tail}sæ·¡å‡º")
                        except Exception as _fade_err:
                            logger.warning(f"BGMæ·¡å‡ºåº”ç”¨å¤±è´¥: {_fade_err}")
                        mixed_audio = CompositeAudioClip([final_video.audio, bgm_clip])
                        print("ğŸµ BGMä¸å£æ’­éŸ³é¢‘åˆæˆå®Œæˆ")
                    else:
                        # æ— å£æ’­ï¼Œä»… BGMï¼›åŒæ ·æ·»åŠ ç‰‡å°¾æ·¡å‡º
                        try:
                            total_dur = float(final_video.duration)
                            fade_tail = float(getattr(config, "ENDING_FADE_SECONDS", 2.5))
                            fade_gain = _linear_fade_out_gain(total_dur, fade_tail)
                            bgm_clip = bgm_clip.transform(
                                lambda gf, t: ((fade_gain(t)[:, None]) if hasattr(t, "__len__") else fade_gain(t)) * gf(t),
                                keep_duration=True,
                            )
                            print(f"ğŸšï¸ å·²æ·»åŠ BGMç‰‡å°¾{fade_tail}sæ·¡å‡º")
                        except Exception as _fade_err:
                            logger.warning(f"BGMæ·¡å‡ºåº”ç”¨å¤±è´¥: {_fade_err}")
                        mixed_audio = CompositeAudioClip([bgm_clip])
                        print("ğŸµ ä»…æ·»åŠ BGMéŸ³é¢‘ï¼ˆæ— å£æ’­éŸ³é¢‘ï¼‰")
                    final_video = final_video.with_audio(mixed_audio)
                    print("ğŸµ èƒŒæ™¯éŸ³ä¹æ·»åŠ æˆåŠŸï¼")
                else:
                    print("âŒ BGMå¤„ç†å¤±è´¥ï¼Œç”Ÿæˆæ— èƒŒæ™¯éŸ³ä¹è§†é¢‘")
            else:
                if bgm_audio_path:
                    print(f"âš ï¸ èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ä¸å­˜åœ¨: {bgm_audio_path}")
                else:
                    print("â„¹ï¸ æœªæŒ‡å®šèƒŒæ™¯éŸ³ä¹æ–‡ä»¶")
        except Exception as e:
            print(f"âŒ èƒŒæ™¯éŸ³ä¹å¤„ç†å¼‚å¸¸: {str(e)}")
            logger.warning(f"èƒŒæ™¯éŸ³ä¹å¤„ç†å¤±è´¥: {str(e)}ï¼Œå°†ç»§ç»­ç”Ÿæˆæ— èƒŒæ™¯éŸ³ä¹çš„è§†é¢‘")

        # è¾“å‡ºæœ€ç»ˆè§†é¢‘ï¼šä½¿ç”¨ç®€å•è¿›åº¦æ¡ï¼Œé¿å…æŸäº›ç»ˆç«¯ç¯å¢ƒä¸‹ tqdm å¤šè¡Œæ»šåŠ¨åˆ·å±
        moviepy_logger = 'bar'

        final_video.write_videofile(
            output_path,
            fps=24,
            codec='libx264',
            audio_codec='aac',
            logger=moviepy_logger
        )
        
        # é‡Šæ”¾èµ„æº
        for clip in video_clips:
            clip.close()
        for aclip in audio_clips:
            aclip.close()
        final_video.close()
        if bgm_clip is not None:
            try:
                bgm_clip.close()
            except Exception:
                pass
        if 'opening_voice_clip' in locals() and opening_voice_clip is not None:
            try:
                opening_voice_clip.close()
            except Exception:
                pass
        
        print(f"æœ€ç»ˆè§†é¢‘å·²ä¿å­˜: {output_path}")
        return output_path
    
    except Exception as e:
        raise ValueError(f"è§†é¢‘åˆæˆé”™è¯¯: {e}")

################ Style Helper Functions ################
def get_image_style(style_name: str = "cinematic") -> str:
    """
    è·å–å›¾åƒé£æ ¼å­—ç¬¦ä¸²
    
    Args:
        style_name: é£æ ¼åç§°ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›ç¬¬ä¸€ä¸ªé£æ ¼
    
    Returns:
        str: å›¾åƒé£æ ¼æè¿°å­—ç¬¦ä¸²
    """
    return IMAGE_STYLE_PRESETS.get(style_name, list(IMAGE_STYLE_PRESETS.values())[0])

def split_text_for_subtitle(text: str, max_chars_per_line: int = 20, max_lines: int = 2) -> List[str]:
    """
    å°†é•¿æ–‡æœ¬åˆ†å‰²ä¸ºé€‚åˆå­—å¹•æ˜¾ç¤ºçš„çŸ­å¥ï¼Œä¸¥æ ¼æŒ‰æ¯è¡Œå­—ç¬¦æ•°é™åˆ¶
    
    Args:
        text: åŸå§‹æ–‡æœ¬
        max_chars_per_line: æ¯è¡Œæœ€å¤§å­—ç¬¦æ•°
        max_lines: æœ€å¤§è¡Œæ•°
    
    Returns:
        List[str]: åˆ†å‰²åçš„å­—å¹•æ–‡æœ¬åˆ—è¡¨
    """
    # å¦‚æœæ–‡æœ¬å¾ˆçŸ­ï¼Œç›´æ¥æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†
    if len(text) <= max_chars_per_line:
        return [text]
    
    # æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²ï¼ˆå«ä¸­è‹±æ–‡ï¼‰
    sentences = []
    current = ""
    for char in text:
        current += char
        # ä¸€çº§åˆ†å¥ï¼šæŒ‰ä¸­è‹±æ–‡é‡åœé¡¿æ ‡ç‚¹åˆ‡åˆ†ï¼ˆã€‚ï¼ï¼Ÿï¼›.!?ï¼‰
        if char in "ã€‚ï¼ï¼Ÿï¼›.!?":
            sentences.append(current.strip())
            current = ""
    
    if current.strip():
        sentences.append(current.strip())
    
    # å¦‚æœæ²¡æœ‰å¥å­åˆ†éš”ç¬¦ï¼Œå¼ºåˆ¶æŒ‰å­—ç¬¦æ•°åˆ‡åˆ†
    if not sentences:
        result = []
        for i in range(0, len(text), max_chars_per_line):
            result.append(text[i:i + max_chars_per_line])
        return result
    
    # ç»„åˆå¥å­ï¼Œä¸¥æ ¼æŒ‰æ¯è¡Œå­—ç¬¦æ•°é™åˆ¶
    result = []
    current_subtitle = ""
    
    for sentence in sentences:
        # å¦‚æœå•ä¸ªå¥å­è¶…è¿‡æ¯è¡Œé™åˆ¶ï¼šå…ˆå°è¯•æŒ‰æ¬¡çº§æ ‡ç‚¹ï¼ˆï¼Œã€ï¼‰ç»†åˆ†ï¼Œå†å¿…è¦æ—¶ç¡¬åˆ‡
        if len(sentence) > max_chars_per_line:
            if current_subtitle:
                result.append(current_subtitle)
                current_subtitle = ""

            # äºŒçº§åˆ†å¥å‡½æ•°ï¼šæŒ‰ï¼ˆï¼Œã€ã€â€œâ€ã€â€˜ â€™ã€ã€Š ã€‹ä»¥åŠè‹±æ–‡é€—å·, å’Œ ASCII å•å¼•å·'ï¼‰åˆ‡åˆ†å¹¶ä¿ç•™æ ‡ç‚¹ï¼ˆä¸å¤„ç† ASCII åŒå¼•å·ï¼‰
            def _split_by_secondary(s: str) -> List[str]:
                tokens = re.split(r'([ï¼Œã€,â€œâ€â€˜â€™ã€Šã€‹ï¼Œ,])', s)
                chunks: List[str] = []
                buf = ""
                in_ascii_single = False

                OPENERS = ("â€œ", "â€˜", "ã€Š")
                CLOSERS = ("â€", "â€™", "ã€‹")
                COMMAS = ("ï¼Œ", "ã€", ",")

                def flush_buf() -> None:
                    nonlocal buf
                    if buf:
                        chunks.append(buf)
                        buf = ""

                def start_new_with(tok: str) -> None:
                    nonlocal buf
                    flush_buf()
                    buf = tok

                def end_with(tok: str) -> None:
                    nonlocal buf
                    if buf:
                        buf += tok
                        flush_buf()
                    elif chunks:
                        chunks[-1] += tok
                    else:
                        # è‹¥ä¸å­˜åœ¨ä¸Šä¸€æ®µï¼Œåˆ™ä¸´æ—¶æ”¾å…¥ç¼“å†²ï¼Œé¿å…åŠŸèƒ½å˜åŒ–
                        buf = tok

                for t in tokens:
                    if not t:
                        continue

                    if t in OPENERS:
                        start_new_with(t)
                        continue

                    if t in CLOSERS:
                        end_with(t)
                        continue

                    if t == "'":
                        if not in_ascii_single:
                            start_new_with(t)
                            in_ascii_single = True
                        else:
                            end_with(t)
                            in_ascii_single = False
                        continue

                    if t in COMMAS:
                        end_with(t)
                        continue

                    # æ™®é€šæ–‡æœ¬
                    buf += t

                if buf:
                    chunks.append(buf)
                return chunks

            parts = _split_by_secondary(sentence)

            if len(parts) == 1:
                # æ— ï¼ˆï¼Œã€ï¼‰å¯ç”¨ï¼Œå›é€€åˆ°æŒ‰å­—ç¬¦æ•°ç¡¬åˆ‡
                for i in range(0, len(sentence), max_chars_per_line):
                    result.append(sentence[i:i + max_chars_per_line])
            else:
                # ä½¿ç”¨äºŒçº§åˆ†å¥ï¼Œå°½é‡åˆå¹¶åˆ°ä¸è¶…è¿‡ä¸Šé™çš„è¡Œ
                buf = ""
                for p in parts:
                    if len(p) <= max_chars_per_line:
                        if not buf:
                            buf = p
                        elif len(buf + p) <= max_chars_per_line:
                            buf += p
                        else:
                            result.append(buf)
                            buf = p
                    else:
                        # æ¬¡çº§ç‰‡æ®µä»ç„¶è¿‡é•¿ï¼Œå…ˆè¾“å‡ºå·²æœ‰ç¼“å†²ï¼Œå†ç¡¬åˆ‡
                        if buf:
                            result.append(buf)
                            buf = ""
                        for i in range(0, len(p), max_chars_per_line):
                            result.append(p[i:i + max_chars_per_line])
                if buf:
                    result.append(buf)
        elif not current_subtitle:
            current_subtitle = sentence
        elif len(current_subtitle + sentence) <= max_chars_per_line:
            current_subtitle += sentence
        else:
            result.append(current_subtitle)
            current_subtitle = sentence
    
    if current_subtitle:
        result.append(current_subtitle)
    
    return result

def create_subtitle_clips(script_data: Dict[str, Any], subtitle_config: Dict[str, Any] = None) -> List[TextClip]:
    """
    åˆ›å»ºå­—å¹•å‰ªè¾‘åˆ—è¡¨
    
    Args:
        script_data: è„šæœ¬æ•°æ®ï¼ŒåŒ…å«segmentsä¿¡æ¯
        subtitle_config: å­—å¹•é…ç½®ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é…ç½®
    
    Returns:
        List[TextClip]: å­—å¹•å‰ªè¾‘åˆ—è¡¨
    """
    if subtitle_config is None:
        from config import config
        subtitle_config = config.SUBTITLE_CONFIG.copy()
    
    subtitle_clips = []
    current_time = float(subtitle_config.get("offset_seconds", 0.0) if isinstance(subtitle_config, dict) else 0.0)
    
    logger.info("å¼€å§‹åˆ›å»ºå­—å¹•å‰ªè¾‘...")
    
    # è§£æå¯ç”¨å­—ä½“ï¼ˆä¼˜å…ˆä½¿ç”¨ç³»ç»Ÿä¸­çš„ä¸­æ–‡å­—ä½“æ–‡ä»¶è·¯å¾„ï¼Œé¿å…ä¸­æ–‡ç¼ºå­—ï¼‰
    def _resolve_font_path(preferred: Optional[str]) -> Optional[str]:
        return resolve_font_path(preferred)

    resolved_font = _resolve_font_path(subtitle_config.get("font_family"))
    if not resolved_font:
        logger.warning("æœªèƒ½è§£æåˆ°å¯ç”¨ä¸­æ–‡å­—ä½“ï¼Œå¯èƒ½å¯¼è‡´å­—å¹•æ— æ³•æ˜¾ç¤ºä¸­æ–‡å­—ç¬¦ã€‚å»ºè®®åœ¨ config.SUBTITLE_CONFIG.font_family æŒ‡å®šå­—ä½“æ–‡ä»¶è·¯å¾„ã€‚")

    # è¯»å–è§†é¢‘å°ºå¯¸ï¼ˆç”¨äºè®¡ç®—åº•éƒ¨è¾¹è·å’ŒèƒŒæ™¯æ¡ï¼‰
    video_size = subtitle_config.get("video_size", (1280, 720))
    video_width, video_height = video_size

    segment_durations = subtitle_config.get("segment_durations", [])

    # å®šä¹‰éœ€è¦æ›¿æ¢ä¸ºç©ºæ ¼çš„æ ‡ç‚¹é›†åˆï¼ˆä¸­è‹±æ–‡å¸¸è§æ ‡ç‚¹ï¼‰
    # ä¸­æ–‡å¼•å·â€œâ€â€˜â€™ä¸ä¹¦åå·ã€Šã€‹ä¿ç•™ï¼›è‹±æ–‡åŒå¼•å·ç›´æ¥æ›¿æ¢ä¸ºåŒç©ºæ ¼ï¼›å…¶ä»–æ ‡ç‚¹æ›¿æ¢ä¸ºåŒç©ºæ ¼
    # ä½¿ç”¨ + å°†è¿ç»­æ ‡ç‚¹è§†ä½œä¸€ä¸ªæ•´ä½“ï¼Œé¿å…äº§ç”Ÿè¿‡å¤šç©ºç™½
    punctuation_pattern = r"[-.,!?;:\"ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼šï¼ˆï¼‰()\[\]{}ã€ã€‘â€”â€¦â€“ã€]+"

    # å†…éƒ¨è¾…åŠ©ï¼šæ ¹æ®é…ç½®ç”Ÿæˆæ–‡æœ¬ä¸å¯é€‰é˜´å½±ã€èƒŒæ™¯æ¡çš„å‰ªè¾‘åˆ—è¡¨
    def _make_text_and_bg_clips(display_text: str, start_time: float, duration: float) -> List[Any]:
        position = subtitle_config["position"]
        margin_bottom = int(subtitle_config.get("margin_bottom", 0))
        anchor_x = position[0] if isinstance(position, tuple) else "center"

        # ä¸»æ–‡æœ¬å‰ªè¾‘ï¼ˆç”¨äºæµ‹é‡é«˜åº¦ä¸å®é™…å±•ç¤ºï¼‰
        main_clip = TextClip(
            text=display_text,
            font_size=subtitle_config["font_size"],
            color=subtitle_config["color"],
            font=resolved_font or subtitle_config["font_family"],
            stroke_color=subtitle_config["stroke_color"],
            stroke_width=subtitle_config["stroke_width"]
        )

        # è®¡ç®—æ–‡æœ¬ä½ç½®ï¼ˆå½“å®šä½ bottom æ—¶åŸºäºæ–‡æœ¬é«˜åº¦ä¸è¾¹è·ï¼‰
        if isinstance(position, tuple) and len(position) == 2 and position[1] == "bottom":
            baseline_safe_padding = int(subtitle_config.get("baseline_safe_padding", 4))
            y_text = max(0, video_height - margin_bottom - main_clip.h - baseline_safe_padding)
            main_pos = (anchor_x, y_text)
        else:
            main_pos = position

        main_clip = main_clip.with_position(main_pos).with_start(start_time).with_duration(duration)

        clips_to_add: List[Any] = []

        # èƒŒæ™¯æ¡ï¼ˆå¦‚å¯ç”¨ï¼‰
        bg_color = subtitle_config.get("background_color")
        bg_opacity = float(subtitle_config.get("background_opacity", 0))
        if bg_color and bg_opacity > 0.0:
            bg_height = int(
                subtitle_config["font_size"] * subtitle_config.get("max_lines", 2)
                + subtitle_config.get("line_spacing", 10) + 4
            )
            bg_clip = ColorClip(size=(video_width, bg_height), color=bg_color)
            if hasattr(bg_clip, "with_opacity"):
                bg_clip = bg_clip.with_opacity(bg_opacity)
            y_bg = max(0, video_height - margin_bottom - bg_height)
            bg_clip = bg_clip.with_position(("center", y_bg)).with_start(start_time).with_duration(duration)
            clips_to_add.append(bg_clip)

        # å¯é€‰é˜´å½±
        if subtitle_config.get("shadow_enabled", False):
            shadow_color = subtitle_config.get("shadow_color", "black")
            shadow_clip = TextClip(
                text=display_text,
                font_size=subtitle_config["font_size"],
                color=shadow_color,
                font=resolved_font or subtitle_config["font_family"]
            ).with_position(main_pos).with_start(start_time).with_duration(duration)
            clips_to_add.extend([shadow_clip, main_clip])
        else:
            clips_to_add.append(main_clip)

        return clips_to_add

    for i, segment in enumerate(script_data["segments"], 1):
        content = segment["content"]
        # ä¼˜å…ˆä½¿ç”¨çœŸå®éŸ³é¢‘æ—¶é•¿ï¼Œå…¶æ¬¡å›é€€åˆ°ä¼°ç®—æ—¶é•¿
        duration = None
        if isinstance(segment_durations, list) and len(segment_durations) >= i:
            duration = float(segment_durations[i-1])
        if duration is None:
            duration = float(segment.get("estimated_duration", 0))
        
        logger.debug(f"å¤„ç†ç¬¬{i}æ®µå­—å¹•ï¼Œæ—¶é•¿: {duration}ç§’")
        
        # åˆ†å‰²é•¿æ–‡æœ¬ä¸ºé€‚åˆæ˜¾ç¤ºçš„å­—å¹•
        subtitle_texts = split_text_for_subtitle(
            content,
            subtitle_config["max_chars_per_line"],
            subtitle_config["max_lines"]
        )
        
        # è®¡ç®—æ¯è¡Œå­—å¹•çš„æ˜¾ç¤ºæ—¶é•¿ï¼šæŒ‰è¡Œå­—ç¬¦æ•°å æ¯”åˆ†é…ï¼Œç¡®ä¿æ€»å’Œ==æ®µæ—¶é•¿
        subtitle_start_time = current_time
        line_durations: List[float] = []
        if len(subtitle_texts) > 0:
            lengths = [max(1, len(t)) for t in subtitle_texts]
            total_len = sum(lengths)
            acc = 0.0
            for idx, L in enumerate(lengths):
                if idx < len(lengths) - 1:
                    d = duration * (L / total_len)
                    line_durations.append(d)
                    acc += d
                else:
                    line_durations.append(max(0.0, duration - acc))
        else:
            line_durations = [duration]
        
        for subtitle_text, subtitle_duration in zip(subtitle_texts, line_durations):
            try:
                # å°†è¿ç»­æ ‡ç‚¹æ›¿æ¢ä¸ºä¸¤ä¸ªç©ºæ ¼ï¼Œå¹¶å‹ç¼©å¯èƒ½äº§ç”Ÿçš„å¤šä½™ç©ºæ ¼
                display_text = re.sub(punctuation_pattern, "  ", subtitle_text)
                display_text = re.sub(r" {3,}", "  ", display_text)

                clips_to_add = _make_text_and_bg_clips(display_text, subtitle_start_time, subtitle_duration)
                subtitle_clips.extend(clips_to_add)
                logger.debug(f"åˆ›å»ºå­—å¹•: '{subtitle_text[:20]}...' æ—¶é—´: {subtitle_start_time:.1f}-{subtitle_start_time+subtitle_duration:.1f}s")
                
                subtitle_start_time += subtitle_duration
                
            except Exception as e:
                logger.warning(f"åˆ›å»ºå­—å¹•å¤±è´¥: {str(e)}ï¼Œè·³è¿‡æ­¤å­—å¹•")
                continue
        
        current_time += duration
    
    logger.info(f"å­—å¹•åˆ›å»ºå®Œæˆï¼Œå…±åˆ›å»º {len(subtitle_clips)} ä¸ªå­—å¹•å‰ªè¾‘")
    return subtitle_clips