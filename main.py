import os
import shutil
import json
import datetime
import glob
from functions import (
    read_document, intelligent_summarize, extract_keywords, 
    generate_images_for_segments, synthesize_voice_for_segments, 
    compose_final_video
)
from config import config


def auto_detect_server_from_model(model_name: str, model_type: str) -> str:
    """
    æ ¹æ®æ¨¡å‹åç§°è‡ªåŠ¨æ£€æµ‹æœåŠ¡å•†
    
    Args:
        model_name: æ¨¡å‹åç§°
        model_type: æ¨¡å‹ç±»å‹ (llm/image/tts)
    
    Returns:
        str: æœåŠ¡å•†åç§°
    """
    if model_type == "llm":
        # LLMæ¨¡å‹æœåŠ¡å•†è¯†åˆ«
        if any(prefix in model_name for prefix in ["google/", "anthropic/", "meta/"]):
            return "openrouter"
        elif any(prefix in model_name for prefix in ["zai-org/", "moonshotai/", "Qwen/"]):
            return "siliconflow"
        elif model_name.startswith("gpt-"):
            return "openai"  # aihubmixä»£ç†
        else:
            return "openrouter"  # é»˜è®¤
    
    elif model_type == "image":
        # å›¾åƒæ¨¡å‹æœåŠ¡å•†è¯†åˆ«
        if "doubao" in model_name.lower() or "seedream" in model_name.lower():
            return "doubao"
        else:
            return "doubao"  # é»˜è®¤
    
    elif model_type == "voice":
        # è¯­éŸ³æœåŠ¡å•†è¯†åˆ«
        if "_bigtts" in model_name:
            return "bytedance"  # å­—èŠ‚è¯­éŸ³åˆæˆå¤§æ¨¡å‹
        else:
            return "bytedance"  # å½“å‰åªæ”¯æŒå­—èŠ‚è¯­éŸ³åˆæˆ
    
    return "unknown"

def main(
    input_file=None,    # è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆEPUBæˆ–PDFæ–‡ä»¶ï¼‰ï¼Œå¦‚ä¸ºNoneåˆ™è‡ªåŠ¨ä»inputæ–‡ä»¶å¤¹è¯»å–
    target_length=800,  # ç¼©å†™åçš„ç›®æ ‡å­—æ•°ï¼ŒèŒƒå›´500-1000å­—
    num_segments=10,    # åˆ†æ®µæ•°é‡ï¼Œé»˜è®¤10æ®µ
    image_size="1280x720",  # ç”Ÿæˆå›¾ç‰‡çš„å°ºå¯¸ï¼Œå¯é€‰ï¼š1024x1024(1:1), 1280x720(16:9), 864x1152(3:4), 720x1280(9:16)ç­‰
    llm_model="google/gemini-2.5-pro",  # å¤§è¯­è¨€æ¨¡å‹
    image_model="doubao-seedream-3-0-t2i-250415",  # å›¾åƒç”Ÿæˆæ¨¡å‹
    voice="zh_male_yuanboxiaoshu_moon_bigtts",      # è¯­éŸ³éŸ³è‰²
    output_dir="output",  # è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„outputæ–‡ä»¶å¤¹
    image_style_preset="cinematic",  # å›¾åƒé£æ ¼é¢„è®¾ï¼Œå¯é€‰ï¼šcinematic, documentary, artisticç­‰
    enable_subtitles=True,  # æ˜¯å¦å¯ç”¨å­—å¹•ï¼Œé»˜è®¤å¯ç”¨
    bgm_filename: str = None,  # èƒŒæ™¯éŸ³ä¹æ–‡ä»¶åï¼ˆä½äºé¡¹ç›® output å­ç›®å½•å†…çš„ music æ–‡ä»¶å¤¹ï¼‰
    run_mode="auto"  # è¿è¡Œæ¨¡å¼ï¼šauto å…¨è‡ªåŠ¨ï¼›step åˆ†æ­¥ç¡®è®¤
):
    
    try:
        start_time = datetime.datetime.now()
        
        # é”šå®šåˆ°é¡¹ç›®æ ¹ç›®å½•ï¼ˆæœ¬æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼‰ï¼Œé¿å…ä¾èµ–ç»ˆç«¯CWD
        project_root = os.path.dirname(__file__)
        if not os.path.isabs(output_dir):
            output_dir = os.path.join(project_root, output_dir)
        
        # è‡ªåŠ¨è¯†åˆ«æœåŠ¡å•†
        llm_server = auto_detect_server_from_model(llm_model, "llm")
        image_server = auto_detect_server_from_model(image_model, "image") 
        tts_server = auto_detect_server_from_model(voice, "voice")
        
        # Input validation
        if not 500 <= target_length <= 2000:
            raise ValueError("target_lengthå¿…é¡»åœ¨500-2000ä¹‹é—´")
        if not 5 <= num_segments <= 20:
            raise ValueError("num_segmentså¿…é¡»åœ¨5-20ä¹‹é—´")
        if llm_server not in ["openrouter", "openai", "siliconflow"]:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæ¨¡å‹: {llm_model}ï¼Œè¯·ä½¿ç”¨æ”¯æŒçš„æ¨¡å‹")
        if image_server not in ["doubao"]:
            raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒæ¨¡å‹: {image_model}ï¼Œè¯·ä½¿ç”¨æ”¯æŒçš„æ¨¡å‹")
        if tts_server not in ["bytedance"]:
            raise ValueError(f"ä¸æ”¯æŒçš„è¯­éŸ³æ¨¡å‹: {voice}ï¼Œè¯·ä½¿ç”¨æ”¯æŒçš„è¯­éŸ³")
        if image_size not in config.SUPPORTED_IMAGE_SIZES:
            print(f"\nâš ï¸  ä¸æ”¯æŒçš„å›¾åƒå°ºå¯¸: {image_size}")
            print("æ”¯æŒçš„å°ºå¯¸: " + ", ".join(config.SUPPORTED_IMAGE_SIZES))
            raise ValueError(f"è¯·é€‰æ‹©æ”¯æŒçš„å›¾åƒå°ºå¯¸")

        # 1. æ–‡æ¡£è¯»å–
        if input_file is None:
            # ä½¿ç”¨äº¤äº’å¼æ–‡ä»¶é€‰æ‹©å™¨
            from utils import interactive_file_selector, prompt_choice
            input_file = interactive_file_selector(input_dir=os.path.join(project_root, "input"))
            if input_file is None:
                print("\nç¨‹åºå·²å–æ¶ˆ")
                return {
                    "success": False,
                    "message": "ç”¨æˆ·å–æ¶ˆäº†æ–‡ä»¶é€‰æ‹©",
                    "execution_time": 0,
                    "error": "ç”¨æˆ·å–æ¶ˆ"
                }
            # é€‰æ‹©è¿è¡Œæ¨¡å¼
            mode = prompt_choice("è¯·é€‰æ‹©å¤„ç†æ–¹å¼", ["å…¨è‡ªåŠ¨ï¼ˆä¸€æ¬¡æ€§å…¨éƒ¨ç”Ÿæˆï¼‰", "åˆ†æ­¥å¤„ç†ï¼ˆæ¯æ­¥ç¡®è®¤å¹¶å¯ä¿®æ”¹äº§ç‰©ï¼‰"], default_index=1)
            run_mode = "auto" if mode.startswith("å…¨è‡ªåŠ¨") else "step"
        # å¦‚æœæä¾›çš„æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œåˆ™ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•è§£æ
        if not os.path.isabs(input_file):
            input_file = os.path.join(project_root, input_file)
        
        print(f"æ­£åœ¨è¯»å–æ–‡æ¡£: {input_file}")
        document_content, original_length = read_document(input_file)
        
        # 2. æ™ºèƒ½ç¼©å†™ï¼ˆç¬¬ä¸€æ¬¡LLMå¤„ç†ï¼‰
        print("æ­£åœ¨è¿›è¡Œæ™ºèƒ½ç¼©å†™å¤„ç†...")
        script_data = intelligent_summarize(
            llm_server, llm_model, document_content, 
            target_length, num_segments
        )
        
        # åˆ›å»ºå¸¦æœ‰title+æ—¶é—´çš„è¾“å‡ºç›®å½•ç»“æ„
        current_time = datetime.datetime.now()
        time_suffix = current_time.strftime("%m%d_%H%M")
        title = script_data.get('title', 'untitled').replace(' ', '_').replace('/', '_').replace('\\', '_')
        project_folder = f"{title}_{time_suffix}"
        project_output_dir = os.path.join(output_dir, project_folder)
        
        os.makedirs(project_output_dir, exist_ok=True)
        os.makedirs(f"{project_output_dir}/images", exist_ok=True)
        os.makedirs(f"{project_output_dir}/voice", exist_ok=True)
        os.makedirs(f"{project_output_dir}/text", exist_ok=True)
        os.makedirs(f"{project_output_dir}/music", exist_ok=True)
        
        print(f"é¡¹ç›®è¾“å‡ºç›®å½•: {project_output_dir}")
        
        # ä¿å­˜å£æ’­ç¨¿JSON
        script_path = f"{project_output_dir}/text/script.json"
        with open(script_path, 'w', encoding='utf-8') as f:
            json.dump(script_data, f, ensure_ascii=False, indent=2)
        print(f"å£æ’­ç¨¿å·²ä¿å­˜åˆ°: {script_path}")
        
        # åˆ†æ­¥ç¡®è®¤ï¼šå…è®¸ç”¨æˆ·ä¿®æ”¹ script.json åå†ç»§ç»­
        if run_mode == "step":
            from utils import prompt_yes_no, load_json_file
            if not prompt_yes_no("æ˜¯å¦ç»§ç»­åˆ°å…³é”®è¯æå–æ­¥éª¤ï¼Ÿ(å¯å…ˆåœ¨ output/text/script.json ä¿®æ”¹åå†ç»§ç»­)"):
                return {"success": True, "message": "å·²ç”Ÿæˆè„šæœ¬ï¼Œç”¨æˆ·ç»ˆæ­¢äºæ­¤", "final_stage": "script"}
            # é‡æ–°ä»ç£ç›˜åŠ è½½æœ€æ–°è„šæœ¬ï¼Œç¡®ä¿æ•è·ç”¨æˆ·è°ƒæ•´
            script_data = load_json_file(script_path)
        
        # 3. å…³é”®è¯æå–ï¼ˆç¬¬äºŒæ¬¡LLMå¤„ç†ï¼‰
        print("æ­£åœ¨æå–å…³é”®è¯...")
        keywords_data = extract_keywords(
            llm_server, llm_model, script_data
        )
        
        # ä¿å­˜å…³é”®è¯JSON
        keywords_path = f"{project_output_dir}/text/keywords.json"
        with open(keywords_path, 'w', encoding='utf-8') as f:
            json.dump(keywords_data, f, ensure_ascii=False, indent=2)
        print(f"å…³é”®è¯å·²ä¿å­˜åˆ°: {keywords_path}")
        
        if run_mode == "step":
            from utils import prompt_yes_no, load_json_file
            if not prompt_yes_no("æ˜¯å¦ç»§ç»­åˆ°å›¾åƒç”Ÿæˆæ­¥éª¤ï¼Ÿ(å¯å…ˆåœ¨ output/text/keywords.json ä¿®æ”¹åå†ç»§ç»­)"):
                return {"success": True, "message": "å·²ç”Ÿæˆå…³é”®è¯ï¼Œç”¨æˆ·ç»ˆæ­¢äºæ­¤", "final_stage": "keywords"}
            keywords_data = load_json_file(keywords_path)
        
        # 4. AIå›¾åƒç”Ÿæˆ
        print("æ­£åœ¨ç”Ÿæˆå›¾åƒ...")
        image_paths = generate_images_for_segments(
            image_server, image_model, keywords_data, 
            image_style_preset, image_size, f"{project_output_dir}/images"
        )
        
        if run_mode == "step":
            from utils import prompt_yes_no
            print("å›¾åƒå·²ç”Ÿæˆè‡³:")
            for p in image_paths:
                print(" -", p)
            if not prompt_yes_no("æ˜¯å¦ç»§ç»­åˆ°è¯­éŸ³åˆæˆæ­¥éª¤ï¼Ÿ(å¯å…ˆåœ¨ output/images ä¸­æ›¿æ¢å›¾ç‰‡ï¼Œä¿æŒæ–‡ä»¶åä¸å˜)"):
                return {"success": True, "message": "å·²ç”Ÿæˆå›¾åƒï¼Œç”¨æˆ·ç»ˆæ­¢äºæ­¤", "final_stage": "images", "images": image_paths}
            # å†æ¬¡ä»ç£ç›˜è¯»å–ï¼Œç¡®ä¿æ•è·ç”¨æˆ·æ›¿æ¢åçš„æ–‡ä»¶è·¯å¾„ï¼ˆæ–‡ä»¶åä¸å˜ï¼‰
            image_paths = [os.path.join(project_output_dir, "images", os.path.basename(p)) for p in image_paths]
        
        # 5. è¯­éŸ³åˆæˆ
        print("æ­£åœ¨åˆæˆè¯­éŸ³...")
        audio_paths = synthesize_voice_for_segments(
            tts_server, voice, script_data, f"{project_output_dir}/voice"
        )
        
        if run_mode == "step":
            from utils import prompt_yes_no
            print("éŸ³é¢‘å·²ç”Ÿæˆè‡³:")
            for p in audio_paths:
                print(" -", p)
            if not prompt_yes_no("æ˜¯å¦ç»§ç»­åˆ°è§†é¢‘åˆæˆæ­¥éª¤ï¼Ÿ(å¯å…ˆåœ¨ output/voice ä¸­æ›¿æ¢éŸ³é¢‘ï¼Œä¿æŒæ–‡ä»¶åä¸å˜)"):
                return {"success": True, "message": "å·²ç”ŸæˆéŸ³é¢‘ï¼Œç”¨æˆ·ç»ˆæ­¢äºæ­¤", "final_stage": "audio", "audio": audio_paths}
            # é‡æ–°åŸºäºç£ç›˜æ–‡ä»¶ç¡®è®¤è·¯å¾„
            audio_paths = [os.path.join(project_output_dir, "voice", os.path.basename(p)) for p in audio_paths]
        
        # 6. è§†é¢‘åˆæˆå‰æ ¡éªŒèµ„æº
        from utils import validate_media_assets, prompt_yes_no
        validation = validate_media_assets(
            script_data=script_data,
            images_dir=os.path.join(project_output_dir, "images"),
            voice_dir=os.path.join(project_output_dir, "voice"),
        )
        if not validation['ok']:
            print("\nâš ï¸  è§†é¢‘åˆæˆå‰æ ¡éªŒæœªé€šè¿‡ï¼š")
            for item in validation['issues']:
                print(" -", item)
            print("è¯·åˆ° output ç›¸åº”ç›®å½•ä¿®æ­£èµ„æºï¼ˆæ–‡ä»¶æ•°é‡ä¸å‘½åå¿…é¡»åŒ¹é…æ®µè½æ•°é‡ï¼‰ï¼Œä¿®æ­£åå†ç»§ç»­ã€‚")
            if run_mode == "step":
                if not prompt_yes_no("æ˜¯å¦å·²å®Œæˆè°ƒæ•´å¹¶ç»§ç»­è¿›è¡Œè§†é¢‘åˆæˆï¼Ÿ"):
                    return {"success": False, "message": "è§†é¢‘èµ„æºæ ¡éªŒæœªé€šè¿‡ï¼Œç”¨æˆ·ç»ˆæ­¢äºæ­¤", "final_stage": "validation_failed"}
                # å†æ¬¡æ ¡éªŒ
                validation = validate_media_assets(
                    script_data=script_data,
                    images_dir=os.path.join(project_output_dir, "images"),
                    voice_dir=os.path.join(project_output_dir, "voice"),
                )
                if not validation['ok']:
                    return {"success": False, "message": "è§†é¢‘èµ„æºæ ¡éªŒä»æœªé€šè¿‡", "issues": validation['issues']}
            else:
                return {"success": False, "message": "è§†é¢‘èµ„æºæ ¡éªŒæœªé€šè¿‡", "issues": validation['issues']}

        print("æ­£åœ¨åˆæˆæœ€ç»ˆè§†é¢‘...")
        # è§£æèƒŒæ™¯éŸ³ä¹ç»å¯¹è·¯å¾„
        bgm_audio_path = None
        if bgm_filename:
            candidate = os.path.join(project_output_dir, "music", bgm_filename)
            if not os.path.exists(candidate):
                # è‹¥é¡¹ç›®è¾“å‡ºç›®å½•ä¸å­˜åœ¨è¯¥æ–‡ä»¶ï¼Œåˆ™å°è¯•ä»å…¨å±€åº“å¤åˆ¶
                global_candidate = os.path.join(project_root, "music", bgm_filename)
                if os.path.exists(global_candidate):
                    try:
                        shutil.copy2(global_candidate, candidate)
                        print(f"å·²ä»å…¨å±€éŸ³ä¹åº“å¤åˆ¶ BGM åˆ°æœ¬é¡¹ç›®: {candidate}")
                    except Exception as _e:
                        print(f"âš ï¸  å¤åˆ¶èƒŒæ™¯éŸ³ä¹å¤±è´¥: {_e}")
            if os.path.exists(candidate):
                bgm_audio_path = candidate
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ°æŒ‡å®šçš„èƒŒæ™¯éŸ³ä¹æ–‡ä»¶: {candidate}ï¼Œå°†ç»§ç»­ç”Ÿæˆæ— èƒŒæ™¯éŸ³ä¹çš„è§†é¢‘")

        final_video_path = compose_final_video(
            image_paths, audio_paths, f"{project_output_dir}/final_video.mp4",
            script_data=script_data, enable_subtitles=enable_subtitles,
            bgm_audio_path=bgm_audio_path, bgm_volume=0.15
        )
        
        # è®¡ç®—å¤„ç†ç»Ÿè®¡ä¿¡æ¯
        end_time = datetime.datetime.now()
        execution_time = (end_time - start_time).total_seconds()
        compression_ratio = (1 - script_data['total_length'] / original_length) * 100
        
        # è¾“å‡ºå®Œæˆä¿¡æ¯
        print("\n" + "="*60)
        print("ğŸ‰ è§†é¢‘åˆ¶ä½œå®Œæˆï¼")
        print("="*60)
        print(f"ğŸ“„ å£æ’­ç¨¿æ®µæ•°: {script_data['actual_segments']}")
        print(f"ğŸ–¼ï¸  ç”Ÿæˆå›¾ç‰‡æ•°é‡: {len(image_paths)}")
        print(f"ğŸ”Š éŸ³é¢‘æ–‡ä»¶æ•°é‡: {len(audio_paths)}")
        print(f"ğŸ¬ æœ€ç»ˆè§†é¢‘: {final_video_path}")
        print(f"ğŸ“ å­—å¹•åŠŸèƒ½: {'å¯ç”¨' if enable_subtitles else 'ç¦ç”¨'}")
        print(f"â±ï¸  æ€»å¤„ç†æ—¶é—´: {execution_time:.1f}ç§’")
        print("="*60)
        
        # è¿”å›ç»“æœ
        result = {
            "success": True,
            "message": "è§†é¢‘åˆ¶ä½œå®Œæˆ",
            "execution_time": execution_time,
            "script": {
                "file_path": script_path,
                "total_length": script_data['total_length'],
                "segments_count": script_data['actual_segments']
            },
            "keywords": {
                "file_path": keywords_path,
                "total_keywords": sum(len(seg.get('keywords', [])) + len(seg.get('atmosphere', [])) 
                                    for seg in keywords_data['segments']),
                "avg_per_segment": sum(len(seg.get('keywords', [])) + len(seg.get('atmosphere', [])) 
                                     for seg in keywords_data['segments']) / len(keywords_data['segments'])
            },
            "images": image_paths,
            "audio_files": audio_paths,
            "final_video": final_video_path,
            "statistics": {
                "original_length": original_length,
                "compression_ratio": f"{compression_ratio:.1f}%",
                "total_processing_time": execution_time,
                "llm_calls": 2,
                "image_generation_time": 0,  # Will be updated by actual implementation
                "audio_generation_time": 0,  # Will be updated by actual implementation
                "video_composition_time": 0  # Will be updated by actual implementation
            }
        }
        
        return result
    
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "message": f"å¤„ç†å¤±è´¥: {str(e)}",
            "execution_time": 0,
            "error": str(e)
        }

# Interactive CLI Entry Point
if __name__ == "__main__":
    print("ğŸš€ æ™ºèƒ½è§†é¢‘åˆ¶ä½œç³»ç»Ÿå¯åŠ¨")
    
    # ========================================================================
    # å¯é€‰å‚æ•°è¯´æ˜ (æ‰€æœ‰æ¨¡å‹åç§°å‡å¯ç›´æ¥å¤åˆ¶ç²˜è´´ä½¿ç”¨)
    # ========================================================================
    
    # åŸºç¡€å‚æ•°
    # target_length: ç›®æ ‡å­—æ•° (500-1000)
    # num_segments: åˆ†æ®µæ•°é‡ (5-20) 
    # enable_subtitles: æ˜¯å¦å¯ç”¨å­—å¹• (True/False)
    
    # å›¾åƒå°ºå¯¸é€‰é¡¹
    # image_size: 1024x1024 | 1280x720 | 720x1280 | 864x1152 | 1152x864 | 832x1248 | 1248x832 | 1512x648
    
    # LLMæ¨¡å‹é€‰é¡¹
    # llm_model:
    #     OpenRouteræœåŠ¡å•†:
    #       - google/gemini-2.5-pro
    #       - anthropic/claude-sonnet-4  
    #       - anthropic/claude-3.7-sonnet:thinking
    #     
    #     SiliconFlowæœåŠ¡å•†:
    #       - zai-org/GLM-4.5
    #       - moonshotai/Kimi-K2-Instruct
    #       - Qwen/Qwen3-235B-A22B-Thinking-2507
    #     
    #     OpenAIæœåŠ¡å•†(aihubmixä»£ç†):
    #       - gpt-5
    
    # å›¾åƒç”Ÿæˆæ¨¡å‹
    # image_model: doubao-seedream-3-0-t2i-250415
    
    # è¯­éŸ³éŸ³è‰²é€‰é¡¹  
    # voice: zh_male_yuanboxiaoshu_moon_bigtts | zh_female_linjianvhai_moon_bigtts | 
    #        zh_male_yangguangqingnian_moon_bigtts | ICL_zh_female_heainainai_tob
    
    # å›¾åƒé£æ ¼é¢„è®¾
    # image_style_preset: cinematic | documentary | artistic | minimalist | vintage
    
    # èƒŒæ™¯éŸ³ä¹
    # bgm_filename: èƒŒæ™¯éŸ³ä¹æ–‡ä»¶åï¼ˆå°†éŸ³é¢‘æ”¾åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ music/ ä¸‹ï¼‰ï¼›
    #               ä¼ å…¥ None / ç•™ç©º / é”™è¯¯æ–‡ä»¶å åˆ™ä¸ä½¿ç”¨ BGMã€‚
    # ========================================================================
    
    try:
        # è¿è¡Œä¸»ç¨‹åº - input_fileè®¾ä¸ºNoneä»¥å¯ç”¨äº¤äº’å¼é€‰æ‹©
        result = main(
            input_file=None,  # å¯ç”¨äº¤äº’å¼æ–‡ä»¶é€‰æ‹©
            target_length=1000,
            num_segments=10,
            image_size="1280x720",
            llm_model="google/gemini-2.5-pro",
            image_model="doubao-seedream-3-0-t2i-250415",
            voice="zh_male_yuanboxiaoshu_moon_bigtts",
            image_style_preset="vintage",
            enable_subtitles=True,
            bgm_filename="Ramin Djawadi - Light of the Seven.mp3"  
        )
        
        if result["success"]:
            print("\nğŸ‰ è§†é¢‘åˆ¶ä½œå®Œæˆï¼")
        else:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()