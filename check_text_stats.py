"""
ç‹¬ç«‹å­—æ•°ä¸Tokenä¼°ç®—è„šæœ¬

åŠŸèƒ½ï¼š
- è¯»å– EPUB / PDF / TXT æ–‡æœ¬
- ç»Ÿè®¡æ€»å­—ç¬¦æ•°ã€ä¸­æ–‡å­—ç¬¦æ•°ã€è‹±æ–‡å­—ç¬¦æ•°ï¼ˆå«å­—æ¯/æ•°å­—/ASCIIæ ‡ç‚¹/ç©ºç™½ï¼‰ç­‰
- ä¼°ç®—Tokenæ•°é‡ï¼ˆæŒ‰ä¸­è‹±æ–‡åˆ†åˆ«ä¼°ç®—ï¼‰ï¼š
  - ä¸­æ–‡ï¼šçº¦ 1 å­—ç¬¦ â‰ˆ 1 token
  - è‹±æ–‡ï¼šçº¦ 4 å­—ç¬¦ â‰ˆ 1 tokenï¼ˆå­—æ¯/æ•°å­—/ASCIIæ ‡ç‚¹/ç©ºç™½ç´¯è®¡ï¼‰
- å¯é€‰ï¼šè‹¥å·²å®‰è£… tiktokenï¼Œå¯å¯ç”¨ç²¾ç¡®tokenè®¡æ•°ï¼ˆå‚è€ƒOpenAIç¼–ç å™¨ï¼‰

ä½¿ç”¨ç¤ºä¾‹ï¼š
  # äº¤äº’å¼ä» input/ é€‰æ‹©æ–‡ä»¶
  python check_text_stats.py --interactive

  # ç›´æ¥æŒ‡å®šæ–‡ä»¶
  python check_text_stats.py --input "/absolute/path/to/file.epub"
  python check_text_stats.py --input "/absolute/path/to/file.pdf" --use-tiktoken
  python check_text_stats.py --input "/absolute/path/to/file.txt" --encoding utf-8
"""

import os
import re
import math
import argparse
from typing import Tuple, Dict, Any


def _read_txt(file_path: str, encoding: str = "utf-8") -> Tuple[str, int]:
    with open(file_path, "r", encoding=encoding, errors="ignore") as f:
        text = f.read()
    return text, len(text)


def _read_document_any(file_path: str, encoding: str = "utf-8") -> Tuple[str, int]:
    ext = os.path.splitext(file_path)[1].lower()
    if ext == ".txt":
        return _read_txt(file_path, encoding=encoding)
    # å¤ç”¨ç°æœ‰çš„ EPUB/PDF è¯»å–é€»è¾‘
    try:
        from functions import read_document
        return read_document(file_path)
    except Exception as e:
        raise RuntimeError(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")


def _count_categories(text: str) -> Dict[str, int]:
    # åŸºæœ¬åˆ†ç±»ç»Ÿè®¡
    zh_chars = len(re.findall(r"[\u4e00-\u9fff]", text))
    en_letters = len(re.findall(r"[A-Za-z]", text))
    digits = len(re.findall(r"\d", text))
    spaces = len(re.findall(r"\s", text))

    # ASCII æ ‡ç‚¹ï¼ˆstring.punctuation ç­‰ä»·èŒƒå›´ï¼‰
    ascii_punct = len(re.findall(r"[!\"#$%&'()*+,\-./:;<=>?@\[\\\]^_`{|}~]", text))

    total = len(text)
    other = total - zh_chars - en_letters - digits - spaces - ascii_punct

    return {
        "total": total,
        "zh_chars": zh_chars,
        "en_letters": en_letters,
        "digits": digits,
        "spaces": spaces,
        "ascii_punct": ascii_punct,
        "other": other if other >= 0 else 0,
    }


def _estimate_tokens(stats: Dict[str, int]) -> Dict[str, int]:
    # ä¸­æ–‡ï¼š1 å­—ç¬¦ â‰ˆ 1 token
    zh_tokens = stats["zh_chars"]

    # è‹±æ–‡ï¼šçº¦ 4 å­—ç¬¦ â‰ˆ 1 tokenï¼ˆå°†å­—æ¯/æ•°å­—/ASCIIæ ‡ç‚¹/ç©ºç™½éƒ½è®¡å…¥è‹±æ–‡ä¼°ç®—ï¼‰
    en_chars_for_token = stats["en_letters"] + stats["digits"] + stats["ascii_punct"] + stats["spaces"]
    en_tokens = int(math.ceil(en_chars_for_token / 4.0))

    return {
        "tokens_zh_est": zh_tokens,
        "tokens_en_est": en_tokens,
        "tokens_total_est": zh_tokens + en_tokens,
    }


def _tiktoken_count(text: str, model: str = "cl100k_base") -> int:
    try:
        import tiktoken
    except Exception as e:
        raise RuntimeError(f"æœªå®‰è£… tiktokenï¼š{e}")
    try:
        enc = tiktoken.get_encoding(model)
    except Exception:
        try:
            enc = tiktoken.get_encoding("cl100k_base")
        except Exception as ie:
            raise RuntimeError(f"tiktoken ç¼–ç å™¨åŠ è½½å¤±è´¥ï¼š{ie}")
    return len(enc.encode(text))


def analyze_file(file_path: str, encoding: str = "utf-8", use_tiktoken: bool = False, tiktoken_model: str = "cl100k_base") -> Dict[str, Any]:
    text, total_len = _read_document_any(file_path, encoding=encoding)
    stats = _count_categories(text)
    token_est = _estimate_tokens(stats)

    result: Dict[str, Any] = {
        "file": file_path,
        "total_chars": stats["total"],
        "zh_chars": stats["zh_chars"],
        "en_letters": stats["en_letters"],
        "digits": stats["digits"],
        "spaces": stats["spaces"],
        "ascii_punct": stats["ascii_punct"],
        "other_chars": stats["other"],
        **token_est,
    }

    if use_tiktoken:
        try:
            result["tokens_tiktoken"] = _tiktoken_count(text, model=tiktoken_model)
            result["tiktoken_model"] = tiktoken_model
        except Exception as e:
            result["tokens_tiktoken_error"] = str(e)

    return result


def _format_int(n: int) -> str:
    return f"{n:,}"


def main():
    parser = argparse.ArgumentParser(description="æ£€æŸ¥æ–‡æ¡£å­—æ•°ä¸Tokenä¼°ç®—ï¼ˆä¸­è‹±æ–‡åŒºåˆ†ï¼‰")
    parser.add_argument("--input", required=False, help="è¦åˆ†æçš„æ–‡ä»¶ï¼ˆæ”¯æŒ .epub / .pdf / .txtï¼‰")
    parser.add_argument("--interactive", action="store_true", help="ä»é¡¹ç›® input/ ç›®å½•äº¤äº’å¼é€‰æ‹©æ–‡ä»¶")
    parser.add_argument("--encoding", default="utf-8", help="TXTæ–‡ä»¶è¯»å–ç¼–ç ï¼Œé»˜è®¤ utf-8")
    parser.add_argument("--use-tiktoken", action="store_true", help="è‹¥å·²å®‰è£… tiktokenï¼Œåˆ™è®¡ç®—ç²¾ç¡® token æ•°")
    parser.add_argument("--tiktoken-model", default="cl100k_base", help="tiktoken ç¼–ç å™¨ï¼Œé»˜è®¤ cl100k_base")
    args = parser.parse_args()

    file_path = args.input
    if args.interactive or not file_path:
        # å¤ç”¨ä¸»é¡¹ç›®äº¤äº’å¼æ–‡ä»¶é€‰æ‹©å™¨
        try:
            from utils import interactive_file_selector
            project_root = os.path.dirname(__file__)
            file_path = interactive_file_selector(input_dir=os.path.join(project_root, "input"))
        except Exception as e:
            print(f"âŒ äº¤äº’å¼é€‰æ‹©å¤±è´¥: {e}")
            raise SystemExit(1)
        if not file_path:
            print("ğŸ‘‹ å·²å–æ¶ˆ")
            raise SystemExit(0)
    if not os.path.isabs(file_path):
        file_path = os.path.abspath(file_path)
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        raise SystemExit(1)

    try:
        res = analyze_file(
            file_path=file_path,
            encoding=args.encoding,
            use_tiktoken=args.use_tiktoken,
            tiktoken_model=args.tiktoken_model,
        )
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        raise SystemExit(2)

    print("\n" + "=" * 60)
    print("ğŸ“Š æ–‡æ¡£å­—æ•°ä¸Tokenä¼°ç®—")
    print("=" * 60)
    print(f"æ–‡ä»¶: {res['file']}")
    print(f"æ€»å­—ç¬¦: {_format_int(res['total_chars'])}")
    print(f"ä¸­æ–‡å­—ç¬¦: {_format_int(res['zh_chars'])}")
    print(f"è‹±æ–‡å­—æ¯: {_format_int(res['en_letters'])}")
    print(f"æ•°å­—: {_format_int(res['digits'])}")
    print(f"ASCIIæ ‡ç‚¹: {_format_int(res['ascii_punct'])}")
    print(f"ç©ºç™½å­—ç¬¦: {_format_int(res['spaces'])}")
    print(f"å…¶ä»–å­—ç¬¦: {_format_int(res['other_chars'])}")
    print("-" * 60)
    print(f"ä¼°ç®—Tokenï¼ˆä¸­æ–‡ï¼‰: {_format_int(res['tokens_zh_est'])}")
    print(f"ä¼°ç®—Tokenï¼ˆè‹±æ–‡ï¼‰: {_format_int(res['tokens_en_est'])}")
    print(f"ä¼°ç®—Tokenï¼ˆåˆè®¡ï¼‰: {_format_int(res['tokens_total_est'])}")
    if 'tokens_tiktoken' in res:
        model = res.get('tiktoken_model', 'cl100k_base')
        print(f"tiktokenè®¡æ•°ï¼ˆ{model}ï¼‰: {_format_int(res['tokens_tiktoken'])}")
    elif 'tokens_tiktoken_error' in res:
        print(f"tiktokenè®¡æ•°å¤±è´¥: {res['tokens_tiktoken_error']}")
    print("=" * 60)


if __name__ == "__main__":
    main()


