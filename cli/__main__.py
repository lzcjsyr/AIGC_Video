import os
import sys
import datetime
from typing import Dict, Any

# Allow running this file directly: ensure project root is on sys.path
_CURRENT_DIR = os.path.dirname(__file__)
_PROJECT_ROOT = os.path.dirname(_CURRENT_DIR)
if _PROJECT_ROOT not in sys.path:
    sys.path.insert(0, _PROJECT_ROOT)

# é¦–å…ˆé…ç½®CLIä¸“ç”¨æ—¥å¿—
from cli.ui_helpers import setup_cli_logging
setup_cli_logging()

from config import config
from core.validators import validate_startup_args
from core.pipeline import (
    run_auto,
    run_step_1,
    run_step_1_5,
    run_step_2,
    run_step_3,
    run_step_4,
    run_step_5,
)
from cli.ui_helpers import (
    prompt_choice,
    interactive_file_selector,
    interactive_project_selector,
    print_section,
)

"""
å‘½ä»¤è¡Œå‚æ•°ä½¿ç”¨è¯´æ˜ï¼ˆç®€ç‰ˆï¼‰ï¼š

å…³é”®å‚æ•°ï¼ˆå‡å¯æŒ‰éœ€è¦†ç›–ï¼‰ï¼š
- input_file: è¾“å…¥æ–‡æ¡£è·¯å¾„ï¼›ä¸ºç©ºæ—¶è¿›å…¥äº¤äº’é€‰æ‹©
- target_length: ç›®æ ‡å­—æ•°ï¼ˆèŒƒå›´ç”± config.MIN_TARGET_LENGTH/MAX_TARGET_LENGTH æ§åˆ¶ï¼‰
- num_segments: åˆ†æ®µæ•°é‡ï¼ˆèŒƒå›´ç”± config.MIN_NUM_SEGMENTS/MAX_NUM_SEGMENTS æ§åˆ¶ï¼‰
- image_size: å›¾åƒå°ºå¯¸ï¼ˆå¿…é¡»åœ¨ config.SUPPORTED_IMAGE_SIZES ä¸­ï¼‰
- llm_model: LLM æ¨¡å‹åï¼ˆè‡ªåŠ¨è¯†åˆ«æœåŠ¡å•†ï¼‰
- image_model: å›¾åƒæ¨¡å‹åï¼ˆå¦‚ doubao-seedream-3-0-t2i-250415ï¼‰
- voice: è¯­éŸ³éŸ³è‰²ï¼ˆå­—èŠ‚å¤§æ¨¡å‹éŸ³è‰²ï¼‰
- output_dir: è¾“å‡ºæ ¹ç›®å½•ï¼ˆé»˜è®¤ outputï¼‰
- image_style_preset: æ®µè½å›¾åƒé£æ ¼é¢„è®¾ï¼ˆè§ prompts.IMAGE_STYLE_PRESETSï¼‰
- opening_image_style: å¼€åœºå›¾åƒé£æ ¼ï¼ˆè§ prompts.OPENING_IMAGE_STYLESï¼‰
- enable_subtitles: æ˜¯å¦å¯ç”¨å­—å¹•ï¼ˆboolï¼‰
- bgm_filename: èƒŒæ™¯éŸ³ä¹æ–‡ä»¶åï¼ˆä»é¡¹ç›®æ ¹ç›®å½• music/ è¯»å–ï¼Œä¸å¡«åˆ™ä¸æ·»åŠ BGMï¼‰

è¿è¡Œæ–¹å¼ï¼š
- CLI åŒ…æ–¹å¼ï¼ˆæ¨èï¼‰ï¼š
  python -m cli

- ç›´æ¥è¿è¡Œæœ¬æ–‡ä»¶ï¼š
  python cli/__main__.py

è¯´æ˜ï¼š
- å‚æ•°çš„è¾¹ç•Œä¸ç™½åå•ç”± config.py é…ç½®ï¼Œå¯åŠ¨æ—¶ç»Ÿä¸€æ ¡éªŒã€‚
- CLI å…·ä½“æµç¨‹ç”±æœ¬æ–‡ä»¶ä¸ core/pipeline.py å®ç°ã€‚
"""

def _select_entry_and_context(project_root: str, output_dir: str):
    while True:
        entry = prompt_choice("è¯·é€‰æ‹©æ“ä½œ", ["æ–°å»ºé¡¹ç›®ï¼ˆä»æ–‡æ¡£å¼€å§‹ï¼‰", "æ‰“å¼€ç°æœ‰é¡¹ç›®ï¼ˆä»outputé€‰æ‹©ï¼‰"], default_index=0)
        if entry is None:
            return None
        if entry.startswith("æ–°å»ºé¡¹ç›®"):
            input_file = interactive_file_selector(input_dir=os.path.join(project_root, "input"))
            if input_file is None:
                print("\nğŸ‘‹ è¿”å›ä¸Šä¸€çº§")
                continue
            mode = prompt_choice("è¯·é€‰æ‹©å¤„ç†æ–¹å¼", ["å…¨è‡ªåŠ¨ï¼ˆä¸€æ¬¡æ€§å…¨éƒ¨ç”Ÿæˆï¼‰", "åˆ†æ­¥å¤„ç†ï¼ˆæ¯æ­¥ç¡®è®¤å¹¶å¯ä¿®æ”¹äº§ç‰©ï¼‰"], default_index=0)
            if mode is None:
                print("ğŸ‘‹ è¿”å›ä¸Šä¸€çº§")
                continue
            run_mode = "auto" if mode.startswith("å…¨è‡ªåŠ¨") else "step"
            return {"entry": "new", "input_file": input_file, "run_mode": run_mode}

        project_dir = interactive_project_selector(output_dir=os.path.join(project_root, "output"))
        if not project_dir:
            print("ğŸ‘‹ è¿”å›ä¸Šä¸€çº§")
            continue
        from core.project_scanner import detect_project_progress
        from cli.ui_helpers import display_project_progress_and_select_step
        
        # æ£€æµ‹é¡¹ç›®è¿›åº¦å¹¶æ˜¾ç¤ºæ­¥éª¤é€‰é¡¹
        progress = detect_project_progress(project_dir)
        
        # æ˜¾ç¤ºå®Œæ•´è¿›åº¦çŠ¶æ€å¹¶è®©ç”¨æˆ·é€‰æ‹©è¦æ‰§è¡Œçš„æ­¥éª¤
        selected_step = display_project_progress_and_select_step(progress)
        if selected_step is None:
            project_dir = None
            continue
            
        step_val = selected_step
        
        return {"entry": "existing", "project_dir": project_dir, "selected_step": step_val}


def run_specific_step(
    target_step, project_output_dir, llm_server, llm_model, image_model, 
    image_size, image_style_preset, opening_image_style, tts_server, voice, 
    num_segments, enable_subtitles, bgm_filename
):
    """
    æ‰§è¡ŒæŒ‡å®šæ­¥éª¤å¹¶è¿”å›ç»“æœ
    """
    print(f"\næ­£åœ¨æ‰§è¡Œæ­¥éª¤ {target_step}...")
    
    if target_step == 1.5:
        result = run_step_1_5(project_output_dir, num_segments)
    elif target_step == 2:
        result = run_step_2(llm_server, llm_model, project_output_dir)
    elif target_step == 3:
        result = run_step_3(image_model, image_size, image_style_preset, project_output_dir, opening_image_style)
    elif target_step == 4:
        result = run_step_4(tts_server, voice, project_output_dir)
    elif target_step == 5:
        result = run_step_5(project_output_dir, image_size, enable_subtitles, bgm_filename, voice)
    else:
        result = {"success": False, "message": "æ— æ•ˆçš„æ­¥éª¤"}
    
    return result


def run_step_by_step_loop(
    project_output_dir, initial_step, llm_server, llm_model, image_model, 
    image_size, image_style_preset, opening_image_style, tts_server, voice, 
    num_segments, enable_subtitles, bgm_filename
):
    """
    æ‰§è¡ŒæŒ‡å®šæ­¥éª¤ï¼Œç„¶åè¿›å…¥äº¤äº’æ¨¡å¼è®©ç”¨æˆ·é€‰æ‹©ä¸‹ä¸€æ­¥æ“ä½œ
    """
    from core.project_scanner import detect_project_progress
    from cli.ui_helpers import display_project_progress_and_select_step
    
    # é¦–å…ˆæ‰§è¡ŒæŒ‡å®šçš„æ­¥éª¤
    if initial_step > 0:
        result = run_specific_step(
            initial_step, project_output_dir, llm_server, llm_model, image_model, 
            image_size, image_style_preset, opening_image_style, tts_server, voice, 
            num_segments, enable_subtitles, bgm_filename
        )
        
        # æ˜¾ç¤ºæ‰§è¡Œç»“æœ
        if result.get("success"):
            print(f"âœ… æ­¥éª¤ {initial_step} æ‰§è¡ŒæˆåŠŸ")
        else:
            print(f"âŒ æ­¥éª¤ {initial_step} æ‰§è¡Œå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
            return result
    
    # è¿›å…¥äº¤äº’å¾ªç¯
    while True:
        # é‡æ–°æ£€æµ‹é¡¹ç›®è¿›åº¦
        progress = detect_project_progress(project_output_dir)
        current_step = progress.get('current_step', 0)
        
        print(f"\nğŸ“ å½“å‰è¿›åº¦ï¼šå·²å®Œæˆåˆ°ç¬¬{current_step}æ­¥")
        print("ğŸ’¡ å¦‚éœ€ä¿®æ”¹ç”Ÿæˆçš„å†…å®¹ï¼Œå¯ç¼–è¾‘å¯¹åº”æ–‡ä»¶åå†ç»§ç»­")
        
        # è®©ç”¨æˆ·é€‰æ‹©ä¸‹ä¸€æ­¥æ“ä½œ
        selected_step = display_project_progress_and_select_step(progress)
        if selected_step is None:
            return {"success": True, "message": "ç”¨æˆ·é€€å‡º"}
        
        # æ‰§è¡Œé€‰æ‹©çš„æ­¥éª¤
        result = run_specific_step(
            selected_step, project_output_dir, llm_server, llm_model, image_model, 
            image_size, image_style_preset, opening_image_style, tts_server, voice, 
            num_segments, enable_subtitles, bgm_filename
        )
        
        # æ˜¾ç¤ºç»“æœ
        if result.get("success"):
            print(f"âœ… æ­¥éª¤ {selected_step} æ‰§è¡ŒæˆåŠŸ")
            if selected_step == 5:
                print(f"\nğŸ‰ è§†é¢‘åˆ¶ä½œå®Œæˆï¼")
                if result.get("final_video"):
                    print(f"æœ€ç»ˆè§†é¢‘: {result.get('final_video')}")
        else:
            print(f"âŒ æ­¥éª¤ {selected_step} æ‰§è¡Œå¤±è´¥: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")


def cli_main(
    input_file=None,
    target_length: int = config.DEFAULT_TARGET_LENGTH,
    num_segments: int = config.DEFAULT_NUM_SEGMENTS,
    image_size: str = config.DEFAULT_IMAGE_SIZE,
    llm_model: str = "google/gemini-2.5-pro",
    image_model: str = "doubao-seedream-3-0-t2i-250415",
    voice: str = config.DEFAULT_VOICE,
    output_dir: str = config.DEFAULT_OUTPUT_DIR,
    image_style_preset: str = "style05",
    opening_image_style: str = "des01",
    enable_subtitles: bool = True,
    bgm_filename: str = None,
    run_mode: str = "auto",
) -> Dict[str, Any]:
    project_root = os.path.dirname(_PROJECT_ROOT) if os.path.basename(_PROJECT_ROOT) == "cli" else _PROJECT_ROOT

    if not os.path.isabs(output_dir):
        output_dir = os.path.join(project_root, output_dir)

    llm_server, image_server, tts_server = validate_startup_args(
        target_length, num_segments, image_size, llm_model, image_model, voice
    )

    selection = None
    if input_file is None:
        selection = _select_entry_and_context(project_root, output_dir)
        if selection is None:
            return {"success": False, "message": "ç”¨æˆ·å–æ¶ˆ", "execution_time": 0, "error": "ç”¨æˆ·å–æ¶ˆ"}
        if selection["entry"] == "new":
            input_file = selection["input_file"]
            run_mode = selection["run_mode"]
        else:
            # å¤„ç†å·²æœ‰é¡¹ç›®çš„æ­¥éª¤æ‰§è¡Œå¾ªç¯
            project_output_dir = selection["project_dir"]
            return run_step_by_step_loop(
                project_output_dir, selection["selected_step"], 
                llm_server, llm_model, image_model, image_size, image_style_preset, 
                opening_image_style, tts_server, voice, num_segments, 
                enable_subtitles, bgm_filename
            )

    if input_file is not None and not os.path.isabs(input_file):
        input_file = os.path.join(project_root, input_file)

    if run_mode == "auto":
        result = run_auto(
            input_file, output_dir, target_length, num_segments, image_size,
            llm_server, llm_model, image_server, image_model, tts_server, voice,
            image_style_preset, opening_image_style, enable_subtitles, bgm_filename,
        )
        if result.get("success"):
            print_section("æ­¥éª¤ 5/5 å®Œæˆï¼šè§†é¢‘åˆæˆ", "ğŸ¬", "=")
            print(f"æœ€ç»ˆè§†é¢‘: {result.get('final_video')}")
        else:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {result.get('message')}")
        return result
    else:  # step mode
        # å…ˆæ‰§è¡Œæ­¥éª¤1åˆ›å»ºé¡¹ç›®
        result = run_step_1(input_file, output_dir, llm_server, llm_model, target_length, num_segments)
        if not result.get("success"):
            print(f"\nâŒ æ­¥éª¤1å¤±è´¥: {result.get('message')}")
            return result
        
        print("âœ… æ­¥éª¤1æ‰§è¡ŒæˆåŠŸ")
        project_output_dir = result.get("project_output_dir")
        
        # æ­¥éª¤1å®Œæˆåï¼Œè¿›å…¥åˆ†æ­¥å¤„ç†å¾ªç¯
        from core.project_scanner import detect_project_progress
        
        progress = detect_project_progress(project_output_dir)
        current_step = progress.get('current_step', 1)
        
        print(f"\nğŸ“ å½“å‰è¿›åº¦ï¼šå·²å®Œæˆåˆ°ç¬¬{current_step}æ­¥")
        print("ğŸ’¡ å¦‚éœ€ä¿®æ”¹ç”Ÿæˆçš„å†…å®¹ï¼Œå¯ç¼–è¾‘å¯¹åº”æ–‡ä»¶åå†ç»§ç»­")
        
        return run_step_by_step_loop(
            project_output_dir, 0,  # ä¸æ‰§è¡Œåˆå§‹æ­¥éª¤ï¼Œç›´æ¥è¿›å…¥äº¤äº’æ¨¡å¼
            llm_server, llm_model, image_model, image_size, image_style_preset, 
            opening_image_style, tts_server, voice, num_segments, 
            enable_subtitles, bgm_filename
        )


if __name__ == "__main__":
    print("ğŸš€ æ™ºèƒ½è§†é¢‘åˆ¶ä½œç³»ç»Ÿå¯åŠ¨ (CLI)")

    result = cli_main(
        target_length=800,
        num_segments=6,
        image_size="1280x720",
        llm_model="google/gemini-2.5-pro",
        image_model="doubao-seedream-3-0-t2i-250415",
        voice="zh_male_yuanboxiaoshu_moon_bigtts",
        image_style_preset="style05",
        opening_image_style="des01",
        enable_subtitles=True,
        bgm_filename="Ramin Djawadi - Light of the Seven.mp3"
    )

    if result.get("success"):
        if result.get("final_video"):
            print("\nğŸ‰ è§†é¢‘åˆ¶ä½œå®Œæˆï¼")
        else:
            step_msg = result.get("message") or "å·²å®Œæˆå½“å‰æ­¥éª¤"
            print(f"\nâœ… {step_msg}")
    else:
        msg = result.get('message', 'æœªçŸ¥é”™è¯¯')
        if isinstance(msg, str) and ("ç”¨æˆ·å–æ¶ˆ" in msg or "è¿”å›ä¸Šä¸€çº§" in msg):
            print("\nğŸ‘‹ å·²è¿”å›ä¸Šä¸€çº§")
        elif result.get('needs_prior_steps') or (isinstance(msg, str) and "éœ€è¦å…ˆå®Œæˆå‰ç½®æ­¥éª¤" in msg):
            print(f"\nâ„¹ï¸ {msg}")
        else:
            print(f"\nâŒ å¤„ç†å¤±è´¥: {msg}")


